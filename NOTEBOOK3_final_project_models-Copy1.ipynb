{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DS5559 Final Project Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Left Twix Members\n",
    "\n",
    "* Alice Wright - aew7j\n",
    "* Edward Thompson - ejt8b\n",
    "* Michael Davies -  mld9s\n",
    "* Sam Parsons - sp8hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source:\n",
    "The best data source for this appears to be from the City of Chicago, as it is large (169M records and 21 columns), relatively clean, anonymized, and accessible via API.\n",
    "\n",
    "City of Chicago:\n",
    "https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips/m6dm-c72p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Rubric\n",
    "\n",
    "* Model construction (min 3 models) | 3 pts\n",
    "\n",
    "* Model evaluation | 2 pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import context manager: SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# import data types\n",
    "# from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType\n",
    "# import pyspark.sql.types as typ\n",
    "# import pyspark.sql.functions as F\n",
    "# import os\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"mllib_classifier\") \\\n",
    "        .config(\"spark.executor.memory\", '21g') \\\n",
    "        .config('spark.executor.cores', '6') \\\n",
    "        .config('spark.executor.instances', '7') \\\n",
    "        .config(\"spark.driver.memory\",'1g') \\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# import data manipulation methods\n",
    "# from pyspark.ml.feature import Binarizer\n",
    "from pyspark.ml import Pipeline  \n",
    "# from pyspark.ml.feature import *  \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.ml.feature import VectorAssembler \n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "#from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in our dataset from preprocessed parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df = spark.read.parquet(\"/../../project/ds5559/Alice_Ed_Michael_Sam_project/final_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip_ID: string (nullable = true)\n",
      " |-- Trip_Seconds: integer (nullable = true)\n",
      " |-- Trip_Miles: double (nullable = true)\n",
      " |-- Pickup_Census_Tract: string (nullable = true)\n",
      " |-- Dropoff_Census_Tract: string (nullable = true)\n",
      " |-- Pickup_Community_Area: integer (nullable = true)\n",
      " |-- Dropoff_Community_Area: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: double (nullable = true)\n",
      " |-- Additional_Charges_str: double (nullable = true)\n",
      " |-- Trip_Total: double (nullable = true)\n",
      " |-- Shared_Trip_Authorized: boolean (nullable = true)\n",
      " |-- Trips_Pooled: integer (nullable = true)\n",
      " |-- Pickup_Centroid_Latitude: string (nullable = true)\n",
      " |-- Pickup_Centroid_Longitude: string (nullable = true)\n",
      " |-- Pickup_Centroid_Location: string (nullable = true)\n",
      " |-- Dropoff_Centroid_Latitude: string (nullable = true)\n",
      " |-- Dropoff_Centroid_Longitude: string (nullable = true)\n",
      " |-- Dropoff_Centroid_Location: string (nullable = true)\n",
      " |-- Trip_Start_Timestamp: timestamp (nullable = true)\n",
      " |-- Trip_End_Timestamp: timestamp (nullable = true)\n",
      " |-- PostShutdownFlag: integer (nullable = true)\n",
      " |-- Day_Month_str: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- Trip_Year: integer (nullable = true)\n",
      " |-- Trip_Month: integer (nullable = true)\n",
      " |-- Trip_WeekNumber: integer (nullable = true)\n",
      " |-- Trip_DayofWeek: integer (nullable = true)\n",
      " |-- Trip_Start_Hour: integer (nullable = true)\n",
      " |-- Trip_Start_Minute: integer (nullable = true)\n",
      " |-- Trip_End_Hour: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df = p_df.drop('Pickup_Census_Tract',\n",
    "             'Dropoff_Census_Tract',\n",
    "             'Pickup_Centroid_Latitude',\n",
    "             'Pickup_Centroid_Longitude', \n",
    "             'Pickup_Centroid_Location', \n",
    "             'Dropoff_Centroid_Latitude', \n",
    "             'Dropoff_Centroid_Longitude', \n",
    "             'Dropoff_Centroid_Location',\n",
    "             'Day_Month_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip_ID: string (nullable = true)\n",
      " |-- Trip_Seconds: integer (nullable = true)\n",
      " |-- Trip_Miles: double (nullable = true)\n",
      " |-- Pickup_Community_Area: integer (nullable = true)\n",
      " |-- Dropoff_Community_Area: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: double (nullable = true)\n",
      " |-- Additional_Charges_str: double (nullable = true)\n",
      " |-- Trip_Total: double (nullable = true)\n",
      " |-- Shared_Trip_Authorized: boolean (nullable = true)\n",
      " |-- Trips_Pooled: integer (nullable = true)\n",
      " |-- Trip_Start_Timestamp: timestamp (nullable = true)\n",
      " |-- Trip_End_Timestamp: timestamp (nullable = true)\n",
      " |-- PostShutdownFlag: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- Trip_Year: integer (nullable = true)\n",
      " |-- Trip_Month: integer (nullable = true)\n",
      " |-- Trip_WeekNumber: integer (nullable = true)\n",
      " |-- Trip_DayofWeek: integer (nullable = true)\n",
      " |-- Trip_Start_Hour: integer (nullable = true)\n",
      " |-- Trip_Start_Minute: integer (nullable = true)\n",
      " |-- Trip_End_Hour: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------+\n",
      "|Pickup_Community_Area| count|\n",
      "+---------------------+------+\n",
      "|                   31| 53670|\n",
      "|                   65| 10567|\n",
      "|                   53| 10712|\n",
      "|                   34| 15822|\n",
      "|                   28|402866|\n",
      "|                   76|228152|\n",
      "|                   26| 12039|\n",
      "|                   27| 19081|\n",
      "|                   44| 28113|\n",
      "|                   12|  6564|\n",
      "|                   22|170353|\n",
      "|                   47|  1750|\n",
      "|                 null|354582|\n",
      "|                    1| 58825|\n",
      "|                   52|  2478|\n",
      "|                   13| 10627|\n",
      "|                    6|293132|\n",
      "|                   16| 47734|\n",
      "|                    3|107329|\n",
      "|                   40| 12284|\n",
      "+---------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_df.groupby(\"Pickup_Community_Area\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill our NA community areas\n",
    "\n",
    "p_df = p_df.na.fill(value=78,subset=['Pickup_Community_Area', 'Dropoff_Community_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------+\n",
      "|Pickup_Community_Area| count|\n",
      "+---------------------+------+\n",
      "|                   31| 53670|\n",
      "|                   65| 10567|\n",
      "|                   53| 10712|\n",
      "|                   78|354582|\n",
      "|                   34| 15822|\n",
      "|                   28|402866|\n",
      "|                   76|228152|\n",
      "|                   26| 12039|\n",
      "|                   27| 19081|\n",
      "|                   44| 28113|\n",
      "|                   12|  6564|\n",
      "|                   22|170353|\n",
      "|                   47|  1750|\n",
      "|                    1| 58825|\n",
      "|                   52|  2478|\n",
      "|                   13| 10627|\n",
      "|                    6|293132|\n",
      "|                   16| 47734|\n",
      "|                    3|107329|\n",
      "|                   40| 12284|\n",
      "+---------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_df.groupby(\"Pickup_Community_Area\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original No Tip Count:  1900289\n",
      "Original Tip Count   :  1900435\n"
     ]
    }
   ],
   "source": [
    "# split the data\n",
    "\n",
    "# our model didn't work on the standard test train split.  Prof. Tashman recomended upscalling the help with the imbalanced dataset.\n",
    "#from https://spark.apache.org/docs/2.1.0/ml-tuning.html#train-validation-split\n",
    "\n",
    "train, test = p_df.randomSplit([0.8, 0.2], seed=2021)\n",
    "\n",
    "# cahce our test values for later speed\n",
    "#test.cache()\n",
    "\n",
    "# oversampleing code sample\n",
    "# https://stackoverflow.com/questions/53273133/how-to-perform-up-sampling-using-sample-functionpy-spark\n",
    "\n",
    "org_a_count = train.filter(train['label'] == 0).count()\n",
    "org_b_count = train.filter(train['label'] == 1).count()\n",
    "\n",
    "print(\"Original No Tip Count: \", org_a_count)\n",
    "print(\"Original Tip Count   : \", org_b_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Trip_ID: string, Trip_Seconds: int, Trip_Miles: double, Pickup_Community_Area: int, Dropoff_Community_Area: int, Fare: double, Tip: double, Additional_Charges_str: double, Trip_Total: double, Shared_Trip_Authorized: boolean, Trips_Pooled: int, Trip_Start_Timestamp: timestamp, Trip_End_Timestamp: timestamp, PostShutdownFlag: int, label: int, Trip_Year: int, Trip_Month: int, Trip_WeekNumber: int, Trip_DayofWeek: int, Trip_Start_Hour: int, Trip_Start_Minute: int, Trip_End_Hour: int, Date: date]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.cache()\n",
    "train.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre processing handled the imbalanced dataset.  No further balancing is required.  Cache our datasets for speed.\n",
    "\n",
    "test.cache()\n",
    "train.cache()\n",
    "del (p_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions (UDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def cmacc(pred):\n",
    "    t0 = time.time()\n",
    "    # make a confusion matrix and return the accuracy\n",
    "    # select predictions and labels from prediction transform as rdd as there isn't a DF function for this\n",
    "    pred_rdd= pred.select('prediction').rdd.flatMap(lambda x: x)\n",
    "    label_rdd = pred.select('label').rdd.flatMap(lambda x: x).map(lambda x: float(x))\n",
    "    \n",
    "    #zip them together\n",
    "    predictionAndLabels =  pred_rdd.zip(label_rdd)\n",
    "    \n",
    "    #metrics transform\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    \n",
    "    metrics2 = BinaryClassificationMetrics(predictionAndLabels)\n",
    "    \n",
    "    #make our confusion matrix\n",
    "    cm = metrics.confusionMatrix().toArray()\n",
    "\n",
    "    #calc accuracy from confusion matrix\n",
    "    \n",
    "    acc = (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "    \n",
    "    # McM accuracy\n",
    "    \n",
    "    acc2 = metrics.accuracy\n",
    "    \n",
    "    #calc area under curve\n",
    "    auc = metrics2.areaUnderROC\n",
    "    \n",
    "    prc = metrics2.areaUnderPR\n",
    "    \n",
    "    print(\"Confusion Matrix\")\n",
    "    print(cm)\n",
    "    print()\n",
    "    print(\"Accuracy from Confusion Matrix: \", acc)\n",
    "    print()\n",
    "    print(\"Accuracy from MulticlassMetrics: \", acc2)\n",
    "    print()     \n",
    "    print(\"Area Under the ROC\", auc)\n",
    "    print()\n",
    "    print(\"Area Under the PR Curve\", prc)\n",
    "    print('-'*50)\n",
    "    print(\"Metrics2 time:\", time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix and Accuracy, Extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmacc2(pred, name, trtime):\n",
    "    # make a confusion matrix and return the accuracy\n",
    "    # select predictions and labels from prediction transform as rdd as there isn't a DF function for this\n",
    "    \n",
    " \n",
    "    pred_rdd= pred.select('prediction').rdd.flatMap(lambda x: x)\n",
    "    label_rdd = pred.select('label').rdd.flatMap(lambda x: x).map(lambda x: float(x))\n",
    "\n",
    "    #zip them together\n",
    "    predictionAndLabels =  pred_rdd.zip(label_rdd)\n",
    "    print(\"Zipped P and L\")\n",
    "    \n",
    "    #metrics transform\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    metrics2 = BinaryClassificationMetrics(predictionAndLabels)\n",
    "    print('metrics created')\n",
    "    \n",
    "    #make our confusion matrix\n",
    "    cm = metrics.confusionMatrix().toArray()\n",
    "\n",
    "    #calc accuracy from confusion matrix\n",
    "    acc = (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "    \n",
    "    #McM accuracy\n",
    "    acc2 = metrics.accuracy\n",
    "    \n",
    "    #calc area under curve\n",
    "    auc = metrics2.areaUnderROC\n",
    "    prc = metrics2.areaUnderPR\n",
    "    print('areas under the curve')\n",
    "    \n",
    "    #Precision = TP/TP+FP\n",
    "    precision = metrics.precision()\n",
    "    cmprecision = (cm[0][0])/(cm[0][0] + cm[0][1])\n",
    "    \n",
    "    #Recall = TP/TP+FN\n",
    "    recall = metrics.recall()\n",
    "    cmrecall = (cm[0][0])/(cm[0][0] + cm[1][0])\n",
    "    \n",
    "    #F1 = 2*TP/2*TP +FP+FN or 2* (precision * recall)/(precision+ recall)\n",
    "    f1Score = metrics.fMeasure()\n",
    "    cmf1 = (2*cm[0][0])/(2*cm[0][0] + cm[0][1] + cm[1][0])\n",
    "        \n",
    "    print('-'*50)    \n",
    "    print(\"Confusion Matrix\")\n",
    "    print(cm)\n",
    "    print('-'*50)\n",
    "    print()\n",
    "    print(\"Accuracy from Confusion Matrix: \", acc)\n",
    "    print(\"Accuracy from MulticlassMetrics: \", acc2)\n",
    "    print()\n",
    "    print(\"Area Under the ROC\", auc)\n",
    "    print(\"Area Under the PR Curve\", prc)\n",
    "    print('-'*50)\n",
    "    print()\n",
    "    print(\"Summary Stats\")\n",
    "    print()\n",
    "    print(\"Precision from MulticlassMetrics = %s\" % precision)\n",
    "    print(\"Precision from Confusion Matrix :\", cmprecision)\n",
    "    print()\n",
    "    print(\"Recall from MulticlassMetrics = %s\" % recall)\n",
    "    print(\"Recall from Confusion Matrix :\", cmrecall)\n",
    "    print()\n",
    "    print(\"F1 Score = %s\" % f1Score)\n",
    "    print(\"F1 from Confusion Matrix : \", cmf1)\n",
    "    print()\n",
    "    \n",
    "#     # Weighted stats\n",
    "#     print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "#     print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "#     print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
    "#     print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
    "#     print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)\n",
    "    print('-'*50)\n",
    "#     print(\"Metrics2 time:\", time.time() - t0)\n",
    "# set up storage\n",
    "        \n",
    "    out_list = [name, cm[0][0], cm[1][1], cm[0][1], cm[1][0], acc, auc, prc, cmprecision, cmrecall, cmf1, trtime]\n",
    "    \n",
    "    print(out_list)\n",
    "    pickel_name = name + \".pkl\"\n",
    "    with open(pickel_name, 'wb') as f:\n",
    "        pickle.dump(out_list, f)\n",
    "        \n",
    "    return out_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Basic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding Piplelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding for models (Michael sugested that we didn't need it in each model step)\n",
    "\n",
    "#onehotencoder to pickup\n",
    "ohe_pu = OneHotEncoder(inputCol=\"Pickup_Community_Area\", outputCol=\"Pickup_Community_Area_vec\")\n",
    "\n",
    "#onehotencoder to dropoff\n",
    "ohe_do = OneHotEncoder(inputCol=\"Dropoff_Community_Area\", outputCol=\"Dropoff_Community_Area_vec\")\n",
    "\n",
    "#onehotencoder to weekNumber\n",
    "ohe_twn = OneHotEncoder(inputCol=\"Trip_WeekNumber\", outputCol=\"Trip_WeekNumber_vec\")\n",
    "\n",
    "#onehotencoder to dayOfWeek\n",
    "ohe_dw = OneHotEncoder(inputCol=\"Trip_DayofWeek\", outputCol=\"Trip_DayofWeek_vec\")\n",
    "\n",
    "#onehotencoder to startHour\n",
    "ohe_sh = OneHotEncoder(inputCol=\"Trip_Start_Hour\", outputCol=\"Trip_Start_Hour_vec\")\n",
    "\n",
    "#onehotencoder to startMinute\n",
    "ohe_sm = OneHotEncoder(inputCol=\"Trip_Start_Minute\", outputCol=\"Trip_Start_Minute_vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Pipeline Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "testing\n",
      "Baseline LR Train/Test Time: 45.69\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[229461. 245936.]\n",
      " [149632. 325116.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5836761757415974\n",
      "Accuracy from MulticlassMetrics:  0.5836761757415974\n",
      "\n",
      "Area Under the ROC 0.583745213910684\n",
      "Area Under the PR Curve 0.5583488691324588\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.5836761757415974\n",
      "Precision from Confusion Matrix : 0.48267237698176474\n",
      "\n",
      "Recall from MulticlassMetrics = 0.5836761757415974\n",
      "Recall from Confusion Matrix : 0.6052894672283582\n",
      "\n",
      "F1 Score = 0.5836761757415974\n",
      "F1 from Confusion Matrix :  0.5370712354737914\n",
      "\n",
      "--------------------------------------------------\n",
      "['Baseline_LR', 229461.0, 325116.0, 245936.0, 149632.0, 0.5836761757415974, 0.583745213910684, 0.5583488691324588, 0.48267237698176474, 0.6052894672283582, 0.5370712354737914, 45.69]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Baseline_LR'\n",
    "\n",
    "# our colulms for lr\n",
    "predictor_col_for_lr = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] \n",
    "\n",
    "#assemble the vector for lr\n",
    "lr_va = VectorAssembler(inputCols=predictor_col_for_lr, outputCol=\"features\") \n",
    "\n",
    "#scale our lr\n",
    "lr_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "#what do we want to do if we are doing a parameter search? make the parameters as variables and just do a loop?\n",
    "#we learned that this week.  May also need to add in cv step\n",
    "\n",
    "lr = LogisticRegression(maxIter=10,\n",
    "                        regParam=0.1, #org 0.1\n",
    "                        elasticNetParam=0.3, #org 0.3\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"label\")\n",
    "\n",
    "# Build the pipeline\n",
    "lr_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, lr_va, lr_scaler, lr])\n",
    "\n",
    "#time check\n",
    "t0 = time.time()\n",
    "\n",
    "# Fit the pipeline\n",
    "print(\"training\")\n",
    "lr_model = lr_pipeline.fit(train)\n",
    "\n",
    "# Make a prediction\n",
    "print(\"testing\")\n",
    "lr_prediction = lr_model.transform(test)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "print(\"Baseline LR Train/Test Time:\", tt)\n",
    "\n",
    "train_time = tt.real\n",
    "\n",
    "baseLR = cmacc2(lr_prediction, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baseline_LR',\n",
       " 229461.0,\n",
       " 325116.0,\n",
       " 245936.0,\n",
       " 149632.0,\n",
       " 0.5836761757415974,\n",
       " 0.583745213910684,\n",
       " 0.5583488691324588,\n",
       " 0.48267237698176474,\n",
       " 0.6052894672283582,\n",
       " 0.5370712354737914,\n",
       " 45.69]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Pipeline for Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "testing\n",
      "Baseline RF Test Error = 0.420862\n",
      "Accuracy:  0.5791379210541548\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_aa420fa075d7) with 10 trees\n",
      "Baseline RF Train/Test Time: 36.99\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[386698.  88699.]\n",
      " [311181. 163567.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5791379210541548\n",
      "Accuracy from MulticlassMetrics:  0.5791379210541548\n",
      "\n",
      "Area Under the ROC 0.5789777836228537\n",
      "Area Under the PR Curve 0.5996464591438725\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.5791379210541548\n",
      "Precision from Confusion Matrix : 0.8134212037518116\n",
      "\n",
      "Recall from MulticlassMetrics = 0.5791379210541548\n",
      "Recall from Confusion Matrix : 0.5541046513793938\n",
      "\n",
      "F1 Score = 0.5791379210541548\n",
      "F1 from Confusion Matrix :  0.6591765279439791\n",
      "\n",
      "--------------------------------------------------\n",
      "['Baseline_RF', 386698.0, 163567.0, 88699.0, 311181.0, 0.5791379210541548, 0.5789777836228537, 0.5996464591438725, 0.8134212037518116, 0.5541046513793938, 0.6591765279439791, 36.99]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Baseline_RF'\n",
    "\n",
    "# our colulms for rf\n",
    "predictor_col_for_rf = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "# assemble feature vector\n",
    "rf_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "\n",
    "# set classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \n",
    "                            featuresCol=\"features\", \n",
    "                            numTrees=10)\n",
    "\n",
    "# Build the pipeline\n",
    "rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, rf_va, rf])\n",
    "\n",
    "#time check\n",
    "t0 = time.time()\n",
    "\n",
    "# Fit the pipeline\n",
    "print(\"training\")\n",
    "rf_model = rf_pipeline.fit(train)\n",
    "\n",
    "# Make a prediction\n",
    "print(\"testing\")\n",
    "rf_prediction = rf_model.transform(test)\n",
    "t1 = time.time()\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "rf_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "#metric options f1|accuracy|weightedPrecision|weightedRecall\n",
    "\n",
    "rf_accuracy = rf_evaluator.evaluate(rf_prediction)\n",
    "\n",
    "print(\"Baseline RF Test Error = %g\" % (1.0 - rf_accuracy))\n",
    "print(\"Accuracy: \" , rf_accuracy)\n",
    "\n",
    "rfModel2 = rf_model.stages[7]\n",
    "print(rfModel2)  # summary only\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "\n",
    "print(\"Baseline RF Train/Test Time:\", train_time)\n",
    "\n",
    "baseRF = cmacc2(rf_prediction, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baseline_RF',\n",
       " 386698.0,\n",
       " 163567.0,\n",
       " 88699.0,\n",
       " 311181.0,\n",
       " 0.5791379210541548,\n",
       " 0.5789777836228537,\n",
       " 0.5996464591438725,\n",
       " 0.8134212037518116,\n",
       " 0.5541046513793938,\n",
       " 0.6591765279439791,\n",
       " 36.99]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseRF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Pipeline for Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "testing\n",
      "GBT Baseline Train/Test Time: 140.71\n",
      "GBT Test Error = 0.400582\n",
      "GBT accuracy =  0.5994179835709287\n",
      "GBTClassificationModel (uid=GBTClassifier_23fe0c1bcbf8) with 5 trees\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[330590. 144807.]\n",
      " [235804. 238944.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5994179835709287\n",
      "Accuracy from MulticlassMetrics:  0.5994179835709287\n",
      "\n",
      "Area Under the ROC 0.5993523794370115\n",
      "Area Under the PR Curve 0.5921083061039066\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.5994179835709287\n",
      "Precision from Confusion Matrix : 0.6953977412562553\n",
      "\n",
      "Recall from MulticlassMetrics = 0.5994179835709287\n",
      "Recall from Confusion Matrix : 0.5836749683082801\n",
      "\n",
      "F1 Score = 0.5994179835709287\n",
      "F1 from Confusion Matrix :  0.6346570473348301\n",
      "\n",
      "--------------------------------------------------\n",
      "['Baseline_GBT', 330590.0, 238944.0, 144807.0, 235804.0, 0.5994179835709287, 0.5993523794370115, 0.5921083061039066, 0.6953977412562553, 0.5836749683082801, 0.6346570473348301, 140.71]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Baseline_GBT'\n",
    "\n",
    "# our colulms for gbt\n",
    "predictor_col_for_gbt = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "gbt_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "\n",
    "# set classifier\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=5)\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "gbt_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, gbt_va, gbt]) #labelIndexer, featureIndexer\n",
    "\n",
    "#time check\n",
    "t0 = time.time()\n",
    "\n",
    "# Train model.\n",
    "gbt_model = gbt_pipeline.fit(train)\n",
    "print('training')\n",
    "\n",
    "# Make predictions.\n",
    "gbt_prediction = gbt_model.transform(test)\n",
    "print('testing')\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "\n",
    "print(\"GBT Baseline Train/Test Time:\", train_time)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "gbt_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "gbt_accuracy = gbt_evaluator.evaluate(gbt_prediction)\n",
    "print(\"GBT Test Error = %g\" % (1.0 - gbt_accuracy))\n",
    "print('GBT accuracy = ', gbt_accuracy)\n",
    "gbtModel = gbt_model.stages[7]\n",
    "print(gbtModel)  # summary only\n",
    "\n",
    "baseGBT = cmacc2(gbt_prediction, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baseline_GBT',\n",
       " 330590.0,\n",
       " 238944.0,\n",
       " 144807.0,\n",
       " 235804.0,\n",
       " 0.5994179835709287,\n",
       " 0.5993523794370115,\n",
       " 0.5921083061039066,\n",
       " 0.6953977412562553,\n",
       " 0.5836749683082801,\n",
       " 0.6346570473348301,\n",
       " 140.71]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseGBT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline LR with Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(lr_paramGrid): 18\n",
      "train/cv\n",
      "test\n",
      "LR with Tuning Train Time: 2802.17\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[249532. 225865.]\n",
      " [133521. 341227.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.6217566792436944\n",
      "Accuracy from MulticlassMetrics:  0.6217566792436944\n",
      "\n",
      "Area Under the ROC 0.6218228883577326\n",
      "Area Under the PR Curve 0.587362346525713\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.6217566792436944\n",
      "Precision from Confusion Matrix : 0.5248918272517495\n",
      "\n",
      "Recall from MulticlassMetrics = 0.6217566792436944\n",
      "Recall from Confusion Matrix : 0.6514294366575905\n",
      "\n",
      "F1 Score = 0.6217566792436944\n",
      "F1 from Confusion Matrix :  0.5813547673131807\n",
      "\n",
      "--------------------------------------------------\n",
      "['Tuned_LR', 249532.0, 341227.0, 225865.0, 133521.0, 0.6217566792436944, 0.6218228883577326, 0.587362346525713, 0.5248918272517495, 0.6514294366575905, 0.5813547673131807, 2802.17]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Tuned_LR'\n",
    "\n",
    "# our colulms for lr\n",
    "predictor_col_for_lr = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "#assemble the vector or LR\n",
    "\n",
    "lr_va = VectorAssembler(inputCols=predictor_col_for_lr, outputCol=\"features\") \n",
    "\n",
    "#scale our LR\n",
    "\n",
    "lr_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "#classifier\n",
    "lr = LogisticRegression(featuresCol=\"features\",\n",
    "                        labelCol=\"label\") # regParam=0.1, elasticNetParam=0.3, maxIter=10,\n",
    "\n",
    "# Build the pipeline\n",
    "lr_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, lr_va, lr_scaler, lr])\n",
    "\n",
    "# Set up the parameter grid\n",
    "lr_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.03, 0.05]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.1, 0.2, 0.3]) \\\n",
    "    .addGrid(lr.maxIter, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "print('len(lr_paramGrid): {}'.format(len(lr_paramGrid)))\n",
    "\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "print('train/cv')\n",
    "lr_crossval = CrossValidator(estimator=lr_pipeline,\n",
    "                          estimatorParamMaps=lr_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='accuracy'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "\n",
    "t0 = time.time()\n",
    "lr_cvModel = lr_crossval.setParallelism(6).fit(train) # train 6 models in parallel\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on test samples. cvModel uses the best model found (lrModel).\n",
    "print('test')\n",
    "lr_prediction = lr_cvModel.transform(test)\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "print(\"LR with Tuning Train Time:\", tt)\n",
    "\n",
    "TunedLR = cmacc2(lr_prediction, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to find all our items we can call\n",
    "#dir(crossval.evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6194283737675219,\n",
       " 0.6224362826542406,\n",
       " 0.6181530519717919,\n",
       " 0.6218402715625112,\n",
       " 0.616500845340373,\n",
       " 0.6209620777088064,\n",
       " 0.6167186798392326,\n",
       " 0.6207941988042414,\n",
       " 0.6106633790174401,\n",
       " 0.6157819085692713,\n",
       " 0.605309132496221,\n",
       " 0.6112286522444648,\n",
       " 0.6128175788913547,\n",
       " 0.6174757102736057,\n",
       " 0.6034002443327627,\n",
       " 0.6102014362484179,\n",
       " 0.5951620382133644,\n",
       " 0.5975182165411108]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model RMSE https://projector-video-pdf-converter.datacamp.com/14989/chapter4.pdf\n",
    "lr_cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_7718124355ae', name='regParam', doc='regularization parameter (>= 0).'): 0.05,\n",
       " Param(parent='LogisticRegression_7718124355ae', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3,\n",
       " Param(parent='LogisticRegression_7718124355ae', name='maxIter', doc='max number of iterations (>= 0).'): 5}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#determine paramaters of best model\n",
    "#https://dsharpc.github.io/SparkMLFlights/\n",
    "\n",
    "lr_cvModel.getEstimatorParamMaps()[ np.argmin(lr_cvModel.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline RF with Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(rf_paramGrid): 9\n",
      "train/cv\n",
      "test\n",
      "RF with Tuning Train Time: 2139.76\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[300575. 174822.]\n",
      " [198098. 276650.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.6075125375600566\n",
      "Accuracy from MulticlassMetrics:  0.6075125375600566\n",
      "\n",
      "Area Under the ROC 0.6074956214531385\n",
      "Area Under the PR Curve 0.5891736220420802\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.6075125375600566\n",
      "Precision from Confusion Matrix : 0.6322610365652287\n",
      "\n",
      "Recall from MulticlassMetrics = 0.6075125375600566\n",
      "Recall from Confusion Matrix : 0.6027496976976897\n",
      "\n",
      "F1 Score = 0.6075125375600566\n",
      "F1 from Confusion Matrix :  0.6171527713614011\n",
      "\n",
      "--------------------------------------------------\n",
      "['Tuned_RF', 300575.0, 276650.0, 174822.0, 198098.0, 0.6075125375600566, 0.6074956214531385, 0.5891736220420802, 0.6322610365652287, 0.6027496976976897, 0.6171527713614011, 2139.76]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Tuned_RF'\n",
    "\n",
    "# our colulms for rf\n",
    "predictor_col_for_rf = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "# assemble feature vector\n",
    "rf_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "               \n",
    "# set classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \n",
    "                            featuresCol=\"features\")\n",
    "    \n",
    "# Build the pipeline\n",
    "rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, rf_va, rf])\n",
    "\n",
    "# Set up the parameter grid\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5, 10, 15]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "#\"entropy\"\n",
    "#.addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt'])\\\n",
    "#.addGrid(rf.impurity, [\"gini\"])\\\n",
    "   \n",
    "print('len(rf_paramGrid): {}'.format(len(rf_paramGrid)))\n",
    "\n",
    "#https://medium.com/rahasak/random-forest-classifier-with-apache-spark-c63b4a23a7cc\n",
    "#maxDepth, maxBins, impurity, auto and seed \n",
    "#.addGrid(randomForestClassifier.impurity, Array(\"entropy\", \"gini\"))\n",
    "#name='featureSubsetStrategy', auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n]\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "print('train/cv')\n",
    "rf_crossval = CrossValidator(estimator=rf_pipeline,\n",
    "                          estimatorParamMaps=rf_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='accuracy'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "t0 = time.time()\n",
    "cvModel_rf = rf_crossval.setParallelism(6).fit(train) # train 6 models in parallel\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "print('test')\n",
    "prediction_rf = cvModel_rf.transform(test)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "\n",
    "print(\"RF with Tuning Train Time:\", tt)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction_rf = cvModel_rf.transform(test)\n",
    "\n",
    "TunedRF = cmacc2(prediction_rf, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tuned_RF',\n",
       " 300575.0,\n",
       " 276650.0,\n",
       " 174822.0,\n",
       " 198098.0,\n",
       " 0.6075125375600566,\n",
       " 0.6074956214531385,\n",
       " 0.5891736220420802,\n",
       " 0.6322610365652287,\n",
       " 0.6027496976976897,\n",
       " 0.6171527713614011,\n",
       " 2139.76]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TunedRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to find all our items we can call\n",
    "#dir(crossval.evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5825131156098341,\n",
       " 0.5958324256057238,\n",
       " 0.602175883862726,\n",
       " 0.5922419755155239,\n",
       " 0.6012466458538751,\n",
       " 0.6066200613120694,\n",
       " 0.5989367972336797,\n",
       " 0.6017959018064258,\n",
       " 0.6085601252194357]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not sure what this metric is... rmse\n",
    "cvModel_rf.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_843dd99022c4', name='numTrees', doc='Number of trees to train (>= 1).'): 5,\n",
       " Param(parent='RandomForestClassifier_843dd99022c4', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best model paramaters from lowest RMSE\n",
    "\n",
    "cvModel_rf.getEstimatorParamMaps()[ np.argmin(cvModel_rf.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(rf_paramGrid): 8\n",
      "train/cv\n",
      "test\n",
      "RF with Tuning Train Time: 1176.05\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[330540. 144857.]\n",
      " [239087. 235661.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5959100979324209\n",
      "Accuracy from MulticlassMetrics:  0.5959100979324209\n",
      "\n",
      "Area Under the ROC 0.5958421679761307\n",
      "Area Under the PR Curve 0.5891859671197659\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.5959100979324209\n",
      "Precision from Confusion Matrix : 0.6952925660027304\n",
      "\n",
      "Recall from MulticlassMetrics = 0.5959100979324209\n",
      "Recall from Confusion Matrix : 0.5802744603047257\n",
      "\n",
      "F1 Score = 0.5959100979324209\n",
      "F1 from Confusion Matrix :  0.63259791162691\n",
      "\n",
      "--------------------------------------------------\n",
      "['Tuned_RF2', 330540.0, 235661.0, 144857.0, 239087.0, 0.5959100979324209, 0.5958421679761307, 0.5891859671197659, 0.6952925660027304, 0.5802744603047257, 0.63259791162691, 1176.05]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Tuned_RF2'\n",
    "\n",
    "# our colulms for rf\n",
    "predictor_col_for_rf = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "# assemble feature vector\n",
    "rf_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "               \n",
    "# set classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \n",
    "                            featuresCol=\"features\")\n",
    "    \n",
    "# Build the pipeline\n",
    "rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, rf_va, rf])\n",
    "\n",
    "#parameter grid\n",
    "rf_paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(rf.numTrees, [5, 10])\\\n",
    "    .addGrid(rf.maxDepth, [5, 7])\\\n",
    "    .addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt'])\\\n",
    "    .build()\n",
    "   \n",
    "print('len(rf_paramGrid): {}'.format(len(rf_paramGrid)))\n",
    "\n",
    "#https://medium.com/rahasak/random-forest-classifier-with-apache-spark-c63b4a23a7cc\n",
    "#maxDepth, maxBins, impurity, auto and seed \n",
    "#.addGrid(randomForestClassifier.impurity, Array(\"entropy\", \"gini\"))\n",
    "#name='featureSubsetStrategy', auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n]\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "print('train/cv')\n",
    "rf_crossval = CrossValidator(estimator=rf_pipeline,\n",
    "                          estimatorParamMaps=rf_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='accuracy'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "t0 = time.time()\n",
    "cvModel_rf = rf_crossval.setParallelism(6).fit(train) # train 6 models in parallel\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "print('test')\n",
    "prediction_rf = cvModel_rf.transform(test)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "\n",
    "print(\"RF with Tuning Train Time:\", tt)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction_rf = cvModel_rf.transform(test)\n",
    "\n",
    "TunedRF2 = cmacc2(prediction_rf, model_name, train_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5825131156098341,\n",
       " 0.5825131156098341,\n",
       " 0.5878206863283116,\n",
       " 0.5878206863283116,\n",
       " 0.5922419755155239,\n",
       " 0.5922419755155239,\n",
       " 0.5956492373951481,\n",
       " 0.5956492373951481]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not sure what this metric is... rmse\n",
    "cvModel_rf.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_61143016ec7c', name='numTrees', doc='Number of trees to train (>= 1).'): 5,\n",
       " Param(parent='RandomForestClassifier_61143016ec7c', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       " Param(parent='RandomForestClassifier_61143016ec7c', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto'}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best model paramaters from lowest RMSE\n",
    "\n",
    "cvModel_rf.getEstimatorParamMaps()[ np.argmin(cvModel_rf.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # our colulms for rf\n",
    "# predictor_col_for_rf = ['Trip_Seconds',\n",
    "#                         'Trip_Miles',\n",
    "#                         'Fare',\n",
    "#                         'Additional_Charges_str',\n",
    "#                         'Shared_Trip_Authorized',\n",
    "#                         'Trips_Pooled',\n",
    "#                         'Pickup_Community_Area_vec',\n",
    "#                         'Dropoff_Community_Area_vec',\n",
    "#                         'Trip_Year', \n",
    "#                         'Trip_Month',\n",
    "#                         'Trip_WeekNumber_vec', \n",
    "#                         'Trip_DayofWeek_vec', \n",
    "#                         'Trip_Start_Hour_vec',\n",
    "#                         'Trip_Start_Minute_vec',\n",
    "#                         'PostShutdownFlag'\n",
    "#                         ] # 'Date' not supported datatype\n",
    "\n",
    "# # assemble feature vector\n",
    "# rf_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "               \n",
    "# # set classifier\n",
    "# rf = RandomForestClassifier(labelCol=\"label\", \n",
    "#                             featuresCol=\"features\")\n",
    "    \n",
    "# # Build the pipeline\n",
    "# rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, rf_va, rf])\n",
    "\n",
    "# # Set up the parameter grid\n",
    "# rf_paramGrid = ParamGridBuilder() \\\n",
    "#     .addGrid(rf.numTrees, [7, 8, 9]) \\\n",
    "#     .addGrid(rf.maxDepth, [3, 5]) \\\n",
    "#     .addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt'])\\\n",
    "#     .build()\n",
    "# #\"entropy\"\n",
    "# #.addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt'])\\\n",
    "# #.addGrid(rf.impurity, [\"gini\"])\\    \n",
    "    \n",
    "# print('len(rf_paramGrid): {}'.format(len(rf_paramGrid)))\n",
    "\n",
    "# #https://medium.com/rahasak/random-forest-classifier-with-apache-spark-c63b4a23a7cc\n",
    "# #maxDepth, maxBins, impurity, auto and seed \n",
    "# #.addGrid(randomForestClassifier.impurity, Array(\"entropy\", \"gini\"))\n",
    "# #name='featureSubsetStrategy', auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n]\n",
    "\n",
    "# # Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "# rf_crossval = CrossValidator(estimator=rf_pipeline,\n",
    "#                           estimatorParamMaps=rf_paramGrid,\n",
    "#                           #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "#                           evaluator= MulticlassClassificationEvaluator(metricName='accuracy'),\n",
    "#                           numFolds=5)\n",
    "\n",
    "# # you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# # we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# # f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# # Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "# t0 = time.time()\n",
    "# cvModel_rf = rf_crossval.setParallelism(6).fit(train) # train 6 models in parallel\n",
    "\n",
    "# # Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "# prediction_rf = cvModel_rf.transform(test)\n",
    "\n",
    "# t1 = time.time()\n",
    "\n",
    "# tt = round(t1-t0, 2)\n",
    "# train_time = tt.real\n",
    "\n",
    "# # Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "# prediction_rf = cvModel_rf.transform(test)\n",
    "\n",
    "# print(\"RF with Tuning Train Time:\", tt)\n",
    "\n",
    "# # Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "# prediction_rf = cvModel_rf.transform(test)\n",
    "\n",
    "# TunedRF3 = cmacc2(prediction_rf, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmacc2(prediction_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not sure what this metric is... rmse\n",
    "# cvModel_rf.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best model paramaters from lowest RMSE\n",
    "\n",
    "# cvModel_rf.getEstimatorParamMaps()[ np.argmin(cvModel_rf.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline GBT with Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBT was run once on the full dataset.  Due to its long modeling time it was elimiated as a canidate as its accuracy did not warrent the long compute times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(gbt_paramGrid): 4\n",
      "train\n",
      "test\n",
      "GBT with Tuning Train Time: 4730.53\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[308359. 167038.]\n",
      " [202505. 272243.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.6110667319198648\n",
      "Accuracy from MulticlassMetrics:  0.6110667319198648\n",
      "\n",
      "Area Under the ROC 0.6110410534290801\n",
      "Area Under the PR Curve 0.5941348158462253\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.6110667319198648\n",
      "Precision from Confusion Matrix : 0.6486347200339927\n",
      "\n",
      "Recall from MulticlassMetrics = 0.6110667319198648\n",
      "Recall from Confusion Matrix : 0.6036029158445301\n",
      "\n",
      "F1 Score = 0.6110667319198648\n",
      "F1 from Confusion Matrix :  0.6253091220275363\n",
      "\n",
      "--------------------------------------------------\n",
      "['Tuned_GBT', 308359.0, 272243.0, 167038.0, 202505.0, 0.6110667319198648, 0.6110410534290801, 0.5941348158462253, 0.6486347200339927, 0.6036029158445301, 0.6253091220275363, 4730.53]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Tuned_GBT\"\n",
    "\n",
    "# our colulms for gbt\n",
    "predictor_col_for_gbt = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "gbt_va = VectorAssembler(inputCols=predictor_col_for_gbt, outputCol=\"features\") \n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\") #, maxIter=5\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "gbt_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, gbt_va, gbt]) #labelIndexer, featureIndexer\n",
    "\n",
    "# Set up the parameter grid\n",
    "gbt_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [5, 10])\\\n",
    "    .addGrid(gbt.maxDepth, [5, 10])\\\n",
    "    .build()\n",
    "\n",
    "print('len(gbt_paramGrid): {}'.format(len(gbt_paramGrid)))\n",
    "\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "gbt_crossval = CrossValidator(estimator=gbt_pipeline,\n",
    "                          estimatorParamMaps=gbt_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='accuracy'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "print(\"train\")\n",
    "t0 = time.time()\n",
    "cvModel_gbt = gbt_crossval.setParallelism(6).fit(train) # train 6 models in parallel\n",
    "\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "print(\"test\")\n",
    "prediction_gbt = cvModel_gbt.transform(test)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "\n",
    "print(\"GBT with Tuning Train Time:\", tt)\n",
    "\n",
    "TunedGBT = cmacc2(prediction_gbt, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmacc2(prediction_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5957517745394241, 0.6061715229833419, 0.601215551820927, 0.6117324917795979]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not sure what this metric is...\n",
    "cvModel_gbt.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='GBTClassifier_b175a4e3576b', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       " Param(parent='GBTClassifier_b175a4e3576b', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best paramaters\n",
    "cvModel_gbt.getEstimatorParamMaps()[np.argmin(cvModel_gbt.avgMetrics)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline LR with CV and no Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify Gridsearch results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(lr_paramGrid): 1\n",
      "train\n",
      "train time: 152.51662230491638\n",
      "test\n",
      "LR with CV, no tuning, train time: 153.83\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[288388. 187009.]\n",
      " [179953. 294795.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.6137831594125107\n",
      "Accuracy from MulticlassMetrics:  0.6137831594125107\n",
      "\n",
      "Area Under the ROC 0.6137880517373892\n",
      "Area Under the PR Curve 0.5905923489395983\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.6137831594125107\n",
      "Precision from Confusion Matrix : 0.6066256202710577\n",
      "\n",
      "Recall from MulticlassMetrics = 0.6137831594125107\n",
      "Recall from Confusion Matrix : 0.615765008829037\n",
      "\n",
      "F1 Score = 0.6137831594125107\n",
      "F1 from Confusion Matrix :  0.6111611485391073\n",
      "\n",
      "--------------------------------------------------\n",
      "['CV_LR', 288388.0, 294795.0, 187009.0, 179953.0, 0.6137831594125107, 0.6137880517373892, 0.5905923489395983, 0.6066256202710577, 0.615765008829037, 0.6111611485391073, 153.83]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'CV_LR'\n",
    "\n",
    "# our colulms for lr\n",
    "predictor_col_for_lr = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "#assemble the vector ror lr\n",
    "lr_va = VectorAssembler(inputCols=predictor_col_for_lr, outputCol=\"features\") \n",
    "\n",
    "#scale our LR\n",
    "\n",
    "lr_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "#what do we want to do if we are doing a parameter search? make the parameters as variables and just do a loop?\n",
    "#we learned that this week.  May also need to add in cv step\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\",\n",
    "                        labelCol=\"label\") # regParam=0.1, elasticNetParam=0.3, maxIter=10,\n",
    "\n",
    "# Build the pipeline\n",
    "lr_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, lr_va, lr_scaler, lr])\n",
    "\n",
    "# Set up the parameter grid\n",
    "lr_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.03]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.15]) \\\n",
    "    .addGrid(lr.maxIter, [5]) \\\n",
    "    .build()\n",
    "\n",
    "print('len(lr_paramGrid): {}'.format(len(lr_paramGrid)))\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "lr_crossval = CrossValidator(estimator=lr_pipeline,\n",
    "                          estimatorParamMaps=lr_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='accuracy'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "print(\"train\")\n",
    "t0 = time.time()\n",
    "lr_cvModel = lr_crossval.setParallelism(5).fit(train) # train 5 models in parallel\n",
    "print(\"train time:\", time.time() - t0)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "print(\"test\")\n",
    "lr_prediction = lr_cvModel.transform(test)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "\n",
    "print(\"LR with CV, no tuning, train time:\", tt)\n",
    "\n",
    "CVLR = cmacc2(lr_prediction, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6135890507750584]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model RMSE https://projector-video-pdf-converter.datacamp.com/14989/chapter4.pdf\n",
    "lr_cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_9ff09e9f50c6', name='regParam', doc='regularization parameter (>= 0).'): 0.03,\n",
       " Param(parent='LogisticRegression_9ff09e9f50c6', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.15,\n",
       " Param(parent='LogisticRegression_9ff09e9f50c6', name='maxIter', doc='max number of iterations (>= 0).'): 5}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#determine paramaters of best model\n",
    "#https://dsharpc.github.io/SparkMLFlights/\n",
    "\n",
    "lr_cvModel.getEstimatorParamMaps()[ np.argmin(lr_cvModel.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline RF with CV and no Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify Gridsearch results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(rf_paramGrid): 1\n",
      "train\n",
      "test\n",
      "LR with CV, no tuning, train time: 179.75\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[310427. 164970.]\n",
      " [221186. 253562.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5935820322161355\n",
      "Accuracy from MulticlassMetrics:  0.5935820322161355\n",
      "\n",
      "Area Under the ROC 0.5935414292269063\n",
      "Area Under the PR Curve 0.5811022968589641\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.5935820322161355\n",
      "Precision from Confusion Matrix : 0.6529847685197845\n",
      "\n",
      "Recall from MulticlassMetrics = 0.5935820322161355\n",
      "Recall from Confusion Matrix : 0.5839341776818852\n",
      "\n",
      "F1 Score = 0.5935820322161355\n",
      "F1 from Confusion Matrix :  0.6165321099095342\n",
      "\n",
      "--------------------------------------------------\n",
      "['CV_RF', 310427.0, 253562.0, 164970.0, 221186.0, 0.5935820322161355, 0.5935414292269063, 0.5811022968589641, 0.6529847685197845, 0.5839341776818852, 0.6165321099095342, 179.75]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'CV_RF'\n",
    "\n",
    "# our colulms for rf\n",
    "predictor_col_for_rf = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ]\n",
    "\n",
    "# assemble feature vector\n",
    "rf_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "\n",
    "# set classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \n",
    "                            featuresCol=\"features\")\n",
    "\n",
    "# # Build the pipeline\n",
    "# rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, rf_va, rf])\n",
    "\n",
    "# Build the pipeline\n",
    "rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, rf_va, rf])\n",
    "\n",
    "# Set up the parameter grid\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5]) \\\n",
    "    .addGrid(rf.maxDepth, [5]) \\\n",
    "    .addGrid(rf.impurity, [\"gini\"])\\\n",
    "    .addGrid(rf.featureSubsetStrategy, ['auto'])\\\n",
    "    .build()\n",
    "   \n",
    "    \n",
    "\n",
    "print('len(rf_paramGrid): {}'.format(len(rf_paramGrid)))\n",
    "\n",
    "#https://medium.com/rahasak/random-forest-classifier-with-apache-spark-c63b4a23a7cc\n",
    "#maxDepth, maxBins, impurity, auto and seed \n",
    "#.addGrid(randomForestClassifier.impurity, Array(\"entropy\", \"gini\"))\n",
    "#name='featureSubsetStrategy', auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n]\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "rf_crossval = CrossValidator(estimator=rf_pipeline,\n",
    "                          estimatorParamMaps=rf_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='accuracy'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "print(\"train\")\n",
    "t0 = time.time()\n",
    "cvModel_rf = rf_crossval.setParallelism(5).fit(train) # train 5 models in parallel\n",
    "\n",
    "# Make predictions on test documents. \n",
    "print(\"test\")\n",
    "prediction_rf = cvModel_rf.transform(test)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "\n",
    "print(\"LR with CV, no tuning, train time:\", tt)\n",
    "\n",
    "CVLR = cmacc2(prediction_rf, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to find all our items we can call\n",
    "#dir(crossval.evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5756806178239793]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not sure what this metric is... rmse\n",
    "cvModel_rf.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_571ac3a79554', name='numTrees', doc='Number of trees to train (>= 1).'): 5,\n",
       " Param(parent='RandomForestClassifier_571ac3a79554', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       " Param(parent='RandomForestClassifier_571ac3a79554', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       " Param(parent='RandomForestClassifier_571ac3a79554', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#paramaters\n",
    "\n",
    "cvModel_rf.getEstimatorParamMaps()[ np.argmin(cvModel_rf.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Matrix of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = ['Baseline_LR.pkl', 'Baseline_RF.pkl', 'Baseline_GBT.pkl', 'Tuned_LR.pkl', 'Tuned_RF.pkl', 'Tuned_RF2.pkl', 'Tuned_GBT.pkl', 'CV_LR.pkl', 'CV_RF.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out = pd.DataFrame(columns=['model_name', 'TP', 'TN', 'FP', 'FN', 'Accuracy', 'AUROC', 'AUPR', 'Precision', 'Recall', 'F1']) #, index=index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline_LR.pkl\n",
      "['Baseline_LR', 229461.0, 325116.0, 245936.0, 149632.0, 0.5836761757415974, 0.583745213910684, 0.5583488691324588, 0.48267237698176474, 0.6052894672283582, 0.5370712354737914, 45.69]\n",
      "    model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0  Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "Baseline_RF.pkl\n",
      "['Baseline_RF', 386698.0, 163567.0, 88699.0, 311181.0, 0.5791379210541548, 0.5789777836228537, 0.5996464591438725, 0.8134212037518116, 0.5541046513793938, 0.6591765279439791, 36.99]\n",
      "    model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0  Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0  Baseline_RF  386698.0  163567.0   88699.0  311181.0  0.579138  0.578978   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.599646   0.813421  0.554105  0.659177            36.99  \n",
      "Baseline_GBT.pkl\n",
      "['Baseline_GBT', 330590.0, 238944.0, 144807.0, 235804.0, 0.5994179835709287, 0.5993523794370115, 0.5921083061039066, 0.6953977412562553, 0.5836749683082801, 0.6346570473348301, 140.71]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  386698.0  163567.0   88699.0  311181.0  0.579138  0.578978   \n",
      "0  Baseline_GBT  330590.0  238944.0  144807.0  235804.0  0.599418  0.599352   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.599646   0.813421  0.554105  0.659177            36.99  \n",
      "0  0.592108   0.695398  0.583675  0.634657           140.71  \n",
      "Tuned_LR.pkl\n",
      "['Tuned_LR', 249532.0, 341227.0, 225865.0, 133521.0, 0.6217566792436944, 0.6218228883577326, 0.587362346525713, 0.5248918272517495, 0.6514294366575905, 0.5813547673131807, 2802.17]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  386698.0  163567.0   88699.0  311181.0  0.579138  0.578978   \n",
      "0  Baseline_GBT  330590.0  238944.0  144807.0  235804.0  0.599418  0.599352   \n",
      "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.599646   0.813421  0.554105  0.659177            36.99  \n",
      "0  0.592108   0.695398  0.583675  0.634657           140.71  \n",
      "0  0.587362   0.524892  0.651429  0.581355          2802.17  \n",
      "Tuned_RF.pkl\n",
      "['Tuned_RF', 300575.0, 276650.0, 174822.0, 198098.0, 0.6075125375600566, 0.6074956214531385, 0.5891736220420802, 0.6322610365652287, 0.6027496976976897, 0.6171527713614011, 2139.76]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  386698.0  163567.0   88699.0  311181.0  0.579138  0.578978   \n",
      "0  Baseline_GBT  330590.0  238944.0  144807.0  235804.0  0.599418  0.599352   \n",
      "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
      "0      Tuned_RF  300575.0  276650.0  174822.0  198098.0  0.607513  0.607496   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.599646   0.813421  0.554105  0.659177            36.99  \n",
      "0  0.592108   0.695398  0.583675  0.634657           140.71  \n",
      "0  0.587362   0.524892  0.651429  0.581355          2802.17  \n",
      "0  0.589174   0.632261  0.602750  0.617153          2139.76  \n",
      "Tuned_RF2.pkl\n",
      "['Tuned_RF2', 330540.0, 235661.0, 144857.0, 239087.0, 0.5959100979324209, 0.5958421679761307, 0.5891859671197659, 0.6952925660027304, 0.5802744603047257, 0.63259791162691, 1176.05]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  386698.0  163567.0   88699.0  311181.0  0.579138  0.578978   \n",
      "0  Baseline_GBT  330590.0  238944.0  144807.0  235804.0  0.599418  0.599352   \n",
      "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
      "0      Tuned_RF  300575.0  276650.0  174822.0  198098.0  0.607513  0.607496   \n",
      "0     Tuned_RF2  330540.0  235661.0  144857.0  239087.0  0.595910  0.595842   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.599646   0.813421  0.554105  0.659177            36.99  \n",
      "0  0.592108   0.695398  0.583675  0.634657           140.71  \n",
      "0  0.587362   0.524892  0.651429  0.581355          2802.17  \n",
      "0  0.589174   0.632261  0.602750  0.617153          2139.76  \n",
      "0  0.589186   0.695293  0.580274  0.632598          1176.05  \n",
      "Tuned_GBT.pkl\n",
      "['Tuned_GBT', 308359.0, 272243.0, 167038.0, 202505.0, 0.6110667319198648, 0.6110410534290801, 0.5941348158462253, 0.6486347200339927, 0.6036029158445301, 0.6253091220275363, 4730.53]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  386698.0  163567.0   88699.0  311181.0  0.579138  0.578978   \n",
      "0  Baseline_GBT  330590.0  238944.0  144807.0  235804.0  0.599418  0.599352   \n",
      "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
      "0      Tuned_RF  300575.0  276650.0  174822.0  198098.0  0.607513  0.607496   \n",
      "0     Tuned_RF2  330540.0  235661.0  144857.0  239087.0  0.595910  0.595842   \n",
      "0     Tuned_GBT  308359.0  272243.0  167038.0  202505.0  0.611067  0.611041   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.599646   0.813421  0.554105  0.659177            36.99  \n",
      "0  0.592108   0.695398  0.583675  0.634657           140.71  \n",
      "0  0.587362   0.524892  0.651429  0.581355          2802.17  \n",
      "0  0.589174   0.632261  0.602750  0.617153          2139.76  \n",
      "0  0.589186   0.695293  0.580274  0.632598          1176.05  \n",
      "0  0.594135   0.648635  0.603603  0.625309          4730.53  \n",
      "CV_LR.pkl\n",
      "['CV_LR', 288388.0, 294795.0, 187009.0, 179953.0, 0.6137831594125107, 0.6137880517373892, 0.5905923489395983, 0.6066256202710577, 0.615765008829037, 0.6111611485391073, 153.83]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  386698.0  163567.0   88699.0  311181.0  0.579138  0.578978   \n",
      "0  Baseline_GBT  330590.0  238944.0  144807.0  235804.0  0.599418  0.599352   \n",
      "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
      "0      Tuned_RF  300575.0  276650.0  174822.0  198098.0  0.607513  0.607496   \n",
      "0     Tuned_RF2  330540.0  235661.0  144857.0  239087.0  0.595910  0.595842   \n",
      "0     Tuned_GBT  308359.0  272243.0  167038.0  202505.0  0.611067  0.611041   \n",
      "0         CV_LR  288388.0  294795.0  187009.0  179953.0  0.613783  0.613788   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.599646   0.813421  0.554105  0.659177            36.99  \n",
      "0  0.592108   0.695398  0.583675  0.634657           140.71  \n",
      "0  0.587362   0.524892  0.651429  0.581355          2802.17  \n",
      "0  0.589174   0.632261  0.602750  0.617153          2139.76  \n",
      "0  0.589186   0.695293  0.580274  0.632598          1176.05  \n",
      "0  0.594135   0.648635  0.603603  0.625309          4730.53  \n",
      "0  0.590592   0.606626  0.615765  0.611161           153.83  \n",
      "CV_RF.pkl\n",
      "['CV_RF', 310427.0, 253562.0, 164970.0, 221186.0, 0.5935820322161355, 0.5935414292269063, 0.5811022968589641, 0.6529847685197845, 0.5839341776818852, 0.6165321099095342, 179.75]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  386698.0  163567.0   88699.0  311181.0  0.579138  0.578978   \n",
      "0  Baseline_GBT  330590.0  238944.0  144807.0  235804.0  0.599418  0.599352   \n",
      "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
      "0      Tuned_RF  300575.0  276650.0  174822.0  198098.0  0.607513  0.607496   \n",
      "0     Tuned_RF2  330540.0  235661.0  144857.0  239087.0  0.595910  0.595842   \n",
      "0     Tuned_GBT  308359.0  272243.0  167038.0  202505.0  0.611067  0.611041   \n",
      "0         CV_LR  288388.0  294795.0  187009.0  179953.0  0.613783  0.613788   \n",
      "0         CV_RF  310427.0  253562.0  164970.0  221186.0  0.593582  0.593541   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.599646   0.813421  0.554105  0.659177            36.99  \n",
      "0  0.592108   0.695398  0.583675  0.634657           140.71  \n",
      "0  0.587362   0.524892  0.651429  0.581355          2802.17  \n",
      "0  0.589174   0.632261  0.602750  0.617153          2139.76  \n",
      "0  0.589186   0.695293  0.580274  0.632598          1176.05  \n",
      "0  0.594135   0.648635  0.603603  0.625309          4730.53  \n",
      "0  0.590592   0.606626  0.615765  0.611161           153.83  \n",
      "0  0.581102   0.652985  0.583934  0.616532           179.75  \n"
     ]
    }
   ],
   "source": [
    "for model in model_list:\n",
    "    print(model)\n",
    "    with open(model, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(data)\n",
    "    new_data = pd.DataFrame([[data[0], data[1], data[2], data[3], data[4], data[5], data[6], data[7], data[8], data[9], data[10], data[11]]], \n",
    "                            columns=['model_name', 'TP', 'TN', 'FP', 'FN', 'Accuracy', 'AUROC', 'AUPR', 'Precision', 'Recall', 'F1', 'Train_Test_Time'])\n",
    "    #print(new_data)\n",
    "    data_out = pd.concat([data_out, new_data])\n",
    "    print(data_out)\n",
    "    \n",
    "# with open('Baseline_RF.pkl', 'rb') as f:\n",
    "#     data2 = pickle.load(f)\n",
    "\n",
    "# print(data2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Train_Test_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline_LR</td>\n",
       "      <td>229461.0</td>\n",
       "      <td>325116.0</td>\n",
       "      <td>245936.0</td>\n",
       "      <td>149632.0</td>\n",
       "      <td>0.583676</td>\n",
       "      <td>0.583745</td>\n",
       "      <td>0.558349</td>\n",
       "      <td>0.482672</td>\n",
       "      <td>0.605289</td>\n",
       "      <td>0.537071</td>\n",
       "      <td>45.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline_RF</td>\n",
       "      <td>386698.0</td>\n",
       "      <td>163567.0</td>\n",
       "      <td>88699.0</td>\n",
       "      <td>311181.0</td>\n",
       "      <td>0.579138</td>\n",
       "      <td>0.578978</td>\n",
       "      <td>0.599646</td>\n",
       "      <td>0.813421</td>\n",
       "      <td>0.554105</td>\n",
       "      <td>0.659177</td>\n",
       "      <td>36.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline_GBT</td>\n",
       "      <td>330590.0</td>\n",
       "      <td>238944.0</td>\n",
       "      <td>144807.0</td>\n",
       "      <td>235804.0</td>\n",
       "      <td>0.599418</td>\n",
       "      <td>0.599352</td>\n",
       "      <td>0.592108</td>\n",
       "      <td>0.695398</td>\n",
       "      <td>0.583675</td>\n",
       "      <td>0.634657</td>\n",
       "      <td>140.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned_LR</td>\n",
       "      <td>249532.0</td>\n",
       "      <td>341227.0</td>\n",
       "      <td>225865.0</td>\n",
       "      <td>133521.0</td>\n",
       "      <td>0.621757</td>\n",
       "      <td>0.621823</td>\n",
       "      <td>0.587362</td>\n",
       "      <td>0.524892</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.581355</td>\n",
       "      <td>2802.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned_RF</td>\n",
       "      <td>300575.0</td>\n",
       "      <td>276650.0</td>\n",
       "      <td>174822.0</td>\n",
       "      <td>198098.0</td>\n",
       "      <td>0.607513</td>\n",
       "      <td>0.607496</td>\n",
       "      <td>0.589174</td>\n",
       "      <td>0.632261</td>\n",
       "      <td>0.602750</td>\n",
       "      <td>0.617153</td>\n",
       "      <td>2139.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned_RF2</td>\n",
       "      <td>330540.0</td>\n",
       "      <td>235661.0</td>\n",
       "      <td>144857.0</td>\n",
       "      <td>239087.0</td>\n",
       "      <td>0.595910</td>\n",
       "      <td>0.595842</td>\n",
       "      <td>0.589186</td>\n",
       "      <td>0.695293</td>\n",
       "      <td>0.580274</td>\n",
       "      <td>0.632598</td>\n",
       "      <td>1176.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned_GBT</td>\n",
       "      <td>308359.0</td>\n",
       "      <td>272243.0</td>\n",
       "      <td>167038.0</td>\n",
       "      <td>202505.0</td>\n",
       "      <td>0.611067</td>\n",
       "      <td>0.611041</td>\n",
       "      <td>0.594135</td>\n",
       "      <td>0.648635</td>\n",
       "      <td>0.603603</td>\n",
       "      <td>0.625309</td>\n",
       "      <td>4730.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_LR</td>\n",
       "      <td>288388.0</td>\n",
       "      <td>294795.0</td>\n",
       "      <td>187009.0</td>\n",
       "      <td>179953.0</td>\n",
       "      <td>0.613783</td>\n",
       "      <td>0.613788</td>\n",
       "      <td>0.590592</td>\n",
       "      <td>0.606626</td>\n",
       "      <td>0.615765</td>\n",
       "      <td>0.611161</td>\n",
       "      <td>153.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_RF</td>\n",
       "      <td>310427.0</td>\n",
       "      <td>253562.0</td>\n",
       "      <td>164970.0</td>\n",
       "      <td>221186.0</td>\n",
       "      <td>0.593582</td>\n",
       "      <td>0.593541</td>\n",
       "      <td>0.581102</td>\n",
       "      <td>0.652985</td>\n",
       "      <td>0.583934</td>\n",
       "      <td>0.616532</td>\n",
       "      <td>179.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
       "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
       "0   Baseline_RF  386698.0  163567.0   88699.0  311181.0  0.579138  0.578978   \n",
       "0  Baseline_GBT  330590.0  238944.0  144807.0  235804.0  0.599418  0.599352   \n",
       "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
       "0      Tuned_RF  300575.0  276650.0  174822.0  198098.0  0.607513  0.607496   \n",
       "0     Tuned_RF2  330540.0  235661.0  144857.0  239087.0  0.595910  0.595842   \n",
       "0     Tuned_GBT  308359.0  272243.0  167038.0  202505.0  0.611067  0.611041   \n",
       "0         CV_LR  288388.0  294795.0  187009.0  179953.0  0.613783  0.613788   \n",
       "0         CV_RF  310427.0  253562.0  164970.0  221186.0  0.593582  0.593541   \n",
       "\n",
       "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
       "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
       "0  0.599646   0.813421  0.554105  0.659177            36.99  \n",
       "0  0.592108   0.695398  0.583675  0.634657           140.71  \n",
       "0  0.587362   0.524892  0.651429  0.581355          2802.17  \n",
       "0  0.589174   0.632261  0.602750  0.617153          2139.76  \n",
       "0  0.589186   0.695293  0.580274  0.632598          1176.05  \n",
       "0  0.594135   0.648635  0.603603  0.625309          4730.53  \n",
       "0  0.590592   0.606626  0.615765  0.611161           153.83  \n",
       "0  0.581102   0.652985  0.583934  0.616532           179.75  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>model_name</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Train_Test_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline_LR</td>\n",
       "      <td>229461.0</td>\n",
       "      <td>325116.0</td>\n",
       "      <td>245936.0</td>\n",
       "      <td>149632.0</td>\n",
       "      <td>0.583676</td>\n",
       "      <td>0.583745</td>\n",
       "      <td>0.558349</td>\n",
       "      <td>0.482672</td>\n",
       "      <td>0.605289</td>\n",
       "      <td>0.537071</td>\n",
       "      <td>45.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline_RF</td>\n",
       "      <td>386698.0</td>\n",
       "      <td>163567.0</td>\n",
       "      <td>88699.0</td>\n",
       "      <td>311181.0</td>\n",
       "      <td>0.579138</td>\n",
       "      <td>0.578978</td>\n",
       "      <td>0.599646</td>\n",
       "      <td>0.813421</td>\n",
       "      <td>0.554105</td>\n",
       "      <td>0.659177</td>\n",
       "      <td>36.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Baseline_GBT</td>\n",
       "      <td>330590.0</td>\n",
       "      <td>238944.0</td>\n",
       "      <td>144807.0</td>\n",
       "      <td>235804.0</td>\n",
       "      <td>0.599418</td>\n",
       "      <td>0.599352</td>\n",
       "      <td>0.592108</td>\n",
       "      <td>0.695398</td>\n",
       "      <td>0.583675</td>\n",
       "      <td>0.634657</td>\n",
       "      <td>140.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Tuned_LR</td>\n",
       "      <td>249532.0</td>\n",
       "      <td>341227.0</td>\n",
       "      <td>225865.0</td>\n",
       "      <td>133521.0</td>\n",
       "      <td>0.621757</td>\n",
       "      <td>0.621823</td>\n",
       "      <td>0.587362</td>\n",
       "      <td>0.524892</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.581355</td>\n",
       "      <td>2802.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Tuned_RF</td>\n",
       "      <td>300575.0</td>\n",
       "      <td>276650.0</td>\n",
       "      <td>174822.0</td>\n",
       "      <td>198098.0</td>\n",
       "      <td>0.607513</td>\n",
       "      <td>0.607496</td>\n",
       "      <td>0.589174</td>\n",
       "      <td>0.632261</td>\n",
       "      <td>0.602750</td>\n",
       "      <td>0.617153</td>\n",
       "      <td>2139.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>Tuned_RF2</td>\n",
       "      <td>330540.0</td>\n",
       "      <td>235661.0</td>\n",
       "      <td>144857.0</td>\n",
       "      <td>239087.0</td>\n",
       "      <td>0.595910</td>\n",
       "      <td>0.595842</td>\n",
       "      <td>0.589186</td>\n",
       "      <td>0.695293</td>\n",
       "      <td>0.580274</td>\n",
       "      <td>0.632598</td>\n",
       "      <td>1176.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>Tuned_GBT</td>\n",
       "      <td>308359.0</td>\n",
       "      <td>272243.0</td>\n",
       "      <td>167038.0</td>\n",
       "      <td>202505.0</td>\n",
       "      <td>0.611067</td>\n",
       "      <td>0.611041</td>\n",
       "      <td>0.594135</td>\n",
       "      <td>0.648635</td>\n",
       "      <td>0.603603</td>\n",
       "      <td>0.625309</td>\n",
       "      <td>4730.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>CV_LR</td>\n",
       "      <td>288388.0</td>\n",
       "      <td>294795.0</td>\n",
       "      <td>187009.0</td>\n",
       "      <td>179953.0</td>\n",
       "      <td>0.613783</td>\n",
       "      <td>0.613788</td>\n",
       "      <td>0.590592</td>\n",
       "      <td>0.606626</td>\n",
       "      <td>0.615765</td>\n",
       "      <td>0.611161</td>\n",
       "      <td>153.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>CV_RF</td>\n",
       "      <td>310427.0</td>\n",
       "      <td>253562.0</td>\n",
       "      <td>164970.0</td>\n",
       "      <td>221186.0</td>\n",
       "      <td>0.593582</td>\n",
       "      <td>0.593541</td>\n",
       "      <td>0.581102</td>\n",
       "      <td>0.652985</td>\n",
       "      <td>0.583934</td>\n",
       "      <td>0.616532</td>\n",
       "      <td>179.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index    model_name        TP        TN        FP        FN  Accuracy  \\\n",
       "0      0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676   \n",
       "1      0   Baseline_RF  386698.0  163567.0   88699.0  311181.0  0.579138   \n",
       "2      0  Baseline_GBT  330590.0  238944.0  144807.0  235804.0  0.599418   \n",
       "3      0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757   \n",
       "4      0      Tuned_RF  300575.0  276650.0  174822.0  198098.0  0.607513   \n",
       "5      0     Tuned_RF2  330540.0  235661.0  144857.0  239087.0  0.595910   \n",
       "6      0     Tuned_GBT  308359.0  272243.0  167038.0  202505.0  0.611067   \n",
       "7      0         CV_LR  288388.0  294795.0  187009.0  179953.0  0.613783   \n",
       "8      0         CV_RF  310427.0  253562.0  164970.0  221186.0  0.593582   \n",
       "\n",
       "      AUROC      AUPR  Precision    Recall        F1  Train_Test_Time  \n",
       "0  0.583745  0.558349   0.482672  0.605289  0.537071            45.69  \n",
       "1  0.578978  0.599646   0.813421  0.554105  0.659177            36.99  \n",
       "2  0.599352  0.592108   0.695398  0.583675  0.634657           140.71  \n",
       "3  0.621823  0.587362   0.524892  0.651429  0.581355          2802.17  \n",
       "4  0.607496  0.589174   0.632261  0.602750  0.617153          2139.76  \n",
       "5  0.595842  0.589186   0.695293  0.580274  0.632598          1176.05  \n",
       "6  0.611041  0.594135   0.648635  0.603603  0.625309          4730.53  \n",
       "7  0.613788  0.590592   0.606626  0.615765  0.611161           153.83  \n",
       "8  0.593541  0.581102   0.652985  0.583934  0.616532           179.75  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_name', 'TP', 'TN', 'FP', 'FN', 'Accuracy', 'AUROC', 'AUPR',\n",
       "       'Precision', 'Recall', 'F1', 'Train_Test_Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out = data_out.set_index('model_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Train_Test_Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline_LR</th>\n",
       "      <td>229461.0</td>\n",
       "      <td>325116.0</td>\n",
       "      <td>245936.0</td>\n",
       "      <td>149632.0</td>\n",
       "      <td>0.583676</td>\n",
       "      <td>0.583745</td>\n",
       "      <td>0.558349</td>\n",
       "      <td>0.482672</td>\n",
       "      <td>0.605289</td>\n",
       "      <td>0.537071</td>\n",
       "      <td>45.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline_RF</th>\n",
       "      <td>386698.0</td>\n",
       "      <td>163567.0</td>\n",
       "      <td>88699.0</td>\n",
       "      <td>311181.0</td>\n",
       "      <td>0.579138</td>\n",
       "      <td>0.578978</td>\n",
       "      <td>0.599646</td>\n",
       "      <td>0.813421</td>\n",
       "      <td>0.554105</td>\n",
       "      <td>0.659177</td>\n",
       "      <td>36.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline_GBT</th>\n",
       "      <td>330590.0</td>\n",
       "      <td>238944.0</td>\n",
       "      <td>144807.0</td>\n",
       "      <td>235804.0</td>\n",
       "      <td>0.599418</td>\n",
       "      <td>0.599352</td>\n",
       "      <td>0.592108</td>\n",
       "      <td>0.695398</td>\n",
       "      <td>0.583675</td>\n",
       "      <td>0.634657</td>\n",
       "      <td>140.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_LR</th>\n",
       "      <td>249532.0</td>\n",
       "      <td>341227.0</td>\n",
       "      <td>225865.0</td>\n",
       "      <td>133521.0</td>\n",
       "      <td>0.621757</td>\n",
       "      <td>0.621823</td>\n",
       "      <td>0.587362</td>\n",
       "      <td>0.524892</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.581355</td>\n",
       "      <td>2802.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_RF</th>\n",
       "      <td>300575.0</td>\n",
       "      <td>276650.0</td>\n",
       "      <td>174822.0</td>\n",
       "      <td>198098.0</td>\n",
       "      <td>0.607513</td>\n",
       "      <td>0.607496</td>\n",
       "      <td>0.589174</td>\n",
       "      <td>0.632261</td>\n",
       "      <td>0.602750</td>\n",
       "      <td>0.617153</td>\n",
       "      <td>2139.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_RF2</th>\n",
       "      <td>330540.0</td>\n",
       "      <td>235661.0</td>\n",
       "      <td>144857.0</td>\n",
       "      <td>239087.0</td>\n",
       "      <td>0.595910</td>\n",
       "      <td>0.595842</td>\n",
       "      <td>0.589186</td>\n",
       "      <td>0.695293</td>\n",
       "      <td>0.580274</td>\n",
       "      <td>0.632598</td>\n",
       "      <td>1176.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_GBT</th>\n",
       "      <td>308359.0</td>\n",
       "      <td>272243.0</td>\n",
       "      <td>167038.0</td>\n",
       "      <td>202505.0</td>\n",
       "      <td>0.611067</td>\n",
       "      <td>0.611041</td>\n",
       "      <td>0.594135</td>\n",
       "      <td>0.648635</td>\n",
       "      <td>0.603603</td>\n",
       "      <td>0.625309</td>\n",
       "      <td>4730.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_LR</th>\n",
       "      <td>288388.0</td>\n",
       "      <td>294795.0</td>\n",
       "      <td>187009.0</td>\n",
       "      <td>179953.0</td>\n",
       "      <td>0.613783</td>\n",
       "      <td>0.613788</td>\n",
       "      <td>0.590592</td>\n",
       "      <td>0.606626</td>\n",
       "      <td>0.615765</td>\n",
       "      <td>0.611161</td>\n",
       "      <td>153.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_RF</th>\n",
       "      <td>310427.0</td>\n",
       "      <td>253562.0</td>\n",
       "      <td>164970.0</td>\n",
       "      <td>221186.0</td>\n",
       "      <td>0.593582</td>\n",
       "      <td>0.593541</td>\n",
       "      <td>0.581102</td>\n",
       "      <td>0.652985</td>\n",
       "      <td>0.583934</td>\n",
       "      <td>0.616532</td>\n",
       "      <td>179.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TP        TN        FP        FN  Accuracy     AUROC  \\\n",
       "model_name                                                                 \n",
       "Baseline_LR   229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
       "Baseline_RF   386698.0  163567.0   88699.0  311181.0  0.579138  0.578978   \n",
       "Baseline_GBT  330590.0  238944.0  144807.0  235804.0  0.599418  0.599352   \n",
       "Tuned_LR      249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
       "Tuned_RF      300575.0  276650.0  174822.0  198098.0  0.607513  0.607496   \n",
       "Tuned_RF2     330540.0  235661.0  144857.0  239087.0  0.595910  0.595842   \n",
       "Tuned_GBT     308359.0  272243.0  167038.0  202505.0  0.611067  0.611041   \n",
       "CV_LR         288388.0  294795.0  187009.0  179953.0  0.613783  0.613788   \n",
       "CV_RF         310427.0  253562.0  164970.0  221186.0  0.593582  0.593541   \n",
       "\n",
       "                  AUPR  Precision    Recall        F1  Train_Test_Time  \n",
       "model_name                                                              \n",
       "Baseline_LR   0.558349   0.482672  0.605289  0.537071            45.69  \n",
       "Baseline_RF   0.599646   0.813421  0.554105  0.659177            36.99  \n",
       "Baseline_GBT  0.592108   0.695398  0.583675  0.634657           140.71  \n",
       "Tuned_LR      0.587362   0.524892  0.651429  0.581355          2802.17  \n",
       "Tuned_RF      0.589174   0.632261  0.602750  0.617153          2139.76  \n",
       "Tuned_RF2     0.589186   0.695293  0.580274  0.632598          1176.05  \n",
       "Tuned_GBT     0.594135   0.648635  0.603603  0.625309          4730.53  \n",
       "CV_LR         0.590592   0.606626  0.615765  0.611161           153.83  \n",
       "CV_RF         0.581102   0.652985  0.583934  0.616532           179.75  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out = data_out.sort_values(by=['AUROC', 'Accuracy'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Train_Test_Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tuned_LR</th>\n",
       "      <td>249532.0</td>\n",
       "      <td>341227.0</td>\n",
       "      <td>225865.0</td>\n",
       "      <td>133521.0</td>\n",
       "      <td>0.621757</td>\n",
       "      <td>0.621823</td>\n",
       "      <td>0.587362</td>\n",
       "      <td>0.524892</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.581355</td>\n",
       "      <td>2802.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_LR</th>\n",
       "      <td>288388.0</td>\n",
       "      <td>294795.0</td>\n",
       "      <td>187009.0</td>\n",
       "      <td>179953.0</td>\n",
       "      <td>0.613783</td>\n",
       "      <td>0.613788</td>\n",
       "      <td>0.590592</td>\n",
       "      <td>0.606626</td>\n",
       "      <td>0.615765</td>\n",
       "      <td>0.611161</td>\n",
       "      <td>153.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_GBT</th>\n",
       "      <td>308359.0</td>\n",
       "      <td>272243.0</td>\n",
       "      <td>167038.0</td>\n",
       "      <td>202505.0</td>\n",
       "      <td>0.611067</td>\n",
       "      <td>0.611041</td>\n",
       "      <td>0.594135</td>\n",
       "      <td>0.648635</td>\n",
       "      <td>0.603603</td>\n",
       "      <td>0.625309</td>\n",
       "      <td>4730.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_RF</th>\n",
       "      <td>300575.0</td>\n",
       "      <td>276650.0</td>\n",
       "      <td>174822.0</td>\n",
       "      <td>198098.0</td>\n",
       "      <td>0.607513</td>\n",
       "      <td>0.607496</td>\n",
       "      <td>0.589174</td>\n",
       "      <td>0.632261</td>\n",
       "      <td>0.602750</td>\n",
       "      <td>0.617153</td>\n",
       "      <td>2139.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline_GBT</th>\n",
       "      <td>330590.0</td>\n",
       "      <td>238944.0</td>\n",
       "      <td>144807.0</td>\n",
       "      <td>235804.0</td>\n",
       "      <td>0.599418</td>\n",
       "      <td>0.599352</td>\n",
       "      <td>0.592108</td>\n",
       "      <td>0.695398</td>\n",
       "      <td>0.583675</td>\n",
       "      <td>0.634657</td>\n",
       "      <td>140.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_RF2</th>\n",
       "      <td>330540.0</td>\n",
       "      <td>235661.0</td>\n",
       "      <td>144857.0</td>\n",
       "      <td>239087.0</td>\n",
       "      <td>0.595910</td>\n",
       "      <td>0.595842</td>\n",
       "      <td>0.589186</td>\n",
       "      <td>0.695293</td>\n",
       "      <td>0.580274</td>\n",
       "      <td>0.632598</td>\n",
       "      <td>1176.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_RF</th>\n",
       "      <td>310427.0</td>\n",
       "      <td>253562.0</td>\n",
       "      <td>164970.0</td>\n",
       "      <td>221186.0</td>\n",
       "      <td>0.593582</td>\n",
       "      <td>0.593541</td>\n",
       "      <td>0.581102</td>\n",
       "      <td>0.652985</td>\n",
       "      <td>0.583934</td>\n",
       "      <td>0.616532</td>\n",
       "      <td>179.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline_LR</th>\n",
       "      <td>229461.0</td>\n",
       "      <td>325116.0</td>\n",
       "      <td>245936.0</td>\n",
       "      <td>149632.0</td>\n",
       "      <td>0.583676</td>\n",
       "      <td>0.583745</td>\n",
       "      <td>0.558349</td>\n",
       "      <td>0.482672</td>\n",
       "      <td>0.605289</td>\n",
       "      <td>0.537071</td>\n",
       "      <td>45.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline_RF</th>\n",
       "      <td>386698.0</td>\n",
       "      <td>163567.0</td>\n",
       "      <td>88699.0</td>\n",
       "      <td>311181.0</td>\n",
       "      <td>0.579138</td>\n",
       "      <td>0.578978</td>\n",
       "      <td>0.599646</td>\n",
       "      <td>0.813421</td>\n",
       "      <td>0.554105</td>\n",
       "      <td>0.659177</td>\n",
       "      <td>36.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TP        TN        FP        FN  Accuracy     AUROC  \\\n",
       "model_name                                                                 \n",
       "Tuned_LR      249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
       "CV_LR         288388.0  294795.0  187009.0  179953.0  0.613783  0.613788   \n",
       "Tuned_GBT     308359.0  272243.0  167038.0  202505.0  0.611067  0.611041   \n",
       "Tuned_RF      300575.0  276650.0  174822.0  198098.0  0.607513  0.607496   \n",
       "Baseline_GBT  330590.0  238944.0  144807.0  235804.0  0.599418  0.599352   \n",
       "Tuned_RF2     330540.0  235661.0  144857.0  239087.0  0.595910  0.595842   \n",
       "CV_RF         310427.0  253562.0  164970.0  221186.0  0.593582  0.593541   \n",
       "Baseline_LR   229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
       "Baseline_RF   386698.0  163567.0   88699.0  311181.0  0.579138  0.578978   \n",
       "\n",
       "                  AUPR  Precision    Recall        F1  Train_Test_Time  \n",
       "model_name                                                              \n",
       "Tuned_LR      0.587362   0.524892  0.651429  0.581355          2802.17  \n",
       "CV_LR         0.590592   0.606626  0.615765  0.611161           153.83  \n",
       "Tuned_GBT     0.594135   0.648635  0.603603  0.625309          4730.53  \n",
       "Tuned_RF      0.589174   0.632261  0.602750  0.617153          2139.76  \n",
       "Baseline_GBT  0.592108   0.695398  0.583675  0.634657           140.71  \n",
       "Tuned_RF2     0.589186   0.695293  0.580274  0.632598          1176.05  \n",
       "CV_RF         0.581102   0.652985  0.583934  0.616532           179.75  \n",
       "Baseline_LR   0.558349   0.482672  0.605289  0.537071            45.69  \n",
       "Baseline_RF   0.599646   0.813421  0.554105  0.659177            36.99  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_out.to_csv('Model_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original Code, Archived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code developed to read in original CSV.  Replaced with parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom schema.  \n",
    "\n",
    "customSchema = StructType([\n",
    "    StructField('Trip_ID', StringType(), True),        \n",
    "    StructField('Trip_Start_Timestamp', StringType(), True),\n",
    "    StructField('Trip_End_Timestamp', StringType(), True),\n",
    "    StructField('Trip_Seconds', DoubleType(), True),\n",
    "    StructField('Trip_Miles', DoubleType(), True),\n",
    "    StructField('Pickup_Census_Tract', StringType(), True),\n",
    "    StructField('Dropoff_Census_Tract', StringType(), True),\n",
    "    StructField('Pickup_Community_Area', DoubleType(), True),\n",
    "    StructField('Dropoff_Community_Area', DoubleType(), True),\n",
    "    StructField(\"Fare\", DoubleType(), True),\n",
    "    StructField(\"Tip\", DoubleType(), True),\n",
    "    StructField(\"Additional_Charges\", DoubleType(), True),\n",
    "    StructField(\"Trip_Total\", StringType(), True),\n",
    "    StructField(\"Shared_Trip_Authorized\", BooleanType(), True),\n",
    "    StructField(\"Trips_Pooled\", DoubleType(), True),\n",
    "    StructField('Pickup_Centroid_Latitude', StringType(), True),\n",
    "    StructField('Pickup_Centroid_Longitude', StringType(), True),\n",
    "    StructField('Pickup_Centroid_Location', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Latitude', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Longitude', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Location', StringType(), True)])\n",
    "\n",
    "#old readin.  Infer is slow for large dataset\n",
    "#df = spark.read.csv('/../../project/ds5559/Alice_Ed_Michael_Sam_project/BigTrips.csv', header = True, inferSchema=True)\n",
    "\n",
    "#read in the data to a dataframe\n",
    "df = spark.read.csv('/../../project/ds5559/Alice_Ed_Michael_Sam_project/BigTrips.csv', header = True, schema=customSchema)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doesn't update if you don't resave the variable\n",
    "\n",
    "df = df.drop('Pickup_Census_Tract',\n",
    "             'Dropoff_Census_Tract',\n",
    "             'Pickup_Centroid_Latitude',\n",
    "             'Pickup_Centroid_Longitude', \n",
    "             'Pickup_Centroid_Location', \n",
    "             'Dropoff_Centroid_Latitude', \n",
    "             'Dropoff_Centroid_Longitude', \n",
    "             'Dropoff_Centroid_Location')\n",
    "\n",
    "#'Trip_End_Timestamp' keep for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.sample(False, .05, seed = 2021) #decreased our sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the big df for now\n",
    "del (df)\n",
    "\n",
    "#hopefully that will make things faster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill our NA community areas\n",
    "\n",
    "df2 = df2.na.fill(value=78,subset=['Pickup_Community_Area', 'Dropoff_Community_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a binary tip/no tip indicator\n",
    "# https://spark.apache.org/docs/2.2.0/ml-features.html#binarizer\n",
    "\n",
    "#binarized tip seems to be causing problems.  Change its name to label as that is that the packages are expecting\n",
    "\n",
    "binarizer = Binarizer(threshold=0, inputCol=\"Tip\", outputCol=\"label\")\n",
    "df2 = binarizer.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumn(\"Trip_Start_TS\", F.to_timestamp(F.col(\"Trip_Start_Timestamp\"), \"MM/dd/yyyy hh:mm:ss a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumn('Trip_Year',F.year(F.to_timestamp('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_Month',F.month(F.to_timestamp('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_WeekNumber',F.weekofyear(F.to_timestamp('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_DayofWeek', F.dayofweek(F.col('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_Start_Hour', F.hour(F.col('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_Start_Minute', F.minute(F.col('Trip_Start_TS'))) \\\n",
    "         .withColumn('Date', F.to_date(F.col('Trip_Start_TS')))\n",
    "         \n",
    "df2.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "\n",
    "# our model didn't work on the standard test train split.  Prof. Tashman recomended upscalling the help with the imbalanced dataset.\n",
    "#from https://spark.apache.org/docs/2.1.0/ml-tuning.html#train-validation-split\n",
    "\n",
    "train_inital, test = df2.randomSplit([0.8, 0.2], seed=2021)\n",
    "\n",
    "# cahce our test values for later speed\n",
    "test.cache()\n",
    "\n",
    "# oversampleing code sample\n",
    "# https://stackoverflow.com/questions/53273133/how-to-perform-up-sampling-using-sample-functionpy-spark\n",
    "\n",
    "df_a = train_inital.filter(train_inital['label'] == 0)\n",
    "df_b = train_inital.filter(train_inital['label'] == 1)\n",
    "\n",
    "org_a_count = df_a.count()\n",
    "org_b_count = df_b.count() \n",
    "\n",
    "\n",
    "ratio = df_a.count() / df_b.count()\n",
    "# print(ratio)\n",
    "\n",
    "df_b_overampled = df_b.sample(withReplacement=True, fraction=ratio, seed=2021)\n",
    "\n",
    "# cahce our train values for later speed\n",
    "train = df_a.unionAll(df_b_overampled).cache()\n",
    "\n",
    "df_af = train.filter(train_inital['label'] == 0)\n",
    "df_bf = train.filter(train_inital['label'] == 1)\n",
    "fin_a_count = df_af.count()\n",
    "fin_b_count = df_bf.count() \n",
    "\n",
    "print(\"Original No Tip Count: \", org_a_count)\n",
    "print(\"Original Tip Count   : \", org_b_count)\n",
    "print(\"\")\n",
    "print(\"Final No Tip Count   : \", fin_a_count)\n",
    "print(\"Final Tip Count      : \", fin_b_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR inital results gridsearch\n",
    "\n",
    "'''\n",
    "25k set\n",
    "best from tuning inital (accuracy):\n",
    "addGrid(lr.regParam, [0.03, 0.05, 0.07]) \\\n",
    ".addGrid(lr.elasticNetParam, [0.15, 0.2, 0.25]) \\\n",
    ".addGrid(lr.maxIter, [8, 9, 10, 11, 12]) \n",
    "\n",
    "regParam= 0.03\n",
    "elasticNetParam = 0.15\n",
    "maxIter = 12\n",
    " \n",
    "Confusion Matrix\n",
    "[[1842. 2203.]\n",
    " [ 193.  595.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.5042416718394372\n",
    "Accuracy from MulticlassMetrics:  0.5042416718394372\n",
    "\n",
    "Area Under the ROC 0.6052265753923187\n",
    "\n",
    "Area Under the PR Curve 0.2065770273222743\n",
    "Summary Stats\n",
    "Precision = 0.5042416718394372\n",
    "Recall = 0.5042416718394372\n",
    "F1 Score = 0.5042416718394372\n",
    "Weighted recall = 0.5042416718394371\n",
    "Weighted precision = 0.7922492654683645\n",
    "Weighted F(1) Score = 0.5612342974368173\n",
    "Weighted F(0.5) Score = 0.6730989071456968\n",
    "Weighted false positive rate = 0.2937885210547999\n",
    "\n",
    "2nd round:\n",
    "\n",
    "lr_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.02, 0.03]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.05, 0.1, 0.15]) \\\n",
    "    .addGrid(lr.maxIter, [11, 12, 13, 15]) \\\n",
    "\n",
    "regParam= 0.03\n",
    "elasticNetParam = 0.15\n",
    "maxIter = 11\n",
    "\n",
    "Confusion Matrix\n",
    "[[1815. 2230.]\n",
    " [ 183.  605.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.5007241878750258\n",
    "Accuracy from MulticlassMetrics:  0.5007241878750258\n",
    "\n",
    "Area Under the ROC 0.6082342994108162\n",
    "\n",
    "Area Under the PR Curve 0.2075564549699384\n",
    "Summary Stats\n",
    "Precision = 0.5007241878750258\n",
    "Recall = 0.5007241878750258\n",
    "F1 Score = 0.5007241878750258\n",
    "Weighted recall = 0.5007241878750258\n",
    "Weighted precision = 0.7950908896146499\n",
    "Weighted F(1) Score = 0.5572078454446675\n",
    "Weighted F(0.5) Score = 0.6716684076809212\n",
    "Weighted false positive rate = 0.28425558905339354\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF inital results gridsearch\n",
    "\n",
    "'''\n",
    "best from tuning inital (accuracy):\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5, 10]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .addGrid(rf.impurity, [\"entropy\", \"gini\"])\\\n",
    "    .build()\n",
    "\n",
    "numTrees = 10\n",
    "maxDepth = 10\n",
    "impurity = gini\n",
    " \n",
    "Confusion Matrix\n",
    "[[2901. 1144.]\n",
    " [ 456.  332.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6689426857024623\n",
    "Accuracy from MulticlassMetrics:  0.6689426857024623\n",
    "\n",
    "Area Under the ROC 0.5692507513819781\n",
    "\n",
    "Area Under the PR Curve 0.2070259967551608\n",
    "Summary Stats\n",
    "Precision = 0.6689426857024623\n",
    "Recall = 0.6689426857024623\n",
    "F1 Score = 0.6689426857024623\n",
    "Weighted recall = 0.6689426857024622\n",
    "Weighted precision = 0.7599403563099746\n",
    "Weighted F(1) Score = 0.7038591473392332\n",
    "Weighted F(0.5) Score = 0.735232181263078\n",
    "Weighted false positive rate = 0.530441182938506\n",
    "\n",
    "2nd attempt:\n",
    "\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5, 10, 15]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .addGrid(rf.impurity, [\"entropy\", \"gini\"])\\\n",
    "    .addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt'])\\\n",
    "    .build()\n",
    "\n",
    "\n",
    "numTrees = 10\n",
    "maxDepth = 15\n",
    "impurity = gini\n",
    "featureSubsetStrategy = auto\n",
    "\n",
    "Confusion Matrix\n",
    "[[2663. 1382.]\n",
    " [ 388.  400.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6337678460583489\n",
    "Accuracy from MulticlassMetrics:  0.6337678460583489\n",
    "\n",
    "Area Under the ROC 0.5829789236570811\n",
    "\n",
    "Area Under the PR Curve 0.209345437091233\n",
    "Summary Stats\n",
    "Precision = 0.6337678460583489\n",
    "Recall = 0.6337678460583489\n",
    "F1 Score = 0.6337678460583489\n",
    "Weighted recall = 0.6337678460583488\n",
    "Weighted precision = 0.7671159775546591\n",
    "Weighted F(1) Score = 0.6789410276493224\n",
    "Weighted F(0.5) Score = 0.7270236282319229\n",
    "Weighted false positive rate = 0.46780999874418644\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBT inital results gridsearch\n",
    "\n",
    "\n",
    "'''\n",
    "best from tuning inital (accuracy):\n",
    "gbt_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [5, 10, 20]) \\\n",
    "    .build()\n",
    "\n",
    "maxIter = 20\n",
    "\n",
    "Confusion Matrix\n",
    "[[2798. 1247.]\n",
    " [ 423.  365.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.654458928201945\n",
    "Accuracy from MulticlassMetrics:  0.654458928201945\n",
    "\n",
    "Area Under the ROC 0.5774580700620556\n",
    "\n",
    "Area Under the PR Curve 0.2094152550126291\n",
    "Summary Stats\n",
    "Precision = 0.654458928201945\n",
    "Recall = 0.654458928201945\n",
    "F1 Score = 0.654458928201945\n",
    "Weighted recall = 0.654458928201945\n",
    "Weighted precision = 0.7639586098089827\n",
    "Weighted F(1) Score = 0.6941837869282138\n",
    "Weighted F(0.5) Score = 0.7327747544723259\n",
    "Weighted false positive rate = 0.4995427880778336\n",
    "\n",
    "\n",
    "maxIter = 40\n",
    "\n",
    "Confusion Matrix\n",
    "[[2571. 1474.]\n",
    " [ 382.  406.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6159735154148562\n",
    "Accuracy from MulticlassMetrics:  0.6159735154148562\n",
    "\n",
    "Area Under the ROC 0.5754139659791808\n",
    "\n",
    "Area Under the PR Curve 0.20313239804234073\n",
    "Summary Stats\n",
    "Precision = 0.6159735154148562\n",
    "Recall = 0.6159735154148562\n",
    "F1 Score = 0.6159735154148562\n",
    "Weighted recall = 0.6159735154148562\n",
    "Weighted precision = 0.7638968296438198\n",
    "Weighted F(1) Score = 0.6646010165217533\n",
    "Weighted F(0.5) Score = 0.7183436330713325\n",
    "Weighted false positive rate = 0.4651455834564943\n",
    "\n",
    "\n",
    "gbt_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [5, 10])\\\n",
    "    .addGrid(gbt.maxDepth, [5, 10])\\\n",
    "    .build()\n",
    "    \n",
    "maxIter = 5\n",
    "maxDepth = 5\n",
    "\n",
    "Confusion Matrix\n",
    "[[2863. 1182.]\n",
    " [ 469.  319.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6583902338092282\n",
    "Accuracy from MulticlassMetrics:  0.6583902338092282\n",
    "\n",
    "Area Under the ROC 0.5563048634335804\n",
    "\n",
    "Area Under the PR Curve 0.19780050930331394\n",
    "Summary Stats\n",
    "Precision = 0.6583902338092282\n",
    "Recall = 0.6583902338092282\n",
    "F1 Score = 0.6583902338092282\n",
    "Weighted recall = 0.6583902338092282\n",
    "Weighted precision = 0.7537989743798752\n",
    "Weighted F(1) Score = 0.6950856095348379\n",
    "Weighted F(0.5) Score = 0.7279222226014918\n",
    "Weighted false positive rate = 0.5457805069420676\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
