{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS5559 Final Project Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Left Twix Members\n",
    "\n",
    "* Alice Wright - aew7j\n",
    "* Edward Thompson - ejt8b\n",
    "* Michael Davies -  mld9s\n",
    "* Sam Parsons - sp8hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source:\n",
    "The best data source for this appears to be from the City of Chicago, as it is large (169M records and 21 columns), relatively clean, anonymized, and accessible via API.\n",
    "\n",
    "City of Chicago:\n",
    "https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips/m6dm-c72p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Rubric\n",
    "\n",
    "* Model construction (min 3 models) | 3 pts\n",
    "\n",
    "* Model evaluation | 2 pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Spark Session and Load Libraries Required for Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import context manager: SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# import data types\n",
    "# from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType\n",
    "# import pyspark.sql.types as typ\n",
    "# import pyspark.sql.functions as F\n",
    "# import os\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"mllib_classifier\") \\\n",
    "        .config(\"spark.executor.memory\", '21g') \\\n",
    "        .config('spark.executor.cores', '6') \\\n",
    "        .config('spark.executor.instances', '7') \\\n",
    "        .config(\"spark.driver.memory\",'1g') \\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# import data manipulation methods\n",
    "# from pyspark.ml.feature import Binarizer\n",
    "from pyspark.ml import Pipeline  \n",
    "# from pyspark.ml.feature import *  \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.ml.feature import VectorAssembler \n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "#from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in our dataset from preprocessed parquet file generated in notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df = spark.read.parquet(\"/../../project/ds5559/Alice_Ed_Michael_Sam_project/final_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip_ID: string (nullable = true)\n",
      " |-- Trip_Seconds: integer (nullable = true)\n",
      " |-- Trip_Miles: double (nullable = true)\n",
      " |-- Pickup_Census_Tract: string (nullable = true)\n",
      " |-- Dropoff_Census_Tract: string (nullable = true)\n",
      " |-- Pickup_Community_Area: integer (nullable = true)\n",
      " |-- Dropoff_Community_Area: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: double (nullable = true)\n",
      " |-- Additional_Charges_str: double (nullable = true)\n",
      " |-- Trip_Total: double (nullable = true)\n",
      " |-- Shared_Trip_Authorized: boolean (nullable = true)\n",
      " |-- Trips_Pooled: integer (nullable = true)\n",
      " |-- Pickup_Centroid_Latitude: string (nullable = true)\n",
      " |-- Pickup_Centroid_Longitude: string (nullable = true)\n",
      " |-- Pickup_Centroid_Location: string (nullable = true)\n",
      " |-- Dropoff_Centroid_Latitude: string (nullable = true)\n",
      " |-- Dropoff_Centroid_Longitude: string (nullable = true)\n",
      " |-- Dropoff_Centroid_Location: string (nullable = true)\n",
      " |-- Trip_Start_Timestamp: timestamp (nullable = true)\n",
      " |-- Trip_End_Timestamp: timestamp (nullable = true)\n",
      " |-- PostShutdownFlag: integer (nullable = true)\n",
      " |-- Day_Month_str: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- Trip_Year: integer (nullable = true)\n",
      " |-- Trip_Month: integer (nullable = true)\n",
      " |-- Trip_WeekNumber: integer (nullable = true)\n",
      " |-- Trip_DayofWeek: integer (nullable = true)\n",
      " |-- Trip_Start_Hour: integer (nullable = true)\n",
      " |-- Trip_Start_Minute: integer (nullable = true)\n",
      " |-- Trip_End_Hour: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove unnecessary fields, duplicate location data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df = p_df.drop('Pickup_Census_Tract',\n",
    "             'Dropoff_Census_Tract',\n",
    "             'Pickup_Centroid_Latitude',\n",
    "             'Pickup_Centroid_Longitude', \n",
    "             'Pickup_Centroid_Location', \n",
    "             'Dropoff_Centroid_Latitude', \n",
    "             'Dropoff_Centroid_Longitude', \n",
    "             'Dropoff_Centroid_Location',\n",
    "             'Day_Month_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip_ID: string (nullable = true)\n",
      " |-- Trip_Seconds: integer (nullable = true)\n",
      " |-- Trip_Miles: double (nullable = true)\n",
      " |-- Pickup_Community_Area: integer (nullable = true)\n",
      " |-- Dropoff_Community_Area: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: double (nullable = true)\n",
      " |-- Additional_Charges_str: double (nullable = true)\n",
      " |-- Trip_Total: double (nullable = true)\n",
      " |-- Shared_Trip_Authorized: boolean (nullable = true)\n",
      " |-- Trips_Pooled: integer (nullable = true)\n",
      " |-- Trip_Start_Timestamp: timestamp (nullable = true)\n",
      " |-- Trip_End_Timestamp: timestamp (nullable = true)\n",
      " |-- PostShutdownFlag: integer (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- Trip_Year: integer (nullable = true)\n",
      " |-- Trip_Month: integer (nullable = true)\n",
      " |-- Trip_WeekNumber: integer (nullable = true)\n",
      " |-- Trip_DayofWeek: integer (nullable = true)\n",
      " |-- Trip_Start_Hour: integer (nullable = true)\n",
      " |-- Trip_Start_Minute: integer (nullable = true)\n",
      " |-- Trip_End_Hour: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Chicago Community Areas for pickup and dropoff locations.  Null area is location outside City of Chicago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------+\n",
      "|Pickup_Community_Area| count|\n",
      "+---------------------+------+\n",
      "|                   31| 53670|\n",
      "|                   65| 10567|\n",
      "|                   53| 10712|\n",
      "|                   34| 15822|\n",
      "|                   28|402866|\n",
      "|                   76|228152|\n",
      "|                   26| 12039|\n",
      "|                   27| 19081|\n",
      "|                   44| 28113|\n",
      "|                   12|  6564|\n",
      "|                   22|170353|\n",
      "|                   47|  1750|\n",
      "|                 null|354582|\n",
      "|                    1| 58825|\n",
      "|                   52|  2478|\n",
      "|                   13| 10627|\n",
      "|                    6|293132|\n",
      "|                   16| 47734|\n",
      "|                    3|107329|\n",
      "|                   40| 12284|\n",
      "+---------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_df.groupby(\"Pickup_Community_Area\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace Null with dummy value, using 78 as to not expand one hot encoding excessivly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill our NA community areas\n",
    "\n",
    "p_df = p_df.na.fill(value=78,subset=['Pickup_Community_Area', 'Dropoff_Community_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------+\n",
      "|Pickup_Community_Area| count|\n",
      "+---------------------+------+\n",
      "|                   31| 53670|\n",
      "|                   65| 10567|\n",
      "|                   53| 10712|\n",
      "|                   78|354582|\n",
      "|                   34| 15822|\n",
      "|                   28|402866|\n",
      "|                   76|228152|\n",
      "|                   26| 12039|\n",
      "|                   27| 19081|\n",
      "|                   44| 28113|\n",
      "|                   12|  6564|\n",
      "|                   22|170353|\n",
      "|                   47|  1750|\n",
      "|                    1| 58825|\n",
      "|                   52|  2478|\n",
      "|                   13| 10627|\n",
      "|                    6|293132|\n",
      "|                   16| 47734|\n",
      "|                    3|107329|\n",
      "|                   40| 12284|\n",
      "+---------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_df.groupby(\"Pickup_Community_Area\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Test/Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original No Tip Count:  1900289\n",
      "Original Tip Count   :  1900435\n"
     ]
    }
   ],
   "source": [
    "# split the data\n",
    "\n",
    "train, test = p_df.randomSplit([0.8, 0.2], seed=2021)\n",
    "\n",
    "org_a_count = train.filter(train['label'] == 0).count()\n",
    "org_b_count = train.filter(train['label'] == 1).count()\n",
    "\n",
    "print(\"Original No Tip Count: \", org_a_count)\n",
    "print(\"Original Tip Count   : \", org_b_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre processing in notebook 1 handled the imbalanced dataset.  No further balancing is required.  Cache our datasets for speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.cache()\n",
    "train.cache()\n",
    "\n",
    "# delete the original parquet file for more memory. \n",
    "del (p_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions (UDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def cmacc(pred):\n",
    "    t0 = time.time()\n",
    "    # make a confusion matrix and return the accuracy\n",
    "    # select predictions and labels from prediction transform as rdd as there isn't a DF function for this\n",
    "    pred_rdd= pred.select('prediction').rdd.flatMap(lambda x: x)\n",
    "    label_rdd = pred.select('label').rdd.flatMap(lambda x: x).map(lambda x: float(x))\n",
    "    \n",
    "    #zip them together\n",
    "    predictionAndLabels =  pred_rdd.zip(label_rdd)\n",
    "    \n",
    "    #metrics transform\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    \n",
    "    metrics2 = BinaryClassificationMetrics(predictionAndLabels)\n",
    "    \n",
    "    #make our confusion matrix\n",
    "    cm = metrics.confusionMatrix().toArray()\n",
    "\n",
    "    #calc accuracy from confusion matrix\n",
    "    \n",
    "    acc = (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "    \n",
    "    # McM accuracy\n",
    "    \n",
    "    acc2 = metrics.accuracy\n",
    "    \n",
    "    #calc area under curve\n",
    "    auc = metrics2.areaUnderROC\n",
    "    \n",
    "    prc = metrics2.areaUnderPR\n",
    "    \n",
    "    print(\"Confusion Matrix\")\n",
    "    print(cm)\n",
    "    print()\n",
    "    print(\"Accuracy from Confusion Matrix: \", acc)\n",
    "    print()\n",
    "    print(\"Accuracy from MulticlassMetrics: \", acc2)\n",
    "    print()     \n",
    "    print(\"Area Under the ROC\", auc)\n",
    "    print()\n",
    "    print(\"Area Under the PR Curve\", prc)\n",
    "    print('-'*50)\n",
    "    print(\"Metrics2 time:\", time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Confusion Matrix and Accuracy, Extended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmacc2(pred, name, trtime):\n",
    "    # make a confusion matrix and return the accuracy\n",
    "    # select predictions and labels from prediction transform as rdd as there isn't a DF function for this\n",
    "     \n",
    "    pred_rdd= pred.select('prediction').rdd.flatMap(lambda x: x)\n",
    "    label_rdd = pred.select('label').rdd.flatMap(lambda x: x).map(lambda x: float(x))\n",
    "\n",
    "    #zip them together\n",
    "    predictionAndLabels =  pred_rdd.zip(label_rdd)\n",
    "    print(\"Zipped P and L\")\n",
    "    \n",
    "    #metrics transform\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    metrics2 = BinaryClassificationMetrics(predictionAndLabels)\n",
    "    print('metrics created')\n",
    "    \n",
    "    #make our confusion matrix\n",
    "    cm = metrics.confusionMatrix().toArray()\n",
    "\n",
    "    #calc accuracy from confusion matrix\n",
    "    acc = (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "    \n",
    "    #McM accuracy\n",
    "    acc2 = metrics.accuracy\n",
    "    \n",
    "    #calc area under curve\n",
    "    auc = metrics2.areaUnderROC\n",
    "    prc = metrics2.areaUnderPR\n",
    "    print('areas under the curve')\n",
    "    \n",
    "    #Precision = TP/TP+FP\n",
    "    precision = metrics.precision()\n",
    "    cmprecision = (cm[0][0])/(cm[0][0] + cm[0][1])\n",
    "    \n",
    "    #Recall = TP/TP+FN\n",
    "    recall = metrics.recall()\n",
    "    cmrecall = (cm[0][0])/(cm[0][0] + cm[1][0])\n",
    "    \n",
    "    #F1 = 2*TP/2*TP +FP+FN or 2* (precision * recall)/(precision+ recall)\n",
    "    f1Score = metrics.fMeasure()\n",
    "    cmf1 = (2*cm[0][0])/(2*cm[0][0] + cm[0][1] + cm[1][0])\n",
    "        \n",
    "    print('-'*50)    \n",
    "    print(\"Confusion Matrix\")\n",
    "    print(cm)\n",
    "    print('-'*50)\n",
    "    print()\n",
    "    print(\"Accuracy from Confusion Matrix: \", acc)\n",
    "    print(\"Accuracy from MulticlassMetrics: \", acc2)\n",
    "    print()\n",
    "    print(\"Area Under the ROC\", auc)\n",
    "    print(\"Area Under the PR Curve\", prc)\n",
    "    print('-'*50)\n",
    "    print()\n",
    "    print(\"Summary Stats\")\n",
    "    print()\n",
    "    print(\"Precision from MulticlassMetrics = %s\" % precision)\n",
    "    print(\"Precision from Confusion Matrix :\", cmprecision)\n",
    "    print()\n",
    "    print(\"Recall from MulticlassMetrics = %s\" % recall)\n",
    "    print(\"Recall from Confusion Matrix :\", cmrecall)\n",
    "    print()\n",
    "    print(\"F1 Score = %s\" % f1Score)\n",
    "    print(\"F1 from Confusion Matrix : \", cmf1)\n",
    "    print()\n",
    "    \n",
    "#     # Weighted stats\n",
    "#     print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "#     print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "#     print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
    "#     print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
    "#     print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)\n",
    "    print('-'*50)\n",
    "#     print(\"Metrics2 time:\", time.time() - t0)\n",
    "\n",
    "    # set up storage   \n",
    "    out_list = [name, cm[0][0], cm[1][1], cm[0][1], cm[1][0], acc, auc, prc, cmprecision, cmrecall, cmf1, trtime]\n",
    "    \n",
    "    print(out_list)\n",
    "    pickel_name = name + \".pkl\"\n",
    "    \n",
    "    # thanks to Prof. Tashman for demonstarting this during the DS5100 notebook testing.\n",
    "    with open(pickel_name, 'wb') as f:\n",
    "        pickle.dump(out_list, f)\n",
    "        \n",
    "    return out_list\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Basic Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding Piplelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding for models (Michael sugested that we didn't need it in each model step)\n",
    "\n",
    "#onehotencoder to pickup\n",
    "ohe_pu = OneHotEncoder(inputCol=\"Pickup_Community_Area\", outputCol=\"Pickup_Community_Area_vec\")\n",
    "\n",
    "#onehotencoder to dropoff\n",
    "ohe_do = OneHotEncoder(inputCol=\"Dropoff_Community_Area\", outputCol=\"Dropoff_Community_Area_vec\")\n",
    "\n",
    "#onehotencoder to weekNumber\n",
    "ohe_twn = OneHotEncoder(inputCol=\"Trip_WeekNumber\", outputCol=\"Trip_WeekNumber_vec\")\n",
    "\n",
    "#onehotencoder to dayOfWeek\n",
    "ohe_dw = OneHotEncoder(inputCol=\"Trip_DayofWeek\", outputCol=\"Trip_DayofWeek_vec\")\n",
    "\n",
    "#onehotencoder to startHour\n",
    "ohe_sh = OneHotEncoder(inputCol=\"Trip_Start_Hour\", outputCol=\"Trip_Start_Hour_vec\")\n",
    "\n",
    "#onehotencoder to startMinute\n",
    "ohe_sm = OneHotEncoder(inputCol=\"Trip_Start_Minute\", outputCol=\"Trip_Start_Minute_vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Pipeline Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "testing\n",
      "Baseline LR Train/Test Time: 35.92\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[229461. 245936.]\n",
      " [149632. 325116.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5836761757415974\n",
      "Accuracy from MulticlassMetrics:  0.5836761757415974\n",
      "\n",
      "Area Under the ROC 0.583745213910684\n",
      "Area Under the PR Curve 0.5583488691324588\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.5836761757415974\n",
      "Precision from Confusion Matrix : 0.48267237698176474\n",
      "\n",
      "Recall from MulticlassMetrics = 0.5836761757415974\n",
      "Recall from Confusion Matrix : 0.6052894672283582\n",
      "\n",
      "F1 Score = 0.5836761757415974\n",
      "F1 from Confusion Matrix :  0.5370712354737914\n",
      "\n",
      "--------------------------------------------------\n",
      "['Baseline_LR', 229461.0, 325116.0, 245936.0, 149632.0, 0.5836761757415974, 0.583745213910684, 0.5583488691324588, 0.48267237698176474, 0.6052894672283582, 0.5370712354737914, 35.92]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Baseline_LR'\n",
    "\n",
    "# our colulms for lr\n",
    "predictor_col_for_lr = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] \n",
    "\n",
    "#assemble the vector for lr\n",
    "lr_va = VectorAssembler(inputCols=predictor_col_for_lr, outputCol=\"features\") \n",
    "\n",
    "#scale our lr\n",
    "lr_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "#what do we want to do if we are doing a parameter search? make the parameters as variables and just do a loop?\n",
    "#we learned that this week.  May also need to add in cv step\n",
    "\n",
    "lr = LogisticRegression(maxIter=10,\n",
    "                        regParam=0.1, #org 0.1\n",
    "                        elasticNetParam=0.3, #org 0.3\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"label\")\n",
    "\n",
    "# Build the pipeline\n",
    "lr_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, lr_va, lr_scaler, lr])\n",
    "\n",
    "#time check\n",
    "t0 = time.time()\n",
    "\n",
    "# Fit the pipeline\n",
    "print(\"training\")\n",
    "lr_model = lr_pipeline.fit(train)\n",
    "\n",
    "# Make a prediction\n",
    "print(\"testing\")\n",
    "lr_prediction = lr_model.transform(test)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "print(\"Baseline LR Train/Test Time:\", tt)\n",
    "\n",
    "train_time = tt.real\n",
    "\n",
    "baseLR = cmacc2(lr_prediction, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baseline_LR',\n",
       " 229461.0,\n",
       " 325116.0,\n",
       " 245936.0,\n",
       " 149632.0,\n",
       " 0.5836761757415974,\n",
       " 0.583745213910684,\n",
       " 0.5583488691324588,\n",
       " 0.48267237698176474,\n",
       " 0.6052894672283582,\n",
       " 0.5370712354737914,\n",
       " 45.69]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseMatrix(1, 256, [0, 6], [2, 3, 4, 5, 163, 255], [0.001, 0.0784, -0.1861, -0.0158, -0.1056, -0.0625], 1)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model.stages[-1].coefficientMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Pipeline for Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "testing\n",
      "Baseline RF Test Error = 0.409512\n",
      "Accuracy:  0.590488251152715\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_4bfa20a92609) with 10 trees\n",
      "Baseline RF Train/Test Time: 35.21\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[329109. 146288.]\n",
      " [239071. 235677.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5944208515542364\n",
      "Accuracy from MulticlassMetrics:  0.5944208515542364\n",
      "\n",
      "Area Under the ROC 0.5943539611433748\n",
      "Area Under the PR Curve 0.5874638989337708\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.5944208515542364\n",
      "Precision from Confusion Matrix : 0.6922824502468463\n",
      "\n",
      "Recall from MulticlassMetrics = 0.5944208515542364\n",
      "Recall from Confusion Matrix : 0.5792336935478194\n",
      "\n",
      "F1 Score = 0.5944208515542364\n",
      "F1 from Confusion Matrix :  0.6307325669308542\n",
      "\n",
      "--------------------------------------------------\n",
      "['Baseline_RF', 329109.0, 235677.0, 146288.0, 239071.0, 0.5944208515542364, 0.5943539611433748, 0.5874638989337708, 0.6922824502468463, 0.5792336935478194, 0.6307325669308542, 35.21]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Baseline_RF'\n",
    "\n",
    "# our colulms for rf\n",
    "predictor_col_for_rf = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "# assemble feature vector\n",
    "rf_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "\n",
    "# set classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \n",
    "                            featuresCol=\"features\", \n",
    "                            numTrees=10)\n",
    "\n",
    "# Build the pipeline\n",
    "rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, rf_va, rf])\n",
    "\n",
    "#time check\n",
    "t0 = time.time()\n",
    "\n",
    "# Fit the pipeline\n",
    "print(\"training\")\n",
    "rf_model = rf_pipeline.fit(train)\n",
    "\n",
    "# Make a prediction\n",
    "print(\"testing\")\n",
    "rf_prediction = rf_model.transform(test)\n",
    "t1 = time.time()\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "rf_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "#metric options f1|accuracy|weightedPrecision|weightedRecall\n",
    "\n",
    "rf_accuracy = rf_evaluator.evaluate(rf_prediction)\n",
    "\n",
    "print(\"Baseline RF Test Error = %g\" % (1.0 - rf_accuracy))\n",
    "print(\"Accuracy: \" , rf_accuracy)\n",
    "\n",
    "rfModel2 = rf_model.stages[7]\n",
    "print(rfModel2)  # summary only\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "\n",
    "print(\"Baseline RF Train/Test Time:\", train_time)\n",
    "\n",
    "baseRF = cmacc2(rf_prediction, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baseline_RF',\n",
       " 325504.0,\n",
       " 239354.0,\n",
       " 149893.0,\n",
       " 235394.0,\n",
       " 0.594496629461819,\n",
       " 0.594434974075626,\n",
       " 0.5863415643818957,\n",
       " 0.6846993144676975,\n",
       " 0.5803265477858719,\n",
       " 0.6282072189868715,\n",
       " 38.34]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.timlrx.com/blog/feature-selection-using-feature-importance-score-creating-a-pyspark-estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SparseVector(256, {0: 0.0215, 1: 0.0687, 2: 0.0526, 3: 0.2716, 4: 0.0286, 5: 0.0693, 10: 0.0, 13: 0.0, 14: 0.0085, 20: 0.0, 31: 0.004, 34: 0.0, 38: 0.0248, 39: 0.0, 41: 0.0, 45: 0.0, 46: 0.0049, 48: 0.0015, 49: 0.0001, 50: 0.013, 52: 0.0002, 62: 0.0192, 65: 0.0, 67: 0.0, 72: 0.0001, 75: 0.0273, 77: 0.0024, 82: 0.1729, 83: 0.0001, 85: 0.0, 90: 0.0003, 94: 0.0, 97: 0.0, 103: 0.0, 108: 0.0002, 109: 0.0452, 112: 0.0001, 113: 0.0002, 116: 0.0053, 117: 0.0, 119: 0.0008, 121: 0.0, 122: 0.0056, 127: 0.0031, 128: 0.012, 137: 0.0003, 140: 0.0002, 144: 0.0001, 152: 0.0095, 153: 0.016, 156: 0.0, 160: 0.0554, 161: 0.0002, 163: 0.0089, 172: 0.0, 173: 0.0, 176: 0.0048, 177: 0.0078, 178: 0.0037, 179: 0.0053, 183: 0.0, 186: 0.0, 188: 0.0, 191: 0.0, 192: 0.0, 194: 0.0, 197: 0.0, 198: 0.0, 199: 0.0, 200: 0.0, 204: 0.0, 207: 0.0, 210: 0.0, 255: 0.0235})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_model.stages[-1].featureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Pipeline for Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training\n",
      "testing\n",
      "GBT Baseline Train/Test Time: 116.96\n",
      "GBT Test Error = 0.404306\n",
      "GBT accuracy =  0.5956939318235045\n",
      "GBTClassificationModel (uid=GBTClassifier_5cc09f72907f) with 5 trees\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[330585. 144812.]\n",
      " [235790. 238958.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5994274558093765\n",
      "Accuracy from MulticlassMetrics:  0.5994274558093765\n",
      "\n",
      "Area Under the ROC 0.5993618653388731\n",
      "Area Under the PR Curve 0.5921143690572241\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.5994274558093765\n",
      "Precision from Confusion Matrix : 0.6953872237309028\n",
      "\n",
      "Recall from MulticlassMetrics = 0.5994274558093765\n",
      "Recall from Confusion Matrix : 0.5836857205914809\n",
      "\n",
      "F1 Score = 0.5994274558093765\n",
      "F1 from Confusion Matrix :  0.634659023279566\n",
      "\n",
      "--------------------------------------------------\n",
      "['Baseline_GBT', 330585.0, 238958.0, 144812.0, 235790.0, 0.5994274558093765, 0.5993618653388731, 0.5921143690572241, 0.6953872237309028, 0.5836857205914809, 0.634659023279566, 116.96]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Baseline_GBT'\n",
    "\n",
    "# our colulms for gbt\n",
    "predictor_col_for_gbt = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "gbt_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "\n",
    "# set classifier\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=5)\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "gbt_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, gbt_va, gbt]) #labelIndexer, featureIndexer\n",
    "\n",
    "#time check\n",
    "t0 = time.time()\n",
    "\n",
    "# Train model.\n",
    "gbt_model = gbt_pipeline.fit(train)\n",
    "print('training')\n",
    "\n",
    "# Make predictions.\n",
    "gbt_prediction = gbt_model.transform(test)\n",
    "print('testing')\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "\n",
    "print(\"GBT Baseline Train/Test Time:\", train_time)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "gbt_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "gbt_accuracy = gbt_evaluator.evaluate(gbt_prediction)\n",
    "print(\"GBT Test Error = %g\" % (1.0 - gbt_accuracy))\n",
    "print('GBT accuracy = ', gbt_accuracy)\n",
    "gbtModel = gbt_model.stages[7]\n",
    "print(gbtModel)  # summary only\n",
    "\n",
    "baseGBT = cmacc2(gbt_prediction, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baseline_GBT',\n",
       " 330585.0,\n",
       " 238958.0,\n",
       " 144812.0,\n",
       " 235790.0,\n",
       " 0.5994274558093765,\n",
       " 0.5993618653388731,\n",
       " 0.5921143690572241,\n",
       " 0.6953872237309028,\n",
       " 0.5836857205914809,\n",
       " 0.634659023279566,\n",
       " 116.96]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseGBT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline LR with Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(lr_paramGrid): 18\n",
      "train/cv\n",
      "test\n",
      "LR with Tuning Train Time: 2386.31\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[249532. 225865.]\n",
      " [133521. 341227.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.6217566792436944\n",
      "Accuracy from MulticlassMetrics:  0.6217566792436944\n",
      "\n",
      "Area Under the ROC 0.6218228883577326\n",
      "Area Under the PR Curve 0.587362346525713\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.6217566792436944\n",
      "Precision from Confusion Matrix : 0.5248918272517495\n",
      "\n",
      "Recall from MulticlassMetrics = 0.6217566792436944\n",
      "Recall from Confusion Matrix : 0.6514294366575905\n",
      "\n",
      "F1 Score = 0.6217566792436944\n",
      "F1 from Confusion Matrix :  0.5813547673131807\n",
      "\n",
      "--------------------------------------------------\n",
      "['Tuned_LR', 249532.0, 341227.0, 225865.0, 133521.0, 0.6217566792436944, 0.6218228883577326, 0.587362346525713, 0.5248918272517495, 0.6514294366575905, 0.5813547673131807, 2386.31]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Tuned_LR'\n",
    "\n",
    "# our colulms for lr\n",
    "predictor_col_for_lr = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "#assemble the vector or LR\n",
    "\n",
    "lr_va = VectorAssembler(inputCols=predictor_col_for_lr, outputCol=\"features\") \n",
    "\n",
    "#scale our LR\n",
    "\n",
    "lr_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "#classifier\n",
    "lr = LogisticRegression(featuresCol=\"features\",\n",
    "                        labelCol=\"label\") # regParam=0.1, elasticNetParam=0.3, maxIter=10,\n",
    "\n",
    "# Build the pipeline\n",
    "lr_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, lr_va, lr_scaler, lr])\n",
    "\n",
    "# Set up the parameter grid\n",
    "lr_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.03, 0.05]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.1, 0.2, 0.3]) \\\n",
    "    .addGrid(lr.maxIter, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "print('len(lr_paramGrid): {}'.format(len(lr_paramGrid)))\n",
    "\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "print('train/cv')\n",
    "lr_crossval = CrossValidator(estimator=lr_pipeline,\n",
    "                          estimatorParamMaps=lr_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='f1'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "\n",
    "t0 = time.time()\n",
    "lr_cvModel = lr_crossval.setParallelism(6).fit(train) # train 6 models in parallel\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on test samples. cvModel uses the best model found (lrModel).\n",
    "print('test')\n",
    "lr_prediction = lr_cvModel.transform(test)\n",
    "t1 = time.time()c\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "print(\"LR with Tuning Train Time:\", tt)\n",
    "\n",
    "TunedLR = cmacc2(lr_prediction, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to find all our items we can call\n",
    "#dir(crossval.evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6187369732054344,\n",
       " 0.61916512106001,\n",
       " 0.6178265947983667,\n",
       " 0.6189043791594819,\n",
       " 0.6163600388620095,\n",
       " 0.6185034346180186,\n",
       " 0.6163660091873301,\n",
       " 0.6181994478191033,\n",
       " 0.6105985263982171,\n",
       " 0.6137518450672478,\n",
       " 0.6049166678779192,\n",
       " 0.6091241268373309,\n",
       " 0.6128870658279999,\n",
       " 0.6153804440480171,\n",
       " 0.6028563476245997,\n",
       " 0.6088742135190593,\n",
       " 0.593679373510709,\n",
       " 0.597261311965908]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model RMSE https://projector-video-pdf-converter.datacamp.com/14989/chapter4.pdf\n",
    "lr_cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_8a026aebfd5f', name='regParam', doc='regularization parameter (>= 0).'): 0.05,\n",
       " Param(parent='LogisticRegression_8a026aebfd5f', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3,\n",
       " Param(parent='LogisticRegression_8a026aebfd5f', name='maxIter', doc='max number of iterations (>= 0).'): 5}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#determine paramaters of best model\n",
    "#https://dsharpc.github.io/SparkMLFlights/\n",
    "\n",
    "lr_cvModel.getEstimatorParamMaps()[ np.argmin(lr_cvModel.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(lr_paramGrid): 18\n",
      "train/cv\n",
      "test\n",
      "LR with Tuning Train Time: 2518.9\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[243606. 231791.]\n",
      " [150568. 324180.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.597578264370175\n",
      "Accuracy from MulticlassMetrics:  0.597578264370175\n",
      "\n",
      "Area Under the ROC 0.5976364673784024\n",
      "Area Under the PR Curve 0.5698579879684897\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.597578264370175\n",
      "Precision from Confusion Matrix : 0.5124264562039726\n",
      "\n",
      "Recall from MulticlassMetrics = 0.597578264370175\n",
      "Recall from Confusion Matrix : 0.6180164089970419\n",
      "\n",
      "F1 Score = 0.597578264370175\n",
      "F1 from Confusion Matrix :  0.5602900740710074\n",
      "\n",
      "--------------------------------------------------\n",
      "['Tuned_LR2', 243606.0, 324180.0, 231791.0, 150568.0, 0.597578264370175, 0.5976364673784024, 0.5698579879684897, 0.5124264562039726, 0.6180164089970419, 0.5602900740710074, 2518.9]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Tuned_LR2'\n",
    "\n",
    "# our colulms for lr\n",
    "predictor_col_for_lr = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "#assemble the vector or LR\n",
    "\n",
    "lr_va = VectorAssembler(inputCols=predictor_col_for_lr, outputCol=\"features\") \n",
    "\n",
    "#scale our LR\n",
    "\n",
    "lr_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "#classifier\n",
    "lr = LogisticRegression(featuresCol=\"features\",\n",
    "                        labelCol=\"label\") # regParam=0.1, elasticNetParam=0.3, maxIter=10,\n",
    "\n",
    "# Build the pipeline\n",
    "lr_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, lr_va, lr_scaler, lr])\n",
    "\n",
    "# Set up the parameter grid\n",
    "lr_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.05, 0.075, 0.1]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.3, 0.4, 0.5]) \\\n",
    "    .addGrid(lr.maxIter, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "print('len(lr_paramGrid): {}'.format(len(lr_paramGrid)))\n",
    "\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "print('train/cv')\n",
    "lr_crossval = CrossValidator(estimator=lr_pipeline,\n",
    "                          estimatorParamMaps=lr_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='f1'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "\n",
    "t0 = time.time()\n",
    "lr_cvModel = lr_crossval.setParallelism(6).fit(train) # train 6 models in parallel\n",
    "\n",
    "\n",
    "\n",
    "# Make predictions on test samples. cvModel uses the best model found (lrModel).\n",
    "print('test')\n",
    "lr_prediction = lr_cvModel.transform(test)\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "print(\"LR with Tuning Train Time:\", tt)\n",
    "\n",
    "TunedLR = cmacc2(lr_prediction, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to find all our items we can call\n",
    "#dir(crossval.evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.593679373510709,\n",
       " 0.597261311965908,\n",
       " 0.5897296019074938,\n",
       " 0.5862079132409334,\n",
       " 0.5886593061696461,\n",
       " 0.5819984712150646,\n",
       " 0.5871984081505421,\n",
       " 0.5787496349058965,\n",
       " 0.5868907072411093,\n",
       " 0.57668576758561,\n",
       " 0.587471400775593,\n",
       " 0.5799174851622375,\n",
       " 0.5841778323500006,\n",
       " 0.5784160183360071,\n",
       " 0.5783317524819762,\n",
       " 0.5684637536276904,\n",
       " 0.5863596900940766,\n",
       " 0.5801111239452142]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model RMSE https://projector-video-pdf-converter.datacamp.com/14989/chapter4.pdf\n",
    "lr_cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_6f31af815f7b', name='regParam', doc='regularization parameter (>= 0).'): 0.1,\n",
       " Param(parent='LogisticRegression_6f31af815f7b', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.4,\n",
       " Param(parent='LogisticRegression_6f31af815f7b', name='maxIter', doc='max number of iterations (>= 0).'): 10}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#determine paramaters of best model\n",
    "#https://dsharpc.github.io/SparkMLFlights/\n",
    "\n",
    "lr_cvModel.getEstimatorParamMaps()[ np.argmin(lr_cvModel.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline RF with Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(rf_paramGrid): 9\n",
      "train/cv\n",
      "test\n",
      "RF with Tuning Train Time: 2089.0\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[297800. 177597.]\n",
      " [193923. 280825.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.6089859968741613\n",
      "Accuracy from MulticlassMetrics:  0.6089859968741613\n",
      "\n",
      "Area Under the ROC 0.6089740777710633\n",
      "Area Under the PR Curve 0.5895255738497178\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.6089859968741613\n",
      "Precision from Confusion Matrix : 0.626423809994594\n",
      "\n",
      "Recall from MulticlassMetrics = 0.6089859968741613\n",
      "Recall from Confusion Matrix : 0.6056255249398543\n",
      "\n",
      "F1 Score = 0.6089859968741613\n",
      "F1 from Confusion Matrix :  0.6158491190338324\n",
      "\n",
      "--------------------------------------------------\n",
      "['Tuned_RF', 297800.0, 280825.0, 177597.0, 193923.0, 0.6089859968741613, 0.6089740777710633, 0.5895255738497178, 0.626423809994594, 0.6056255249398543, 0.6158491190338324, 2089.0]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Tuned_RF'\n",
    "\n",
    "# our colulms for rf\n",
    "predictor_col_for_rf = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "# assemble feature vector\n",
    "rf_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "               \n",
    "# set classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \n",
    "                            featuresCol=\"features\")\n",
    "    \n",
    "# Build the pipeline\n",
    "rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, rf_va, rf])\n",
    "\n",
    "# Set up the parameter grid\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5, 10, 15]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .build()\n",
    "#\"entropy\"\n",
    "#.addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt'])\\\n",
    "#.addGrid(rf.impurity, [\"gini\"])\\\n",
    "   \n",
    "print('len(rf_paramGrid): {}'.format(len(rf_paramGrid)))\n",
    "\n",
    "#https://medium.com/rahasak/random-forest-classifier-with-apache-spark-c63b4a23a7cc\n",
    "#maxDepth, maxBins, impurity, auto and seed \n",
    "#.addGrid(randomForestClassifier.impurity, Array(\"entropy\", \"gini\"))\n",
    "#name='featureSubsetStrategy', auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n]\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "print('train/cv')\n",
    "rf_crossval = CrossValidator(estimator=rf_pipeline,\n",
    "                          estimatorParamMaps=rf_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='f1'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "t0 = time.time()\n",
    "cvModel_rf = rf_crossval.setParallelism(6).fit(train) # train 6 models in parallel\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "print('test')\n",
    "prediction_rf = cvModel_rf.transform(test)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "\n",
    "print(\"RF with Tuning Train Time:\", tt)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction_rf = cvModel_rf.transform(test)\n",
    "\n",
    "TunedRF = cmacc2(prediction_rf, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tuned_RF',\n",
       " 297800.0,\n",
       " 280825.0,\n",
       " 177597.0,\n",
       " 193923.0,\n",
       " 0.6089859968741613,\n",
       " 0.6089740777710633,\n",
       " 0.5895255738497178,\n",
       " 0.626423809994594,\n",
       " 0.6056255249398543,\n",
       " 0.6158491190338324,\n",
       " 2089.0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TunedRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to find all our items we can call\n",
    "#dir(crossval.evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5404866096767633,\n",
       " 0.5868874064610188,\n",
       " 0.6023500055035178,\n",
       " 0.5712415911085544,\n",
       " 0.5986262181007318,\n",
       " 0.6058893606475215,\n",
       " 0.5619321633863338,\n",
       " 0.6003225344428791,\n",
       " 0.6085699826147258]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not sure what this metric is... rmse\n",
    "cvModel_rf.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_6fbfd7950324', name='numTrees', doc='Number of trees to train (>= 1).'): 5,\n",
       " Param(parent='RandomForestClassifier_6fbfd7950324', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best model paramaters from lowest RMSE\n",
    "\n",
    "cvModel_rf.getEstimatorParamMaps()[ np.argmin(cvModel_rf.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(rf_paramGrid): 8\n",
      "train/cv\n",
      "test\n",
      "RF with Tuning Train Time: 843.65\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[311983. 163414.]\n",
      " [228521. 246227.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.587499802661699\n",
      "Accuracy from MulticlassMetrics:  0.587499802661699\n",
      "\n",
      "Area Under the ROC 0.587452805144262\n",
      "Area Under the PR Curve 0.5766702390917446\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.587499802661699\n",
      "Precision from Confusion Matrix : 0.6562578224094809\n",
      "\n",
      "Recall from MulticlassMetrics = 0.587499802661699\n",
      "Recall from Confusion Matrix : 0.57720756923168\n",
      "\n",
      "F1 Score = 0.587499802661699\n",
      "F1 from Confusion Matrix :  0.614199611970064\n",
      "\n",
      "--------------------------------------------------\n",
      "['Tuned_RF2', 311983.0, 246227.0, 163414.0, 228521.0, 0.587499802661699, 0.587452805144262, 0.5766702390917446, 0.6562578224094809, 0.57720756923168, 0.614199611970064, 843.65]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'Tuned_RF2'\n",
    "\n",
    "# our colulms for rf\n",
    "predictor_col_for_rf = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "# assemble feature vector\n",
    "rf_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "               \n",
    "# set classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \n",
    "                            featuresCol=\"features\")\n",
    "    \n",
    "# Build the pipeline\n",
    "rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, rf_va, rf])\n",
    "\n",
    "#parameter grid\n",
    "rf_paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(rf.numTrees, [3, 5])\\\n",
    "    .addGrid(rf.maxDepth, [3, 5])\\\n",
    "    .addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt'])\\\n",
    "    .build()\n",
    "   \n",
    "print('len(rf_paramGrid): {}'.format(len(rf_paramGrid)))\n",
    "\n",
    "#https://medium.com/rahasak/random-forest-classifier-with-apache-spark-c63b4a23a7cc\n",
    "#maxDepth, maxBins, impurity, auto and seed \n",
    "#.addGrid(randomForestClassifier.impurity, Array(\"entropy\", \"gini\"))\n",
    "#name='featureSubsetStrategy', auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n]\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "print('train/cv')\n",
    "rf_crossval = CrossValidator(estimator=rf_pipeline,\n",
    "                          estimatorParamMaps=rf_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='f1'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "t0 = time.time()\n",
    "cvModel_rf = rf_crossval.setParallelism(6).fit(train) # train 6 models in parallel\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "print('test')\n",
    "prediction_rf = cvModel_rf.transform(test)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "\n",
    "print(\"RF with Tuning Train Time:\", tt)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction_rf = cvModel_rf.transform(test)\n",
    "\n",
    "TunedRF2 = cmacc2(prediction_rf, model_name, train_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5778278140228544,\n",
       " 0.5778278140228544,\n",
       " 0.5838845019172043,\n",
       " 0.5838845019172043,\n",
       " 0.526715010695165,\n",
       " 0.526715010695165,\n",
       " 0.5404866096767633,\n",
       " 0.5404866096767633]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not sure what this metric is... rmse\n",
    "cvModel_rf.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_d1e089515056', name='numTrees', doc='Number of trees to train (>= 1).'): 5,\n",
       " Param(parent='RandomForestClassifier_d1e089515056', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 3,\n",
       " Param(parent='RandomForestClassifier_d1e089515056', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Best model paramaters from lowest RMSE\n",
    "\n",
    "cvModel_rf.getEstimatorParamMaps()[ np.argmin(cvModel_rf.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline GBT with Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBT was run once on the full dataset.  Due to its long modeling time it was elimiated as a canidate as its accuracy did not warrent the long compute times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(gbt_paramGrid): 4\n",
      "train\n",
      "test\n",
      "GBT with Tuning Train Time: 4872.3\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[313556. 161841.]\n",
      " [209444. 265304.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.6092333275447431\n",
      "Accuracy from MulticlassMetrics:  0.6092333275447431\n",
      "\n",
      "Area Under the ROC 0.6091989236956347\n",
      "Area Under the PR Curve 0.5943196320513571\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.6092333275447431\n",
      "Precision from Confusion Matrix : 0.6595666358853758\n",
      "\n",
      "Recall from MulticlassMetrics = 0.6092333275447431\n",
      "Recall from Confusion Matrix : 0.5995334608030592\n",
      "\n",
      "F1 Score = 0.6092333275447431\n",
      "F1 from Confusion Matrix :  0.6281188745559131\n",
      "\n",
      "--------------------------------------------------\n",
      "['Tuned_GBT', 313556.0, 265304.0, 161841.0, 209444.0, 0.6092333275447431, 0.6091989236956347, 0.5943196320513571, 0.6595666358853758, 0.5995334608030592, 0.6281188745559131, 4872.3]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"Tuned_GBT\"\n",
    "\n",
    "# our colulms for gbt\n",
    "predictor_col_for_gbt = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "gbt_va = VectorAssembler(inputCols=predictor_col_for_gbt, outputCol=\"features\") \n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\") #, maxIter=5\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "gbt_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, gbt_va, gbt]) #labelIndexer, featureIndexer\n",
    "\n",
    "# Set up the parameter grid\n",
    "gbt_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [5, 10])\\\n",
    "    .addGrid(gbt.maxDepth, [5, 10])\\\n",
    "    .build()\n",
    "\n",
    "print('len(gbt_paramGrid): {}'.format(len(gbt_paramGrid)))\n",
    "\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "gbt_crossval = CrossValidator(estimator=gbt_pipeline,\n",
    "                          estimatorParamMaps=gbt_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='f1'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "print(\"train\")\n",
    "t0 = time.time()\n",
    "cvModel_gbt = gbt_crossval.setParallelism(6).fit(train) # train 6 models in parallel\n",
    "\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "print(\"test\")\n",
    "prediction_gbt = cvModel_gbt.transform(test)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "\n",
    "print(\"GBT with Tuning Train Time:\", tt)\n",
    "\n",
    "TunedGBT = cmacc2(prediction_gbt, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmacc2(prediction_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5925946750513758,\n",
       " 0.6021299266975099,\n",
       " 0.5999075809775377,\n",
       " 0.6107245076006178]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not sure what this metric is...\n",
    "cvModel_gbt.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='GBTClassifier_388f134878e9', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       " Param(parent='GBTClassifier_388f134878e9', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#best paramaters\n",
    "cvModel_gbt.getEstimatorParamMaps()[np.argmin(cvModel_gbt.avgMetrics)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline LR with CV and no Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify Gridsearch results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(lr_paramGrid): 1\n",
      "train\n",
      "train time: 151.6270649433136\n",
      "test\n",
      "LR with CV, no tuning, train time: 152.83\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[310536. 164861.]\n",
      " [219267. 255481.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.59571644327971\n",
      "Accuracy from MulticlassMetrics:  0.59571644327971\n",
      "\n",
      "Area Under the ROC 0.5956771424852536\n",
      "Area Under the PR Curve 0.5828216432401201\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.59571644327971\n",
      "Precision from Confusion Matrix : 0.653214050572469\n",
      "\n",
      "Recall from MulticlassMetrics = 0.59571644327971\n",
      "Recall from Confusion Matrix : 0.5861348463485484\n",
      "\n",
      "F1 Score = 0.59571644327971\n",
      "F1 from Confusion Matrix :  0.617859132510943\n",
      "\n",
      "--------------------------------------------------\n",
      "['CV_LR', 310536.0, 255481.0, 164861.0, 219267.0, 0.59571644327971, 0.5956771424852536, 0.5828216432401201, 0.653214050572469, 0.5861348463485484, 0.617859132510943, 152.83]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'CV_LR'\n",
    "\n",
    "# our colulms for lr\n",
    "predictor_col_for_lr = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "#assemble the vector ror lr\n",
    "lr_va = VectorAssembler(inputCols=predictor_col_for_lr, outputCol=\"features\") \n",
    "\n",
    "#scale our LR\n",
    "\n",
    "lr_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "#what do we want to do if we are doing a parameter search? make the parameters as variables and just do a loop?\n",
    "#we learned that this week.  May also need to add in cv step\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\",\n",
    "                        labelCol=\"label\") # regParam=0.1, elasticNetParam=0.3, maxIter=10,\n",
    "\n",
    "# Build the pipeline\n",
    "lr_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, lr_va, lr_scaler, lr])\n",
    "\n",
    "# Set up the parameter grid\n",
    "lr_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.05]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.3]) \\\n",
    "    .addGrid(lr.maxIter, [5]) \\\n",
    "    .build()\n",
    "\n",
    "print('len(lr_paramGrid): {}'.format(len(lr_paramGrid)))\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "lr_crossval = CrossValidator(estimator=lr_pipeline,\n",
    "                          estimatorParamMaps=lr_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='f1'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "print(\"train\")\n",
    "t0 = time.time()\n",
    "lr_cvModel = lr_crossval.setParallelism(5).fit(train) # train 5 models in parallel\n",
    "print(\"train time:\", time.time() - t0)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "print(\"test\")\n",
    "lr_prediction = lr_cvModel.transform(test)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "\n",
    "print(\"LR with CV, no tuning, train time:\", tt)\n",
    "\n",
    "CVLR = cmacc2(lr_prediction, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.593679373510709]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model RMSE https://projector-video-pdf-converter.datacamp.com/14989/chapter4.pdf\n",
    "lr_cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_51fe7a567505', name='regParam', doc='regularization parameter (>= 0).'): 0.05,\n",
       " Param(parent='LogisticRegression_51fe7a567505', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.3,\n",
       " Param(parent='LogisticRegression_51fe7a567505', name='maxIter', doc='max number of iterations (>= 0).'): 5}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#determine paramaters of best model\n",
    "#https://dsharpc.github.io/SparkMLFlights/\n",
    "\n",
    "lr_cvModel.getEstimatorParamMaps()[ np.argmin(lr_cvModel.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline RF with CV and no Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify Gridsearch results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(rf_paramGrid): 1\n",
      "train\n",
      "test\n",
      "LR with CV, no tuning, train time: 223.43\n",
      "Zipped P and L\n",
      "metrics created\n",
      "areas under the curve\n",
      "--------------------------------------------------\n",
      "Confusion Matrix\n",
      "[[392801.  82596.]\n",
      " [317951. 156797.]]\n",
      "--------------------------------------------------\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5784359229380779\n",
      "Accuracy from MulticlassMetrics:  0.5784359229380779\n",
      "\n",
      "Area Under the ROC 0.5782665308511222\n",
      "Area Under the PR Curve 0.602966838029918\n",
      "--------------------------------------------------\n",
      "\n",
      "Summary Stats\n",
      "\n",
      "Precision from MulticlassMetrics = 0.5784359229380779\n",
      "Precision from Confusion Matrix : 0.8262588951970669\n",
      "\n",
      "Recall from MulticlassMetrics = 0.5784359229380779\n",
      "Recall from Confusion Matrix : 0.5526554972761244\n",
      "\n",
      "F1 Score = 0.5784359229380779\n",
      "F1 from Confusion Matrix :  0.6623130820832795\n",
      "\n",
      "--------------------------------------------------\n",
      "['CV_RF', 392801.0, 156797.0, 82596.0, 317951.0, 0.5784359229380779, 0.5782665308511222, 0.602966838029918, 0.8262588951970669, 0.5526554972761244, 0.6623130820832795, 223.43]\n"
     ]
    }
   ],
   "source": [
    "model_name = 'CV_RF'\n",
    "\n",
    "# our colulms for rf\n",
    "predictor_col_for_rf = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ]\n",
    "\n",
    "# assemble feature vector\n",
    "rf_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "\n",
    "# set classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \n",
    "                            featuresCol=\"features\")\n",
    "\n",
    "# # Build the pipeline\n",
    "# rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, rf_va, rf])\n",
    "\n",
    "# Build the pipeline\n",
    "rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, rf_va, rf])\n",
    "\n",
    "# Set up the parameter grid\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5]) \\\n",
    "    .addGrid(rf.maxDepth, [5]) \\\n",
    "    .addGrid(rf.impurity, [\"gini\"])\\\n",
    "    .addGrid(rf.featureSubsetStrategy, ['auto'])\\\n",
    "    .build()\n",
    "   \n",
    "    \n",
    "\n",
    "print('len(rf_paramGrid): {}'.format(len(rf_paramGrid)))\n",
    "\n",
    "#https://medium.com/rahasak/random-forest-classifier-with-apache-spark-c63b4a23a7cc\n",
    "#maxDepth, maxBins, impurity, auto and seed \n",
    "#.addGrid(randomForestClassifier.impurity, Array(\"entropy\", \"gini\"))\n",
    "#name='featureSubsetStrategy', auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n]\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "rf_crossval = CrossValidator(estimator=rf_pipeline,\n",
    "                          estimatorParamMaps=rf_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='f1'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "print(\"train\")\n",
    "t0 = time.time()\n",
    "cvModel_rf = rf_crossval.setParallelism(5).fit(train) # train 5 models in parallel\n",
    "\n",
    "# Make predictions on test documents. \n",
    "print(\"test\")\n",
    "prediction_rf = cvModel_rf.transform(test)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "tt = round(t1-t0, 2)\n",
    "train_time = tt.real\n",
    "\n",
    "print(\"LR with CV, no tuning, train time:\", tt)\n",
    "\n",
    "CVLR = cmacc2(prediction_rf, model_name, train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5404866096767633]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not sure what this metric is... rmse\n",
    "cvModel_rf.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_d099437a911e', name='numTrees', doc='Number of trees to train (>= 1).'): 5,\n",
       " Param(parent='RandomForestClassifier_d099437a911e', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       " Param(parent='RandomForestClassifier_d099437a911e', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini',\n",
       " Param(parent='RandomForestClassifier_d099437a911e', name='featureSubsetStrategy', doc=\"The number of features to consider for splits at each tree node. Supported options: 'auto' (choose automatically for task: If numTrees == 1, set to 'all'. If numTrees > 1 (forest), set to 'sqrt' for classification and to 'onethird' for regression), 'all' (use all features), 'onethird' (use 1/3 of the features), 'sqrt' (use sqrt(number of features)), 'log2' (use log2(number of features)), 'n' (when n is in the range (0, 1.0], use n * number of features. When n is in the range (1, number of features), use n features). default = 'auto'\"): 'auto'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#paramaters\n",
    "\n",
    "cvModel_rf.getEstimatorParamMaps()[ np.argmin(cvModel_rf.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Matrix of Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all the models we ran\n",
    "model_list = ['Baseline_LR.pkl', 'Baseline_RF.pkl', 'Baseline_GBT.pkl', 'Tuned_LR.pkl',  'Tuned_LR2.pkl', 'Tuned_RF.pkl', 'Tuned_RF2.pkl', 'Tuned_GBT.pkl', 'CV_LR.pkl', 'CV_RF.pkl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up pandas dataframe to hold all the model results\n",
    "data_out = pd.DataFrame(columns=['model_name', 'TP', 'TN', 'FP', 'FN', 'Accuracy', 'AUROC', 'AUPR', 'Precision', 'Recall', 'F1']) #, index=index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline_LR.pkl\n",
      "['Baseline_LR', 229461.0, 325116.0, 245936.0, 149632.0, 0.5836761757415974, 0.583745213910684, 0.5583488691324588, 0.48267237698176474, 0.6052894672283582, 0.5370712354737914, 45.69]\n",
      "    model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0  Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "Baseline_RF.pkl\n",
      "['Baseline_RF', 325504.0, 239354.0, 149893.0, 235394.0, 0.594496629461819, 0.594434974075626, 0.5863415643818957, 0.6846993144676975, 0.5803265477858719, 0.6282072189868715, 38.34]\n",
      "    model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0  Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0  Baseline_RF  325504.0  239354.0  149893.0  235394.0  0.594497  0.594435   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.586342   0.684699  0.580327  0.628207            38.34  \n",
      "Baseline_GBT.pkl\n",
      "['Baseline_GBT', 330585.0, 238958.0, 144812.0, 235790.0, 0.5994274558093765, 0.5993618653388731, 0.5921143690572241, 0.6953872237309028, 0.5836857205914809, 0.634659023279566, 116.96]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  325504.0  239354.0  149893.0  235394.0  0.594497  0.594435   \n",
      "0  Baseline_GBT  330585.0  238958.0  144812.0  235790.0  0.599427  0.599362   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.586342   0.684699  0.580327  0.628207            38.34  \n",
      "0  0.592114   0.695387  0.583686  0.634659           116.96  \n",
      "Tuned_LR.pkl\n",
      "['Tuned_LR', 249532.0, 341227.0, 225865.0, 133521.0, 0.6217566792436944, 0.6218228883577326, 0.587362346525713, 0.5248918272517495, 0.6514294366575905, 0.5813547673131807, 2386.31]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  325504.0  239354.0  149893.0  235394.0  0.594497  0.594435   \n",
      "0  Baseline_GBT  330585.0  238958.0  144812.0  235790.0  0.599427  0.599362   \n",
      "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.586342   0.684699  0.580327  0.628207            38.34  \n",
      "0  0.592114   0.695387  0.583686  0.634659           116.96  \n",
      "0  0.587362   0.524892  0.651429  0.581355          2386.31  \n",
      "Tuned_LR2.pkl\n",
      "['Tuned_LR2', 243606.0, 324180.0, 231791.0, 150568.0, 0.597578264370175, 0.5976364673784024, 0.5698579879684897, 0.5124264562039726, 0.6180164089970419, 0.5602900740710074, 2518.9]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  325504.0  239354.0  149893.0  235394.0  0.594497  0.594435   \n",
      "0  Baseline_GBT  330585.0  238958.0  144812.0  235790.0  0.599427  0.599362   \n",
      "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
      "0     Tuned_LR2  243606.0  324180.0  231791.0  150568.0  0.597578  0.597636   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.586342   0.684699  0.580327  0.628207            38.34  \n",
      "0  0.592114   0.695387  0.583686  0.634659           116.96  \n",
      "0  0.587362   0.524892  0.651429  0.581355          2386.31  \n",
      "0  0.569858   0.512426  0.618016  0.560290          2518.90  \n",
      "Tuned_RF.pkl\n",
      "['Tuned_RF', 297800.0, 280825.0, 177597.0, 193923.0, 0.6089859968741613, 0.6089740777710633, 0.5895255738497178, 0.626423809994594, 0.6056255249398543, 0.6158491190338324, 2089.0]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  325504.0  239354.0  149893.0  235394.0  0.594497  0.594435   \n",
      "0  Baseline_GBT  330585.0  238958.0  144812.0  235790.0  0.599427  0.599362   \n",
      "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
      "0     Tuned_LR2  243606.0  324180.0  231791.0  150568.0  0.597578  0.597636   \n",
      "0      Tuned_RF  297800.0  280825.0  177597.0  193923.0  0.608986  0.608974   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.586342   0.684699  0.580327  0.628207            38.34  \n",
      "0  0.592114   0.695387  0.583686  0.634659           116.96  \n",
      "0  0.587362   0.524892  0.651429  0.581355          2386.31  \n",
      "0  0.569858   0.512426  0.618016  0.560290          2518.90  \n",
      "0  0.589526   0.626424  0.605626  0.615849          2089.00  \n",
      "Tuned_RF2.pkl\n",
      "['Tuned_RF2', 311983.0, 246227.0, 163414.0, 228521.0, 0.587499802661699, 0.587452805144262, 0.5766702390917446, 0.6562578224094809, 0.57720756923168, 0.614199611970064, 843.65]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  325504.0  239354.0  149893.0  235394.0  0.594497  0.594435   \n",
      "0  Baseline_GBT  330585.0  238958.0  144812.0  235790.0  0.599427  0.599362   \n",
      "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
      "0     Tuned_LR2  243606.0  324180.0  231791.0  150568.0  0.597578  0.597636   \n",
      "0      Tuned_RF  297800.0  280825.0  177597.0  193923.0  0.608986  0.608974   \n",
      "0     Tuned_RF2  311983.0  246227.0  163414.0  228521.0  0.587500  0.587453   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.586342   0.684699  0.580327  0.628207            38.34  \n",
      "0  0.592114   0.695387  0.583686  0.634659           116.96  \n",
      "0  0.587362   0.524892  0.651429  0.581355          2386.31  \n",
      "0  0.569858   0.512426  0.618016  0.560290          2518.90  \n",
      "0  0.589526   0.626424  0.605626  0.615849          2089.00  \n",
      "0  0.576670   0.656258  0.577208  0.614200           843.65  \n",
      "Tuned_GBT.pkl\n",
      "['Tuned_GBT', 313556.0, 265304.0, 161841.0, 209444.0, 0.6092333275447431, 0.6091989236956347, 0.5943196320513571, 0.6595666358853758, 0.5995334608030592, 0.6281188745559131, 4872.3]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  325504.0  239354.0  149893.0  235394.0  0.594497  0.594435   \n",
      "0  Baseline_GBT  330585.0  238958.0  144812.0  235790.0  0.599427  0.599362   \n",
      "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
      "0     Tuned_LR2  243606.0  324180.0  231791.0  150568.0  0.597578  0.597636   \n",
      "0      Tuned_RF  297800.0  280825.0  177597.0  193923.0  0.608986  0.608974   \n",
      "0     Tuned_RF2  311983.0  246227.0  163414.0  228521.0  0.587500  0.587453   \n",
      "0     Tuned_GBT  313556.0  265304.0  161841.0  209444.0  0.609233  0.609199   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.586342   0.684699  0.580327  0.628207            38.34  \n",
      "0  0.592114   0.695387  0.583686  0.634659           116.96  \n",
      "0  0.587362   0.524892  0.651429  0.581355          2386.31  \n",
      "0  0.569858   0.512426  0.618016  0.560290          2518.90  \n",
      "0  0.589526   0.626424  0.605626  0.615849          2089.00  \n",
      "0  0.576670   0.656258  0.577208  0.614200           843.65  \n",
      "0  0.594320   0.659567  0.599533  0.628119          4872.30  \n",
      "CV_LR.pkl\n",
      "['CV_LR', 310536.0, 255481.0, 164861.0, 219267.0, 0.59571644327971, 0.5956771424852536, 0.5828216432401201, 0.653214050572469, 0.5861348463485484, 0.617859132510943, 152.83]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  325504.0  239354.0  149893.0  235394.0  0.594497  0.594435   \n",
      "0  Baseline_GBT  330585.0  238958.0  144812.0  235790.0  0.599427  0.599362   \n",
      "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
      "0     Tuned_LR2  243606.0  324180.0  231791.0  150568.0  0.597578  0.597636   \n",
      "0      Tuned_RF  297800.0  280825.0  177597.0  193923.0  0.608986  0.608974   \n",
      "0     Tuned_RF2  311983.0  246227.0  163414.0  228521.0  0.587500  0.587453   \n",
      "0     Tuned_GBT  313556.0  265304.0  161841.0  209444.0  0.609233  0.609199   \n",
      "0         CV_LR  310536.0  255481.0  164861.0  219267.0  0.595716  0.595677   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.586342   0.684699  0.580327  0.628207            38.34  \n",
      "0  0.592114   0.695387  0.583686  0.634659           116.96  \n",
      "0  0.587362   0.524892  0.651429  0.581355          2386.31  \n",
      "0  0.569858   0.512426  0.618016  0.560290          2518.90  \n",
      "0  0.589526   0.626424  0.605626  0.615849          2089.00  \n",
      "0  0.576670   0.656258  0.577208  0.614200           843.65  \n",
      "0  0.594320   0.659567  0.599533  0.628119          4872.30  \n",
      "0  0.582822   0.653214  0.586135  0.617859           152.83  \n",
      "CV_RF.pkl\n",
      "['CV_RF', 390424.0, 149276.0, 84973.0, 325472.0, 0.5680185655873577, 0.5678454706470535, 0.5900881453560403, 0.8212588636444909, 0.5453641311028418, 0.6554625940050013, 173.34]\n",
      "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
      "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
      "0   Baseline_RF  325504.0  239354.0  149893.0  235394.0  0.594497  0.594435   \n",
      "0  Baseline_GBT  330585.0  238958.0  144812.0  235790.0  0.599427  0.599362   \n",
      "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
      "0     Tuned_LR2  243606.0  324180.0  231791.0  150568.0  0.597578  0.597636   \n",
      "0      Tuned_RF  297800.0  280825.0  177597.0  193923.0  0.608986  0.608974   \n",
      "0     Tuned_RF2  311983.0  246227.0  163414.0  228521.0  0.587500  0.587453   \n",
      "0     Tuned_GBT  313556.0  265304.0  161841.0  209444.0  0.609233  0.609199   \n",
      "0         CV_LR  310536.0  255481.0  164861.0  219267.0  0.595716  0.595677   \n",
      "0         CV_RF  390424.0  149276.0   84973.0  325472.0  0.568019  0.567845   \n",
      "\n",
      "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
      "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
      "0  0.586342   0.684699  0.580327  0.628207            38.34  \n",
      "0  0.592114   0.695387  0.583686  0.634659           116.96  \n",
      "0  0.587362   0.524892  0.651429  0.581355          2386.31  \n",
      "0  0.569858   0.512426  0.618016  0.560290          2518.90  \n",
      "0  0.589526   0.626424  0.605626  0.615849          2089.00  \n",
      "0  0.576670   0.656258  0.577208  0.614200           843.65  \n",
      "0  0.594320   0.659567  0.599533  0.628119          4872.30  \n",
      "0  0.582822   0.653214  0.586135  0.617859           152.83  \n",
      "0  0.590088   0.821259  0.545364  0.655463           173.34  \n"
     ]
    }
   ],
   "source": [
    "#itterate through model_list to write each pickel into the pandas data frame\n",
    "\n",
    "for model in model_list:\n",
    "    print(model)\n",
    "    with open(model, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    print(data)\n",
    "    new_data = pd.DataFrame([[data[0], data[1], data[2], data[3], data[4], data[5], data[6], data[7], data[8], data[9], data[10], data[11]]], \n",
    "                            columns=['model_name', 'TP', 'TN', 'FP', 'FN', 'Accuracy', 'AUROC', 'AUPR', 'Precision', 'Recall', 'F1', 'Train_Test_Time'])\n",
    "    #print(new_data)\n",
    "    data_out = pd.concat([data_out, new_data])\n",
    "    print(data_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Train_Test_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline_LR</td>\n",
       "      <td>229461.0</td>\n",
       "      <td>325116.0</td>\n",
       "      <td>245936.0</td>\n",
       "      <td>149632.0</td>\n",
       "      <td>0.583676</td>\n",
       "      <td>0.583745</td>\n",
       "      <td>0.558349</td>\n",
       "      <td>0.482672</td>\n",
       "      <td>0.605289</td>\n",
       "      <td>0.537071</td>\n",
       "      <td>45.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline_RF</td>\n",
       "      <td>325504.0</td>\n",
       "      <td>239354.0</td>\n",
       "      <td>149893.0</td>\n",
       "      <td>235394.0</td>\n",
       "      <td>0.594497</td>\n",
       "      <td>0.594435</td>\n",
       "      <td>0.586342</td>\n",
       "      <td>0.684699</td>\n",
       "      <td>0.580327</td>\n",
       "      <td>0.628207</td>\n",
       "      <td>38.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Baseline_GBT</td>\n",
       "      <td>330585.0</td>\n",
       "      <td>238958.0</td>\n",
       "      <td>144812.0</td>\n",
       "      <td>235790.0</td>\n",
       "      <td>0.599427</td>\n",
       "      <td>0.599362</td>\n",
       "      <td>0.592114</td>\n",
       "      <td>0.695387</td>\n",
       "      <td>0.583686</td>\n",
       "      <td>0.634659</td>\n",
       "      <td>116.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned_LR</td>\n",
       "      <td>249532.0</td>\n",
       "      <td>341227.0</td>\n",
       "      <td>225865.0</td>\n",
       "      <td>133521.0</td>\n",
       "      <td>0.621757</td>\n",
       "      <td>0.621823</td>\n",
       "      <td>0.587362</td>\n",
       "      <td>0.524892</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.581355</td>\n",
       "      <td>2386.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned_LR2</td>\n",
       "      <td>243606.0</td>\n",
       "      <td>324180.0</td>\n",
       "      <td>231791.0</td>\n",
       "      <td>150568.0</td>\n",
       "      <td>0.597578</td>\n",
       "      <td>0.597636</td>\n",
       "      <td>0.569858</td>\n",
       "      <td>0.512426</td>\n",
       "      <td>0.618016</td>\n",
       "      <td>0.560290</td>\n",
       "      <td>2518.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned_RF</td>\n",
       "      <td>297800.0</td>\n",
       "      <td>280825.0</td>\n",
       "      <td>177597.0</td>\n",
       "      <td>193923.0</td>\n",
       "      <td>0.608986</td>\n",
       "      <td>0.608974</td>\n",
       "      <td>0.589526</td>\n",
       "      <td>0.626424</td>\n",
       "      <td>0.605626</td>\n",
       "      <td>0.615849</td>\n",
       "      <td>2089.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned_RF2</td>\n",
       "      <td>311983.0</td>\n",
       "      <td>246227.0</td>\n",
       "      <td>163414.0</td>\n",
       "      <td>228521.0</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.587453</td>\n",
       "      <td>0.576670</td>\n",
       "      <td>0.656258</td>\n",
       "      <td>0.577208</td>\n",
       "      <td>0.614200</td>\n",
       "      <td>843.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tuned_GBT</td>\n",
       "      <td>313556.0</td>\n",
       "      <td>265304.0</td>\n",
       "      <td>161841.0</td>\n",
       "      <td>209444.0</td>\n",
       "      <td>0.609233</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.594320</td>\n",
       "      <td>0.659567</td>\n",
       "      <td>0.599533</td>\n",
       "      <td>0.628119</td>\n",
       "      <td>4872.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_LR</td>\n",
       "      <td>310536.0</td>\n",
       "      <td>255481.0</td>\n",
       "      <td>164861.0</td>\n",
       "      <td>219267.0</td>\n",
       "      <td>0.595716</td>\n",
       "      <td>0.595677</td>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.653214</td>\n",
       "      <td>0.586135</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>152.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CV_RF</td>\n",
       "      <td>390424.0</td>\n",
       "      <td>149276.0</td>\n",
       "      <td>84973.0</td>\n",
       "      <td>325472.0</td>\n",
       "      <td>0.568019</td>\n",
       "      <td>0.567845</td>\n",
       "      <td>0.590088</td>\n",
       "      <td>0.821259</td>\n",
       "      <td>0.545364</td>\n",
       "      <td>0.655463</td>\n",
       "      <td>173.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name        TP        TN        FP        FN  Accuracy     AUROC  \\\n",
       "0   Baseline_LR  229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
       "0   Baseline_RF  325504.0  239354.0  149893.0  235394.0  0.594497  0.594435   \n",
       "0  Baseline_GBT  330585.0  238958.0  144812.0  235790.0  0.599427  0.599362   \n",
       "0      Tuned_LR  249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
       "0     Tuned_LR2  243606.0  324180.0  231791.0  150568.0  0.597578  0.597636   \n",
       "0      Tuned_RF  297800.0  280825.0  177597.0  193923.0  0.608986  0.608974   \n",
       "0     Tuned_RF2  311983.0  246227.0  163414.0  228521.0  0.587500  0.587453   \n",
       "0     Tuned_GBT  313556.0  265304.0  161841.0  209444.0  0.609233  0.609199   \n",
       "0         CV_LR  310536.0  255481.0  164861.0  219267.0  0.595716  0.595677   \n",
       "0         CV_RF  390424.0  149276.0   84973.0  325472.0  0.568019  0.567845   \n",
       "\n",
       "       AUPR  Precision    Recall        F1  Train_Test_Time  \n",
       "0  0.558349   0.482672  0.605289  0.537071            45.69  \n",
       "0  0.586342   0.684699  0.580327  0.628207            38.34  \n",
       "0  0.592114   0.695387  0.583686  0.634659           116.96  \n",
       "0  0.587362   0.524892  0.651429  0.581355          2386.31  \n",
       "0  0.569858   0.512426  0.618016  0.560290          2518.90  \n",
       "0  0.589526   0.626424  0.605626  0.615849          2089.00  \n",
       "0  0.576670   0.656258  0.577208  0.614200           843.65  \n",
       "0  0.594320   0.659567  0.599533  0.628119          4872.30  \n",
       "0  0.582822   0.653214  0.586135  0.617859           152.83  \n",
       "0  0.590088   0.821259  0.545364  0.655463           173.34  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verify that pandas dataframe was written correctly\n",
    "data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_name', 'TP', 'TN', 'FP', 'FN', 'Accuracy', 'AUROC', 'AUPR',\n",
       "       'Precision', 'Recall', 'F1', 'Train_Test_Time'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set our index to the model name\n",
    "\n",
    "data_out = data_out.set_index('model_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Train_Test_Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Baseline_LR</th>\n",
       "      <td>229461.0</td>\n",
       "      <td>325116.0</td>\n",
       "      <td>245936.0</td>\n",
       "      <td>149632.0</td>\n",
       "      <td>0.583676</td>\n",
       "      <td>0.583745</td>\n",
       "      <td>0.558349</td>\n",
       "      <td>0.482672</td>\n",
       "      <td>0.605289</td>\n",
       "      <td>0.537071</td>\n",
       "      <td>45.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline_RF</th>\n",
       "      <td>325504.0</td>\n",
       "      <td>239354.0</td>\n",
       "      <td>149893.0</td>\n",
       "      <td>235394.0</td>\n",
       "      <td>0.594497</td>\n",
       "      <td>0.594435</td>\n",
       "      <td>0.586342</td>\n",
       "      <td>0.684699</td>\n",
       "      <td>0.580327</td>\n",
       "      <td>0.628207</td>\n",
       "      <td>38.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline_GBT</th>\n",
       "      <td>330585.0</td>\n",
       "      <td>238958.0</td>\n",
       "      <td>144812.0</td>\n",
       "      <td>235790.0</td>\n",
       "      <td>0.599427</td>\n",
       "      <td>0.599362</td>\n",
       "      <td>0.592114</td>\n",
       "      <td>0.695387</td>\n",
       "      <td>0.583686</td>\n",
       "      <td>0.634659</td>\n",
       "      <td>116.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_LR</th>\n",
       "      <td>249532.0</td>\n",
       "      <td>341227.0</td>\n",
       "      <td>225865.0</td>\n",
       "      <td>133521.0</td>\n",
       "      <td>0.621757</td>\n",
       "      <td>0.621823</td>\n",
       "      <td>0.587362</td>\n",
       "      <td>0.524892</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.581355</td>\n",
       "      <td>2386.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_LR2</th>\n",
       "      <td>243606.0</td>\n",
       "      <td>324180.0</td>\n",
       "      <td>231791.0</td>\n",
       "      <td>150568.0</td>\n",
       "      <td>0.597578</td>\n",
       "      <td>0.597636</td>\n",
       "      <td>0.569858</td>\n",
       "      <td>0.512426</td>\n",
       "      <td>0.618016</td>\n",
       "      <td>0.560290</td>\n",
       "      <td>2518.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_RF</th>\n",
       "      <td>297800.0</td>\n",
       "      <td>280825.0</td>\n",
       "      <td>177597.0</td>\n",
       "      <td>193923.0</td>\n",
       "      <td>0.608986</td>\n",
       "      <td>0.608974</td>\n",
       "      <td>0.589526</td>\n",
       "      <td>0.626424</td>\n",
       "      <td>0.605626</td>\n",
       "      <td>0.615849</td>\n",
       "      <td>2089.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_RF2</th>\n",
       "      <td>311983.0</td>\n",
       "      <td>246227.0</td>\n",
       "      <td>163414.0</td>\n",
       "      <td>228521.0</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.587453</td>\n",
       "      <td>0.576670</td>\n",
       "      <td>0.656258</td>\n",
       "      <td>0.577208</td>\n",
       "      <td>0.614200</td>\n",
       "      <td>843.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_GBT</th>\n",
       "      <td>313556.0</td>\n",
       "      <td>265304.0</td>\n",
       "      <td>161841.0</td>\n",
       "      <td>209444.0</td>\n",
       "      <td>0.609233</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.594320</td>\n",
       "      <td>0.659567</td>\n",
       "      <td>0.599533</td>\n",
       "      <td>0.628119</td>\n",
       "      <td>4872.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_LR</th>\n",
       "      <td>310536.0</td>\n",
       "      <td>255481.0</td>\n",
       "      <td>164861.0</td>\n",
       "      <td>219267.0</td>\n",
       "      <td>0.595716</td>\n",
       "      <td>0.595677</td>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.653214</td>\n",
       "      <td>0.586135</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>152.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_RF</th>\n",
       "      <td>390424.0</td>\n",
       "      <td>149276.0</td>\n",
       "      <td>84973.0</td>\n",
       "      <td>325472.0</td>\n",
       "      <td>0.568019</td>\n",
       "      <td>0.567845</td>\n",
       "      <td>0.590088</td>\n",
       "      <td>0.821259</td>\n",
       "      <td>0.545364</td>\n",
       "      <td>0.655463</td>\n",
       "      <td>173.34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TP        TN        FP        FN  Accuracy     AUROC  \\\n",
       "model_name                                                                 \n",
       "Baseline_LR   229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
       "Baseline_RF   325504.0  239354.0  149893.0  235394.0  0.594497  0.594435   \n",
       "Baseline_GBT  330585.0  238958.0  144812.0  235790.0  0.599427  0.599362   \n",
       "Tuned_LR      249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
       "Tuned_LR2     243606.0  324180.0  231791.0  150568.0  0.597578  0.597636   \n",
       "Tuned_RF      297800.0  280825.0  177597.0  193923.0  0.608986  0.608974   \n",
       "Tuned_RF2     311983.0  246227.0  163414.0  228521.0  0.587500  0.587453   \n",
       "Tuned_GBT     313556.0  265304.0  161841.0  209444.0  0.609233  0.609199   \n",
       "CV_LR         310536.0  255481.0  164861.0  219267.0  0.595716  0.595677   \n",
       "CV_RF         390424.0  149276.0   84973.0  325472.0  0.568019  0.567845   \n",
       "\n",
       "                  AUPR  Precision    Recall        F1  Train_Test_Time  \n",
       "model_name                                                              \n",
       "Baseline_LR   0.558349   0.482672  0.605289  0.537071            45.69  \n",
       "Baseline_RF   0.586342   0.684699  0.580327  0.628207            38.34  \n",
       "Baseline_GBT  0.592114   0.695387  0.583686  0.634659           116.96  \n",
       "Tuned_LR      0.587362   0.524892  0.651429  0.581355          2386.31  \n",
       "Tuned_LR2     0.569858   0.512426  0.618016  0.560290          2518.90  \n",
       "Tuned_RF      0.589526   0.626424  0.605626  0.615849          2089.00  \n",
       "Tuned_RF2     0.576670   0.656258  0.577208  0.614200           843.65  \n",
       "Tuned_GBT     0.594320   0.659567  0.599533  0.628119          4872.30  \n",
       "CV_LR         0.582822   0.653214  0.586135  0.617859           152.83  \n",
       "CV_RF         0.590088   0.821259  0.545364  0.655463           173.34  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the list for F1 score\n",
    "data_out = data_out.sort_values(by=['F1'], ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TP</th>\n",
       "      <th>TN</th>\n",
       "      <th>FP</th>\n",
       "      <th>FN</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUROC</th>\n",
       "      <th>AUPR</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Train_Test_Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CV_RF</th>\n",
       "      <td>390424.0</td>\n",
       "      <td>149276.0</td>\n",
       "      <td>84973.0</td>\n",
       "      <td>325472.0</td>\n",
       "      <td>0.568019</td>\n",
       "      <td>0.567845</td>\n",
       "      <td>0.590088</td>\n",
       "      <td>0.821259</td>\n",
       "      <td>0.545364</td>\n",
       "      <td>0.655463</td>\n",
       "      <td>173.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline_GBT</th>\n",
       "      <td>330585.0</td>\n",
       "      <td>238958.0</td>\n",
       "      <td>144812.0</td>\n",
       "      <td>235790.0</td>\n",
       "      <td>0.599427</td>\n",
       "      <td>0.599362</td>\n",
       "      <td>0.592114</td>\n",
       "      <td>0.695387</td>\n",
       "      <td>0.583686</td>\n",
       "      <td>0.634659</td>\n",
       "      <td>116.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline_RF</th>\n",
       "      <td>325504.0</td>\n",
       "      <td>239354.0</td>\n",
       "      <td>149893.0</td>\n",
       "      <td>235394.0</td>\n",
       "      <td>0.594497</td>\n",
       "      <td>0.594435</td>\n",
       "      <td>0.586342</td>\n",
       "      <td>0.684699</td>\n",
       "      <td>0.580327</td>\n",
       "      <td>0.628207</td>\n",
       "      <td>38.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_GBT</th>\n",
       "      <td>313556.0</td>\n",
       "      <td>265304.0</td>\n",
       "      <td>161841.0</td>\n",
       "      <td>209444.0</td>\n",
       "      <td>0.609233</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.594320</td>\n",
       "      <td>0.659567</td>\n",
       "      <td>0.599533</td>\n",
       "      <td>0.628119</td>\n",
       "      <td>4872.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV_LR</th>\n",
       "      <td>310536.0</td>\n",
       "      <td>255481.0</td>\n",
       "      <td>164861.0</td>\n",
       "      <td>219267.0</td>\n",
       "      <td>0.595716</td>\n",
       "      <td>0.595677</td>\n",
       "      <td>0.582822</td>\n",
       "      <td>0.653214</td>\n",
       "      <td>0.586135</td>\n",
       "      <td>0.617859</td>\n",
       "      <td>152.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_RF</th>\n",
       "      <td>297800.0</td>\n",
       "      <td>280825.0</td>\n",
       "      <td>177597.0</td>\n",
       "      <td>193923.0</td>\n",
       "      <td>0.608986</td>\n",
       "      <td>0.608974</td>\n",
       "      <td>0.589526</td>\n",
       "      <td>0.626424</td>\n",
       "      <td>0.605626</td>\n",
       "      <td>0.615849</td>\n",
       "      <td>2089.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_RF2</th>\n",
       "      <td>311983.0</td>\n",
       "      <td>246227.0</td>\n",
       "      <td>163414.0</td>\n",
       "      <td>228521.0</td>\n",
       "      <td>0.587500</td>\n",
       "      <td>0.587453</td>\n",
       "      <td>0.576670</td>\n",
       "      <td>0.656258</td>\n",
       "      <td>0.577208</td>\n",
       "      <td>0.614200</td>\n",
       "      <td>843.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_LR</th>\n",
       "      <td>249532.0</td>\n",
       "      <td>341227.0</td>\n",
       "      <td>225865.0</td>\n",
       "      <td>133521.0</td>\n",
       "      <td>0.621757</td>\n",
       "      <td>0.621823</td>\n",
       "      <td>0.587362</td>\n",
       "      <td>0.524892</td>\n",
       "      <td>0.651429</td>\n",
       "      <td>0.581355</td>\n",
       "      <td>2386.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tuned_LR2</th>\n",
       "      <td>243606.0</td>\n",
       "      <td>324180.0</td>\n",
       "      <td>231791.0</td>\n",
       "      <td>150568.0</td>\n",
       "      <td>0.597578</td>\n",
       "      <td>0.597636</td>\n",
       "      <td>0.569858</td>\n",
       "      <td>0.512426</td>\n",
       "      <td>0.618016</td>\n",
       "      <td>0.560290</td>\n",
       "      <td>2518.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Baseline_LR</th>\n",
       "      <td>229461.0</td>\n",
       "      <td>325116.0</td>\n",
       "      <td>245936.0</td>\n",
       "      <td>149632.0</td>\n",
       "      <td>0.583676</td>\n",
       "      <td>0.583745</td>\n",
       "      <td>0.558349</td>\n",
       "      <td>0.482672</td>\n",
       "      <td>0.605289</td>\n",
       "      <td>0.537071</td>\n",
       "      <td>45.69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    TP        TN        FP        FN  Accuracy     AUROC  \\\n",
       "model_name                                                                 \n",
       "CV_RF         390424.0  149276.0   84973.0  325472.0  0.568019  0.567845   \n",
       "Baseline_GBT  330585.0  238958.0  144812.0  235790.0  0.599427  0.599362   \n",
       "Baseline_RF   325504.0  239354.0  149893.0  235394.0  0.594497  0.594435   \n",
       "Tuned_GBT     313556.0  265304.0  161841.0  209444.0  0.609233  0.609199   \n",
       "CV_LR         310536.0  255481.0  164861.0  219267.0  0.595716  0.595677   \n",
       "Tuned_RF      297800.0  280825.0  177597.0  193923.0  0.608986  0.608974   \n",
       "Tuned_RF2     311983.0  246227.0  163414.0  228521.0  0.587500  0.587453   \n",
       "Tuned_LR      249532.0  341227.0  225865.0  133521.0  0.621757  0.621823   \n",
       "Tuned_LR2     243606.0  324180.0  231791.0  150568.0  0.597578  0.597636   \n",
       "Baseline_LR   229461.0  325116.0  245936.0  149632.0  0.583676  0.583745   \n",
       "\n",
       "                  AUPR  Precision    Recall        F1  Train_Test_Time  \n",
       "model_name                                                              \n",
       "CV_RF         0.590088   0.821259  0.545364  0.655463           173.34  \n",
       "Baseline_GBT  0.592114   0.695387  0.583686  0.634659           116.96  \n",
       "Baseline_RF   0.586342   0.684699  0.580327  0.628207            38.34  \n",
       "Tuned_GBT     0.594320   0.659567  0.599533  0.628119          4872.30  \n",
       "CV_LR         0.582822   0.653214  0.586135  0.617859           152.83  \n",
       "Tuned_RF      0.589526   0.626424  0.605626  0.615849          2089.00  \n",
       "Tuned_RF2     0.576670   0.656258  0.577208  0.614200           843.65  \n",
       "Tuned_LR      0.587362   0.524892  0.651429  0.581355          2386.31  \n",
       "Tuned_LR2     0.569858   0.512426  0.618016  0.560290          2518.90  \n",
       "Baseline_LR   0.558349   0.482672  0.605289  0.537071            45.69  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the pandas df for use in final report\n",
    "\n",
    "data_out.to_csv('Model_Results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Original Code, Archived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code developed to read in original CSV.  Replaced with parquet file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom schema.  \n",
    "\n",
    "customSchema = StructType([\n",
    "    StructField('Trip_ID', StringType(), True),        \n",
    "    StructField('Trip_Start_Timestamp', StringType(), True),\n",
    "    StructField('Trip_End_Timestamp', StringType(), True),\n",
    "    StructField('Trip_Seconds', DoubleType(), True),\n",
    "    StructField('Trip_Miles', DoubleType(), True),\n",
    "    StructField('Pickup_Census_Tract', StringType(), True),\n",
    "    StructField('Dropoff_Census_Tract', StringType(), True),\n",
    "    StructField('Pickup_Community_Area', DoubleType(), True),\n",
    "    StructField('Dropoff_Community_Area', DoubleType(), True),\n",
    "    StructField(\"Fare\", DoubleType(), True),\n",
    "    StructField(\"Tip\", DoubleType(), True),\n",
    "    StructField(\"Additional_Charges\", DoubleType(), True),\n",
    "    StructField(\"Trip_Total\", StringType(), True),\n",
    "    StructField(\"Shared_Trip_Authorized\", BooleanType(), True),\n",
    "    StructField(\"Trips_Pooled\", DoubleType(), True),\n",
    "    StructField('Pickup_Centroid_Latitude', StringType(), True),\n",
    "    StructField('Pickup_Centroid_Longitude', StringType(), True),\n",
    "    StructField('Pickup_Centroid_Location', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Latitude', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Longitude', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Location', StringType(), True)])\n",
    "\n",
    "#old readin.  Infer is slow for large dataset\n",
    "#df = spark.read.csv('/../../project/ds5559/Alice_Ed_Michael_Sam_project/BigTrips.csv', header = True, inferSchema=True)\n",
    "\n",
    "#read in the data to a dataframe\n",
    "df = spark.read.csv('/../../project/ds5559/Alice_Ed_Michael_Sam_project/BigTrips.csv', header = True, schema=customSchema)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doesn't update if you don't resave the variable\n",
    "\n",
    "df = df.drop('Pickup_Census_Tract',\n",
    "             'Dropoff_Census_Tract',\n",
    "             'Pickup_Centroid_Latitude',\n",
    "             'Pickup_Centroid_Longitude', \n",
    "             'Pickup_Centroid_Location', \n",
    "             'Dropoff_Centroid_Latitude', \n",
    "             'Dropoff_Centroid_Longitude', \n",
    "             'Dropoff_Centroid_Location')\n",
    "\n",
    "#'Trip_End_Timestamp' keep for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.sample(False, .05, seed = 2021) #decreased our sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the big df for now\n",
    "del (df)\n",
    "\n",
    "#hopefully that will make things faster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill our NA community areas\n",
    "\n",
    "df2 = df2.na.fill(value=78,subset=['Pickup_Community_Area', 'Dropoff_Community_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a binary tip/no tip indicator\n",
    "# https://spark.apache.org/docs/2.2.0/ml-features.html#binarizer\n",
    "\n",
    "#binarized tip seems to be causing problems.  Change its name to label as that is that the packages are expecting\n",
    "\n",
    "binarizer = Binarizer(threshold=0, inputCol=\"Tip\", outputCol=\"label\")\n",
    "df2 = binarizer.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumn(\"Trip_Start_TS\", F.to_timestamp(F.col(\"Trip_Start_Timestamp\"), \"MM/dd/yyyy hh:mm:ss a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumn('Trip_Year',F.year(F.to_timestamp('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_Month',F.month(F.to_timestamp('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_WeekNumber',F.weekofyear(F.to_timestamp('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_DayofWeek', F.dayofweek(F.col('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_Start_Hour', F.hour(F.col('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_Start_Minute', F.minute(F.col('Trip_Start_TS'))) \\\n",
    "         .withColumn('Date', F.to_date(F.col('Trip_Start_TS')))\n",
    "         \n",
    "df2.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "\n",
    "# our model didn't work on the standard test train split.  Prof. Tashman recomended upscalling the help with the imbalanced dataset.\n",
    "#from https://spark.apache.org/docs/2.1.0/ml-tuning.html#train-validation-split\n",
    "\n",
    "train_inital, test = df2.randomSplit([0.8, 0.2], seed=2021)\n",
    "\n",
    "# cahce our test values for later speed\n",
    "test.cache()\n",
    "\n",
    "# oversampleing code sample\n",
    "# https://stackoverflow.com/questions/53273133/how-to-perform-up-sampling-using-sample-functionpy-spark\n",
    "\n",
    "df_a = train_inital.filter(train_inital['label'] == 0)\n",
    "df_b = train_inital.filter(train_inital['label'] == 1)\n",
    "\n",
    "org_a_count = df_a.count()\n",
    "org_b_count = df_b.count() \n",
    "\n",
    "\n",
    "ratio = df_a.count() / df_b.count()\n",
    "# print(ratio)\n",
    "\n",
    "df_b_overampled = df_b.sample(withReplacement=True, fraction=ratio, seed=2021)\n",
    "\n",
    "# cahce our train values for later speed\n",
    "train = df_a.unionAll(df_b_overampled).cache()\n",
    "\n",
    "df_af = train.filter(train_inital['label'] == 0)\n",
    "df_bf = train.filter(train_inital['label'] == 1)\n",
    "fin_a_count = df_af.count()\n",
    "fin_b_count = df_bf.count() \n",
    "\n",
    "print(\"Original No Tip Count: \", org_a_count)\n",
    "print(\"Original Tip Count   : \", org_b_count)\n",
    "print(\"\")\n",
    "print(\"Final No Tip Count   : \", fin_a_count)\n",
    "print(\"Final Tip Count      : \", fin_b_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR inital results gridsearch\n",
    "\n",
    "'''\n",
    "25k set\n",
    "best from tuning inital (accuracy):\n",
    "addGrid(lr.regParam, [0.03, 0.05, 0.07]) \\\n",
    ".addGrid(lr.elasticNetParam, [0.15, 0.2, 0.25]) \\\n",
    ".addGrid(lr.maxIter, [8, 9, 10, 11, 12]) \n",
    "\n",
    "regParam= 0.03\n",
    "elasticNetParam = 0.15\n",
    "maxIter = 12\n",
    " \n",
    "Confusion Matrix\n",
    "[[1842. 2203.]\n",
    " [ 193.  595.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.5042416718394372\n",
    "Accuracy from MulticlassMetrics:  0.5042416718394372\n",
    "\n",
    "Area Under the ROC 0.6052265753923187\n",
    "\n",
    "Area Under the PR Curve 0.2065770273222743\n",
    "Summary Stats\n",
    "Precision = 0.5042416718394372\n",
    "Recall = 0.5042416718394372\n",
    "F1 Score = 0.5042416718394372\n",
    "Weighted recall = 0.5042416718394371\n",
    "Weighted precision = 0.7922492654683645\n",
    "Weighted F(1) Score = 0.5612342974368173\n",
    "Weighted F(0.5) Score = 0.6730989071456968\n",
    "Weighted false positive rate = 0.2937885210547999\n",
    "\n",
    "2nd round:\n",
    "\n",
    "lr_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.02, 0.03]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.05, 0.1, 0.15]) \\\n",
    "    .addGrid(lr.maxIter, [11, 12, 13, 15]) \\\n",
    "\n",
    "regParam= 0.03\n",
    "elasticNetParam = 0.15\n",
    "maxIter = 11\n",
    "\n",
    "Confusion Matrix\n",
    "[[1815. 2230.]\n",
    " [ 183.  605.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.5007241878750258\n",
    "Accuracy from MulticlassMetrics:  0.5007241878750258\n",
    "\n",
    "Area Under the ROC 0.6082342994108162\n",
    "\n",
    "Area Under the PR Curve 0.2075564549699384\n",
    "Summary Stats\n",
    "Precision = 0.5007241878750258\n",
    "Recall = 0.5007241878750258\n",
    "F1 Score = 0.5007241878750258\n",
    "Weighted recall = 0.5007241878750258\n",
    "Weighted precision = 0.7950908896146499\n",
    "Weighted F(1) Score = 0.5572078454446675\n",
    "Weighted F(0.5) Score = 0.6716684076809212\n",
    "Weighted false positive rate = 0.28425558905339354\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF inital results gridsearch\n",
    "\n",
    "'''\n",
    "best from tuning inital (accuracy):\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5, 10]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .addGrid(rf.impurity, [\"entropy\", \"gini\"])\\\n",
    "    .build()\n",
    "\n",
    "numTrees = 10\n",
    "maxDepth = 10\n",
    "impurity = gini\n",
    " \n",
    "Confusion Matrix\n",
    "[[2901. 1144.]\n",
    " [ 456.  332.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6689426857024623\n",
    "Accuracy from MulticlassMetrics:  0.6689426857024623\n",
    "\n",
    "Area Under the ROC 0.5692507513819781\n",
    "\n",
    "Area Under the PR Curve 0.2070259967551608\n",
    "Summary Stats\n",
    "Precision = 0.6689426857024623\n",
    "Recall = 0.6689426857024623\n",
    "F1 Score = 0.6689426857024623\n",
    "Weighted recall = 0.6689426857024622\n",
    "Weighted precision = 0.7599403563099746\n",
    "Weighted F(1) Score = 0.7038591473392332\n",
    "Weighted F(0.5) Score = 0.735232181263078\n",
    "Weighted false positive rate = 0.530441182938506\n",
    "\n",
    "2nd attempt:\n",
    "\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5, 10, 15]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .addGrid(rf.impurity, [\"entropy\", \"gini\"])\\\n",
    "    .addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt'])\\\n",
    "    .build()\n",
    "\n",
    "\n",
    "numTrees = 10\n",
    "maxDepth = 15\n",
    "impurity = gini\n",
    "featureSubsetStrategy = auto\n",
    "\n",
    "Confusion Matrix\n",
    "[[2663. 1382.]\n",
    " [ 388.  400.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6337678460583489\n",
    "Accuracy from MulticlassMetrics:  0.6337678460583489\n",
    "\n",
    "Area Under the ROC 0.5829789236570811\n",
    "\n",
    "Area Under the PR Curve 0.209345437091233\n",
    "Summary Stats\n",
    "Precision = 0.6337678460583489\n",
    "Recall = 0.6337678460583489\n",
    "F1 Score = 0.6337678460583489\n",
    "Weighted recall = 0.6337678460583488\n",
    "Weighted precision = 0.7671159775546591\n",
    "Weighted F(1) Score = 0.6789410276493224\n",
    "Weighted F(0.5) Score = 0.7270236282319229\n",
    "Weighted false positive rate = 0.46780999874418644\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBT inital results gridsearch\n",
    "\n",
    "\n",
    "'''\n",
    "best from tuning inital (accuracy):\n",
    "gbt_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [5, 10, 20]) \\\n",
    "    .build()\n",
    "\n",
    "maxIter = 20\n",
    "\n",
    "Confusion Matrix\n",
    "[[2798. 1247.]\n",
    " [ 423.  365.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.654458928201945\n",
    "Accuracy from MulticlassMetrics:  0.654458928201945\n",
    "\n",
    "Area Under the ROC 0.5774580700620556\n",
    "\n",
    "Area Under the PR Curve 0.2094152550126291\n",
    "Summary Stats\n",
    "Precision = 0.654458928201945\n",
    "Recall = 0.654458928201945\n",
    "F1 Score = 0.654458928201945\n",
    "Weighted recall = 0.654458928201945\n",
    "Weighted precision = 0.7639586098089827\n",
    "Weighted F(1) Score = 0.6941837869282138\n",
    "Weighted F(0.5) Score = 0.7327747544723259\n",
    "Weighted false positive rate = 0.4995427880778336\n",
    "\n",
    "\n",
    "maxIter = 40\n",
    "\n",
    "Confusion Matrix\n",
    "[[2571. 1474.]\n",
    " [ 382.  406.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6159735154148562\n",
    "Accuracy from MulticlassMetrics:  0.6159735154148562\n",
    "\n",
    "Area Under the ROC 0.5754139659791808\n",
    "\n",
    "Area Under the PR Curve 0.20313239804234073\n",
    "Summary Stats\n",
    "Precision = 0.6159735154148562\n",
    "Recall = 0.6159735154148562\n",
    "F1 Score = 0.6159735154148562\n",
    "Weighted recall = 0.6159735154148562\n",
    "Weighted precision = 0.7638968296438198\n",
    "Weighted F(1) Score = 0.6646010165217533\n",
    "Weighted F(0.5) Score = 0.7183436330713325\n",
    "Weighted false positive rate = 0.4651455834564943\n",
    "\n",
    "\n",
    "gbt_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [5, 10])\\\n",
    "    .addGrid(gbt.maxDepth, [5, 10])\\\n",
    "    .build()\n",
    "    \n",
    "maxIter = 5\n",
    "maxDepth = 5\n",
    "\n",
    "Confusion Matrix\n",
    "[[2863. 1182.]\n",
    " [ 469.  319.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6583902338092282\n",
    "Accuracy from MulticlassMetrics:  0.6583902338092282\n",
    "\n",
    "Area Under the ROC 0.5563048634335804\n",
    "\n",
    "Area Under the PR Curve 0.19780050930331394\n",
    "Summary Stats\n",
    "Precision = 0.6583902338092282\n",
    "Recall = 0.6583902338092282\n",
    "F1 Score = 0.6583902338092282\n",
    "Weighted recall = 0.6583902338092282\n",
    "Weighted precision = 0.7537989743798752\n",
    "Weighted F(1) Score = 0.6950856095348379\n",
    "Weighted F(0.5) Score = 0.7279222226014918\n",
    "Weighted false positive rate = 0.5457805069420676\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
