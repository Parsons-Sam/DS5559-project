{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DS5559 Final Project Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Left Twix Members\n",
    "\n",
    "* Alice Wright - aew7j\n",
    "* Edward Thompson - ejt8b\n",
    "* Michael Davies -  mld9s\n",
    "* Sam Parsons - sp8hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In STAT 6021 members of our cohort looked at Transportation Network Company data sets to see if there was a potential relationship between tipping and other indicators, specifically with “transportation network providers” i.e. rideshares such as Uber, Lyft, etc.  At that point in our Data Science journey we did not have the skills or equipment to investigate this question in depth.  \n",
    "\n",
    "Utilizing machine learning skills from SYS 6018 and applying Spark to this dataset we hope to come up with a more robust set of answers and potentially a better predictor of tipping. With other classification algorithms such as random forest and the heavy-weight data processing of Spark, will we be able to create a more robust predictive model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Questions from the TNC Data:\n",
    "\n",
    "* Can it be predicted what fares are most likely to tip the driver?\n",
    "* Is there a relationship between time of the fare and tipping? (workday stat, bar close, weekday, weekend, etc)\n",
    "* Is there a relationship between start or end location of the ride and tipping? (downtown pickup, north shore, airport, etc)\n",
    "* Is there a relationship between length or cost of ride and tipping? (do longer rides result in tips)\n",
    "* Using this data would we be able to make recommendations to drivers to maximize likelihood of receiving a tip?\n",
    "* Is the likelihood of tipping changing over time?  Are more rides being tipped?\n",
    "* Are there re-identification abilities in this dataset? For instance, can we find records for a person who reliably takes a rideshare to/from work every day thereby linking a home address to a work address?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, joining in additional datasets may yield answers to questions about external factors such as:\n",
    "* How did news reporting/social media on rideshare companies correlate with tipping?\n",
    "* What relationship(s) does trip demand have with the stocks of these companies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source:\n",
    "The best data source for this appears to be from the City of Chicago, as it is large (169M records and 21 columns), relatively clean, anonymized, and accessible via API.\n",
    "\n",
    "City of Chicago:\n",
    "https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips/m6dm-c72p\n",
    "\n",
    "So far we have only pulled the data down via a CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Rubric\n",
    "\n",
    "* Data Import and PreProcessing | 2 pts\n",
    "\n",
    "* Data splitting/sampling | 1 pt\n",
    "\n",
    "* EDA (min two graphs) | 2 pts\n",
    "\n",
    "* Model construction (min 3 models) | 3 pts\n",
    "\n",
    "* Model evaluation | 2 pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import context manager: SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# import data types\n",
    "# from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType\n",
    "# import pyspark.sql.types as typ\n",
    "# import pyspark.sql.functions as F\n",
    "# import os\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"mllib_classifier\") \\\n",
    "        .config(\"spark.executor.memory\", '21g') \\\n",
    "        .config('spark.executor.cores', '2') \\\n",
    "        .config('spark.executor.instances', '3') \\\n",
    "        .config(\"spark.driver.memory\",'1g') \\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# import data manipulation methods\n",
    "# from pyspark.ml.feature import Binarizer\n",
    "from pyspark.ml import Pipeline  \n",
    "# from pyspark.ml.feature import *  \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.ml.feature import VectorAssembler \n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "#from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in our Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Custom Schema.  \n",
    "This schema was been primarly determined by using a much smaller dataset and letting spark infer the schema.  We encountered an issue with spark reading in the ENTIRE dataset as NULL when there was a type mismatch.  Only the data we are likely to use later has been assigned to a specific type, otherwise it is left as a string type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df = spark.read.parquet(\"/../../project/ds5559/Alice_Ed_Michael_Sam_project/final_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip_ID: string (nullable = true)\n",
      " |-- Trip_Seconds: integer (nullable = true)\n",
      " |-- Trip_Miles: double (nullable = true)\n",
      " |-- Pickup_Census_Tract: string (nullable = true)\n",
      " |-- Dropoff_Census_Tract: string (nullable = true)\n",
      " |-- Pickup_Community_Area: integer (nullable = true)\n",
      " |-- Dropoff_Community_Area: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: double (nullable = true)\n",
      " |-- Additional_Charges_str: double (nullable = true)\n",
      " |-- Trip_Total: double (nullable = true)\n",
      " |-- Shared_Trip_Authorized: boolean (nullable = true)\n",
      " |-- Trips_Pooled: integer (nullable = true)\n",
      " |-- Pickup_Centroid_Latitude: string (nullable = true)\n",
      " |-- Pickup_Centroid_Longitude: string (nullable = true)\n",
      " |-- Pickup_Centroid_Location: string (nullable = true)\n",
      " |-- Dropoff_Centroid_Latitude: string (nullable = true)\n",
      " |-- Dropoff_Centroid_Longitude: string (nullable = true)\n",
      " |-- Dropoff_Centroid_Location: string (nullable = true)\n",
      " |-- Trip_Start_Timestamp: timestamp (nullable = true)\n",
      " |-- Trip_End_Timestamp: timestamp (nullable = true)\n",
      " |-- PostShutdownFlag: integer (nullable = true)\n",
      " |-- Day_Month_str: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- Trip_Year: integer (nullable = true)\n",
      " |-- Trip_Month: integer (nullable = true)\n",
      " |-- Trip_WeekNumber: integer (nullable = true)\n",
      " |-- Trip_DayofWeek: integer (nullable = true)\n",
      " |-- Trip_Start_Hour: integer (nullable = true)\n",
      " |-- Trip_Start_Minute: integer (nullable = true)\n",
      " |-- Trip_End_Hour: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a custom schema.  \n",
    "\n",
    "customSchema = StructType([\n",
    "    StructField('Trip_ID', StringType(), True),        \n",
    "    StructField('Trip_Start_Timestamp', StringType(), True),\n",
    "    StructField('Trip_End_Timestamp', StringType(), True),\n",
    "    StructField('Trip_Seconds', DoubleType(), True),\n",
    "    StructField('Trip_Miles', DoubleType(), True),\n",
    "    StructField('Pickup_Census_Tract', StringType(), True),\n",
    "    StructField('Dropoff_Census_Tract', StringType(), True),\n",
    "    StructField('Pickup_Community_Area', DoubleType(), True),\n",
    "    StructField('Dropoff_Community_Area', DoubleType(), True),\n",
    "    StructField(\"Fare\", DoubleType(), True),\n",
    "    StructField(\"Tip\", DoubleType(), True),\n",
    "    StructField(\"Additional_Charges\", DoubleType(), True),\n",
    "    StructField(\"Trip_Total\", StringType(), True),\n",
    "    StructField(\"Shared_Trip_Authorized\", BooleanType(), True),\n",
    "    StructField(\"Trips_Pooled\", DoubleType(), True),\n",
    "    StructField('Pickup_Centroid_Latitude', StringType(), True),\n",
    "    StructField('Pickup_Centroid_Longitude', StringType(), True),\n",
    "    StructField('Pickup_Centroid_Location', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Latitude', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Longitude', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Location', StringType(), True)])\n",
    "\n",
    "#old readin.  Infer is slow for large dataset\n",
    "#df = spark.read.csv('/../../project/ds5559/Alice_Ed_Michael_Sam_project/BigTrips.csv', header = True, inferSchema=True)\n",
    "\n",
    "#read in the data to a dataframe\n",
    "df = spark.read.csv('/../../project/ds5559/Alice_Ed_Michael_Sam_project/BigTrips.csv', header = True, schema=customSchema)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doesn't update if you don't resave the variable\n",
    "\n",
    "df = df.drop('Pickup_Census_Tract',\n",
    "             'Dropoff_Census_Tract',\n",
    "             'Pickup_Centroid_Latitude',\n",
    "             'Pickup_Centroid_Longitude', \n",
    "             'Pickup_Centroid_Location', \n",
    "             'Dropoff_Centroid_Latitude', \n",
    "             'Dropoff_Centroid_Longitude', \n",
    "             'Dropoff_Centroid_Location')\n",
    "\n",
    "#'Trip_End_Timestamp' keep for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df = p_df.drop('Pickup_Census_Tract',\n",
    "             'Dropoff_Census_Tract',\n",
    "             'Pickup_Centroid_Latitude',\n",
    "             'Pickup_Centroid_Longitude', \n",
    "             'Pickup_Centroid_Location', \n",
    "             'Dropoff_Centroid_Latitude', \n",
    "             'Dropoff_Centroid_Longitude', \n",
    "             'Dropoff_Centroid_Location',\n",
    "             'Day_Month_str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip_ID: string (nullable = true)\n",
      " |-- Trip_Seconds: integer (nullable = true)\n",
      " |-- Trip_Miles: double (nullable = true)\n",
      " |-- Pickup_Community_Area: integer (nullable = true)\n",
      " |-- Dropoff_Community_Area: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: double (nullable = true)\n",
      " |-- Additional_Charges_str: double (nullable = true)\n",
      " |-- Trip_Total: double (nullable = true)\n",
      " |-- Shared_Trip_Authorized: boolean (nullable = true)\n",
      " |-- Trips_Pooled: integer (nullable = true)\n",
      " |-- Trip_Start_Timestamp: timestamp (nullable = true)\n",
      " |-- Trip_End_Timestamp: timestamp (nullable = true)\n",
      " |-- PostShutdownFlag: integer (nullable = true)\n",
      " |-- Day_Month_str: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- Trip_Year: integer (nullable = true)\n",
      " |-- Trip_Month: integer (nullable = true)\n",
      " |-- Trip_WeekNumber: integer (nullable = true)\n",
      " |-- Trip_DayofWeek: integer (nullable = true)\n",
      " |-- Trip_Start_Hour: integer (nullable = true)\n",
      " |-- Trip_Start_Minute: integer (nullable = true)\n",
      " |-- Trip_End_Hour: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.sample(False, .05, seed = 2021) #decreased our sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the big df for now\n",
    "del (df)\n",
    "\n",
    "#hopefully that will make things faster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df.groupby(\"Pickup_Community_Area\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill our NA community areas\n",
    "\n",
    "p_df = p_df.na.fill(value=78,subset=['Pickup_Community_Area', 'Dropoff_Community_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_df.groupby(\"Pickup_Community_Area\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill our NA community areas\n",
    "\n",
    "df2 = df2.na.fill(value=78,subset=['Pickup_Community_Area', 'Dropoff_Community_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a binary tip/no tip indicator\n",
    "# https://spark.apache.org/docs/2.2.0/ml-features.html#binarizer\n",
    "\n",
    "#binarized tip seems to be causing problems.  Change its name to label as that is that the packages are expecting\n",
    "\n",
    "binarizer = Binarizer(threshold=0, inputCol=\"Tip\", outputCol=\"label\")\n",
    "df2 = binarizer.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumn(\"Trip_Start_TS\", F.to_timestamp(F.col(\"Trip_Start_Timestamp\"), \"MM/dd/yyyy hh:mm:ss a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.withColumn('Trip_Year',F.year(F.to_timestamp('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_Month',F.month(F.to_timestamp('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_WeekNumber',F.weekofyear(F.to_timestamp('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_DayofWeek', F.dayofweek(F.col('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_Start_Hour', F.hour(F.col('Trip_Start_TS'))) \\\n",
    "         .withColumn('Trip_Start_Minute', F.minute(F.col('Trip_Start_TS'))) \\\n",
    "         .withColumn('Date', F.to_date(F.col('Trip_Start_TS')))\n",
    "         \n",
    "df2.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "\n",
    "# our model didn't work on the standard test train split.  Prof. Tashman recomended upscalling the help with the imbalanced dataset.\n",
    "#from https://spark.apache.org/docs/2.1.0/ml-tuning.html#train-validation-split\n",
    "\n",
    "train_inital, test = df2.randomSplit([0.8, 0.2], seed=2021)\n",
    "\n",
    "# cahce our test values for later speed\n",
    "test.cache()\n",
    "\n",
    "# oversampleing code sample\n",
    "# https://stackoverflow.com/questions/53273133/how-to-perform-up-sampling-using-sample-functionpy-spark\n",
    "\n",
    "df_a = train_inital.filter(train_inital['label'] == 0)\n",
    "df_b = train_inital.filter(train_inital['label'] == 1)\n",
    "\n",
    "org_a_count = df_a.count()\n",
    "org_b_count = df_b.count() \n",
    "\n",
    "\n",
    "ratio = df_a.count() / df_b.count()\n",
    "# print(ratio)\n",
    "\n",
    "df_b_overampled = df_b.sample(withReplacement=True, fraction=ratio, seed=2021)\n",
    "\n",
    "# cahce our train values for later speed\n",
    "train = df_a.unionAll(df_b_overampled).cache()\n",
    "\n",
    "df_af = train.filter(train_inital['label'] == 0)\n",
    "df_bf = train.filter(train_inital['label'] == 1)\n",
    "fin_a_count = df_af.count()\n",
    "fin_b_count = df_bf.count() \n",
    "\n",
    "print(\"Original No Tip Count: \", org_a_count)\n",
    "print(\"Original Tip Count   : \", org_b_count)\n",
    "print(\"\")\n",
    "print(\"Final No Tip Count   : \", fin_a_count)\n",
    "print(\"Final Tip Count      : \", fin_b_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original No Tip Count:  1900289\n",
      "Original Tip Count   :  1900435\n"
     ]
    }
   ],
   "source": [
    "# split the data\n",
    "\n",
    "# our model didn't work on the standard test train split.  Prof. Tashman recomended upscalling the help with the imbalanced dataset.\n",
    "#from https://spark.apache.org/docs/2.1.0/ml-tuning.html#train-validation-split\n",
    "\n",
    "train, test = p_df.randomSplit([0.8, 0.2], seed=2021)\n",
    "\n",
    "# cahce our test values for later speed\n",
    "#test.cache()\n",
    "\n",
    "# oversampleing code sample\n",
    "# https://stackoverflow.com/questions/53273133/how-to-perform-up-sampling-using-sample-functionpy-spark\n",
    "\n",
    "org_a_count = train.filter(train['label'] == 0).count()\n",
    "org_b_count = train.filter(train['label'] == 1).count()\n",
    "\n",
    "print(\"Original No Tip Count: \", org_a_count)\n",
    "print(\"Original Tip Count   : \", org_b_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Trip_ID: string, Trip_Seconds: int, Trip_Miles: double, Pickup_Community_Area: int, Dropoff_Community_Area: int, Fare: double, Tip: double, Additional_Charges_str: double, Trip_Total: double, Shared_Trip_Authorized: boolean, Trips_Pooled: int, Trip_Start_Timestamp: timestamp, Trip_End_Timestamp: timestamp, PostShutdownFlag: int, Day_Month_str: string, label: int, Trip_Year: int, Trip_Month: int, Trip_WeekNumber: int, Trip_DayofWeek: int, Trip_Start_Hour: int, Trip_Start_Minute: int, Trip_End_Hour: int, Date: date]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.cache()\n",
    "train.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pre processing handled the imbalanced dataset.  No further balancing is required.  Cache our datasets for speed.\n",
    "\n",
    "test.cache()\n",
    "# train = train_inital\n",
    "train.cache()\n",
    "del (p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just as a reminder what was the truth in our test data?\n",
    "\n",
    "dft_a = test.filter(train_inital['label'] == 0)\n",
    "dft_b = test.filter(train_inital['label'] == 1)\n",
    "count_test_a = dft_a.count()\n",
    "count_test_b = dft_b.count()\n",
    "print(count_test_a)\n",
    "print(count_test_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Functions (UDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmacc(pred):\n",
    "    t0 = time.time()\n",
    "    # make a confusion matrix and return the accuracy\n",
    "    # select predictions and labels from prediction transform as rdd as there isn't a DF function for this\n",
    "    pred_rdd= pred.select('prediction').rdd.flatMap(lambda x: x)\n",
    "    label_rdd = pred.select('label').rdd.flatMap(lambda x: x).map(lambda x: float(x))\n",
    "    \n",
    "    #zip them together\n",
    "    predictionAndLabels =  pred_rdd.zip(label_rdd)\n",
    "    \n",
    "    #metrics transform\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    \n",
    "    metrics2 = BinaryClassificationMetrics(predictionAndLabels)\n",
    "    \n",
    "    #make our confusion matrix\n",
    "    cm = metrics.confusionMatrix().toArray()\n",
    "\n",
    "    #calc accuracy from confusion matrix\n",
    "    \n",
    "    acc = (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "    \n",
    "    # McM accuracy\n",
    "    \n",
    "    acc2 = metrics.accuracy\n",
    "    \n",
    "    #calc area under curve\n",
    "    auc = metrics2.areaUnderROC\n",
    "    \n",
    "    prc = metrics2.areaUnderPR\n",
    "    \n",
    "    print(\"Confusion Matrix\")\n",
    "    print(cm)\n",
    "    print()\n",
    "    print(\"Accuracy from Confusion Matrix: \", acc)\n",
    "    print()\n",
    "    print(\"Accuracy from MulticlassMetrics: \", acc2)\n",
    "    print()     \n",
    "    print(\"Area Under the ROC\", auc)\n",
    "    print()\n",
    "    print(\"Area Under the PR Curve\", prc)\n",
    "    print('-'*50)\n",
    "    print(\"Metrics2 time:\", time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmacc2(pred):\n",
    "    # make a confusion matrix and return the accuracy\n",
    "    # select predictions and labels from prediction transform as rdd as there isn't a DF function for this\n",
    "    \n",
    "    t0 = time.time()\n",
    "    \n",
    "    pred_rdd= pred.select('prediction').rdd.flatMap(lambda x: x)\n",
    "    label_rdd = pred.select('label').rdd.flatMap(lambda x: x).map(lambda x: float(x))\n",
    "    \n",
    "    #zip them together\n",
    "    predictionAndLabels =  pred_rdd.zip(label_rdd)\n",
    "    \n",
    "    #metrics transform\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    \n",
    "    metrics2 = BinaryClassificationMetrics(predictionAndLabels)\n",
    "    \n",
    "    #make our confusion matrix\n",
    "    cm = metrics.confusionMatrix().toArray()\n",
    "\n",
    "    #calc accuracy from confusion matrix\n",
    "    \n",
    "    acc = (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "    \n",
    "    #McM accuracy\n",
    "    acc2 = metrics.accuracy\n",
    "    \n",
    "    #calc area under curve\n",
    "    auc = metrics2.areaUnderROC\n",
    "    \n",
    "    prc = metrics2.areaUnderPR\n",
    "    \n",
    "    precision = metrics.precision()\n",
    "    recall = metrics.recall()\n",
    "    f1Score = metrics.fMeasure()\n",
    "       \n",
    "    print(\"Confusion Matrix\")\n",
    "    print(cm)\n",
    "    print()\n",
    "    print(\"Accuracy from Confusion Matrix: \", acc)\n",
    "    print(\"Accuracy from MulticlassMetrics: \", acc2)\n",
    "    print()\n",
    "    print(\"Area Under the ROC\", auc)\n",
    "    print()\n",
    "    print(\"Area Under the PR Curve\", prc)\n",
    "   \n",
    "    print(\"Summary Stats\")\n",
    "    print(\"Precision = %s\" % precision)\n",
    "    print(\"Recall = %s\" % recall)\n",
    "    print(\"F1 Score = %s\" % f1Score)\n",
    "    \n",
    "    # Weighted stats\n",
    "    print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "    print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "    print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
    "    print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
    "    print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)\n",
    "    print('-'*50)\n",
    "    print(\"Metrics2 time:\", time.time() - t0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip_ID: string (nullable = true)\n",
      " |-- Trip_Seconds: integer (nullable = true)\n",
      " |-- Trip_Miles: double (nullable = true)\n",
      " |-- Pickup_Community_Area: integer (nullable = true)\n",
      " |-- Dropoff_Community_Area: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: double (nullable = true)\n",
      " |-- Additional_Charges_str: double (nullable = true)\n",
      " |-- Trip_Total: double (nullable = true)\n",
      " |-- Shared_Trip_Authorized: boolean (nullable = true)\n",
      " |-- Trips_Pooled: integer (nullable = true)\n",
      " |-- Trip_Start_Timestamp: timestamp (nullable = true)\n",
      " |-- Trip_End_Timestamp: timestamp (nullable = true)\n",
      " |-- PostShutdownFlag: integer (nullable = true)\n",
      " |-- Day_Month_str: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      " |-- Trip_Year: integer (nullable = true)\n",
      " |-- Trip_Month: integer (nullable = true)\n",
      " |-- Trip_WeekNumber: integer (nullable = true)\n",
      " |-- Trip_DayofWeek: integer (nullable = true)\n",
      " |-- Trip_Start_Hour: integer (nullable = true)\n",
      " |-- Trip_Start_Minute: integer (nullable = true)\n",
      " |-- Trip_End_Hour: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding for models (Michael sugested that we didn't need it in each model step)\n",
    "\n",
    "#onehotencoder to pickup\n",
    "ohe_pu = OneHotEncoder(inputCol=\"Pickup_Community_Area\", outputCol=\"Pickup_Community_Area_vec\")\n",
    "\n",
    "#onehotencoder to dropoff\n",
    "ohe_do = OneHotEncoder(inputCol=\"Dropoff_Community_Area\", outputCol=\"Dropoff_Community_Area_vec\")\n",
    "\n",
    "#onehotencoder to weekNumber\n",
    "ohe_twn = OneHotEncoder(inputCol=\"Trip_WeekNumber\", outputCol=\"Trip_WeekNumber_vec\")\n",
    "\n",
    "#onehotencoder to dayOfWeek\n",
    "ohe_dw = OneHotEncoder(inputCol=\"Trip_DayofWeek\", outputCol=\"Trip_DayofWeek_vec\")\n",
    "\n",
    "#onehotencoder to startHour\n",
    "ohe_sh = OneHotEncoder(inputCol=\"Trip_Start_Hour\", outputCol=\"Trip_Start_Hour_vec\")\n",
    "\n",
    "#onehotencoder to startMinute\n",
    "ohe_sm = OneHotEncoder(inputCol=\"Trip_Start_Minute\", outputCol=\"Trip_Start_Minute_vec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Pipeline Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train/test time: 27.292113780975342\n"
     ]
    }
   ],
   "source": [
    "# our colulms for lr\n",
    "predictor_col_for_lr = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec'\n",
    "                        ] # ,'Date' not supported datatype\n",
    "\n",
    "#assemble the vector for lr\n",
    "lr_va = VectorAssembler(inputCols=predictor_col_for_lr, outputCol=\"features\") \n",
    "\n",
    "#scale our lr\n",
    "lr_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "#what do we want to do if we are doing a parameter search? make the parameters as variables and just do a loop?\n",
    "#we learned that this week.  May also need to add in cv step\n",
    "\n",
    "lr = LogisticRegression(maxIter=10,\n",
    "                        regParam=0.1, #org 0.1\n",
    "                        elasticNetParam=0.3, #org 0.3\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"label\")\n",
    "\n",
    "# Build the pipeline\n",
    "lr_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, lr_va, lr_scaler, lr])\n",
    "\n",
    "#time check\n",
    "t0 = time.time()\n",
    "\n",
    "# Fit the pipeline\n",
    "lr_model = lr_pipeline.fit(train)\n",
    "\n",
    "# Make a prediction\n",
    "lr_prediction = lr_model.transform(test)\n",
    "\n",
    "print(\"train/test time:\", time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[314316. 161081.]\n",
      " [228670. 246078.]]\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5897983991917023\n",
      "\n",
      "Accuracy from MulticlassMetrics:  0.5897983991917023\n",
      "\n",
      "Area Under the ROC 0.5897496184507037\n",
      "\n",
      "Area Under the PR Curve 0.579158186860823\n",
      "--------------------------------------------------\n",
      "Metrics2 time: 8.698458433151245\n"
     ]
    }
   ],
   "source": [
    "#time check\n",
    "cmacc(lr_prediction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[314316. 161081.]\n",
      " [228670. 246078.]]\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5897983991917023\n",
      "Accuracy from MulticlassMetrics:  0.5897983991917023\n",
      "\n",
      "Area Under the ROC 0.5897496184507037\n",
      "\n",
      "Area Under the PR Curve 0.579158186860823\n",
      "Summary Stats\n",
      "Precision = 0.5897983991917023\n",
      "Recall = 0.5897983991917023\n",
      "F1 Score = 0.5897983991917023\n",
      "Weighted recall = 0.5897983991917023\n",
      "Weighted precision = 0.5916132346574163\n",
      "Weighted F(1) Score = 0.5876918784941367\n",
      "Weighted F(0.5) Score = 0.5893040171743007\n",
      "Weighted false positive rate = 0.41029916229029484\n",
      "--------------------------------------------------\n",
      "Metrics2 time: 10.951287984848022\n"
     ]
    }
   ],
   "source": [
    "#time check\n",
    "cmacc2(lr_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above confirms the results of the first pass of the grid search from tuning below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Pipeline for Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test time: 31.855722188949585\n",
      "Test Error = 0.427661\n",
      "Accuracy:  0.5723389587905005\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_96b610c6dba2) with 10 trees\n"
     ]
    }
   ],
   "source": [
    "# our colulms for rf\n",
    "predictor_col_for_rf = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "# assemble feature vector\n",
    "rf_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "\n",
    "# set classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \n",
    "                            featuresCol=\"features\", \n",
    "                            numTrees=10)\n",
    "\n",
    "# Build the pipeline\n",
    "rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, rf_va, rf])\n",
    "\n",
    "#time check\n",
    "t0 = time.time()\n",
    "\n",
    "# Fit the pipeline\n",
    "rf_model = rf_pipeline.fit(train)\n",
    "\n",
    "# Make a prediction\n",
    "rf_prediction = rf_model.transform(test)\n",
    "\n",
    "print(\"Train/Test time:\", time.time() - t0)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "rf_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "#metric options f1|accuracy|weightedPrecision|weightedRecall\n",
    "\n",
    "rf_accuracy = rf_evaluator.evaluate(rf_prediction)\n",
    "\n",
    "print(\"Test Error = %g\" % (1.0 - rf_accuracy))\n",
    "print(\"Accuracy: \" , rf_accuracy)\n",
    "\n",
    "rfModel2 = rf_model.stages[7]\n",
    "print(rfModel2)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[381650.  93747.]\n",
      " [312593. 162155.]]\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5723389587905005\n",
      "Accuracy from MulticlassMetrics:  0.5723389587905005\n",
      "\n",
      "Area Under the ROC 0.5721814320872429\n",
      "\n",
      "Area Under the PR Curve 0.5895443911731173\n",
      "Summary Stats\n",
      "Precision = 0.5723389587905005\n",
      "Recall = 0.5723389587905005\n",
      "F1 Score = 0.5723389587905005\n",
      "Weighted recall = 0.5723389587905003\n",
      "Weighted precision = 0.5916693419314419\n",
      "Weighted F(1) Score = 0.5483007926209974\n",
      "Weighted F(0.5) Score = 0.5639335246559836\n",
      "Weighted false positive rate = 0.42797609461601455\n",
      "--------------------------------------------------\n",
      "Metrics2 time: 11.051759719848633\n"
     ]
    }
   ],
   "source": [
    "cmacc2(rf_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Pipeline for Gradient Boosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test time: 123.6289427280426\n",
      "Test Error = 0.405872\n",
      "gbt accuracy =  0.5941282646332928\n",
      "GBTClassificationModel (uid=GBTClassifier_ea139a21856c) with 5 trees\n"
     ]
    }
   ],
   "source": [
    "# our colulms for gbt\n",
    "predictor_col_for_gbt = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "gbt_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "\n",
    "# set classifier\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\", maxIter=5)\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "gbt_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, gbt_va, gbt]) #labelIndexer, featureIndexer\n",
    "\n",
    "#time check\n",
    "t0 = time.time()\n",
    "\n",
    "# Train model.\n",
    "gbt_model = gbt_pipeline.fit(train)\n",
    "\n",
    "# Make predictions.\n",
    "gbt_prediction = gbt_model.transform(test)\n",
    "\n",
    "print(\"Train/Test time:\", time.time() - t0)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "gbt_evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "gbt_accuracy = gbt_evaluator.evaluate(gbt_prediction)\n",
    "print(\"Test Error = %g\" % (1.0 - gbt_accuracy))\n",
    "print('gbt accuracy = ', gbt_accuracy)\n",
    "gbtModel = gbt_model.stages[7]\n",
    "print(gbtModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[329258. 146139.]\n",
      " [239498. 235250.]]\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5941282646332928\n",
      "Accuracy from MulticlassMetrics:  0.5941282646332928\n",
      "\n",
      "Area Under the ROC 0.5940609600027235\n",
      "\n",
      "Area Under the PR Curve 0.5872707403342221\n",
      "Summary Stats\n",
      "Precision = 0.5941282646332928\n",
      "Recall = 0.5941282646332928\n",
      "F1 Score = 0.5941282646332928\n",
      "Weighted recall = 0.5941282646332928\n",
      "Weighted precision = 0.5978537258908767\n",
      "Weighted F(1) Score = 0.590143502463202\n",
      "Weighted F(0.5) Score = 0.5933010409575987\n",
      "Weighted false positive rate = 0.40600634462784574\n",
      "--------------------------------------------------\n",
      "Metrics2 time: 10.66636872291565\n"
     ]
    }
   ],
   "source": [
    "cmacc2(gbt_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline LR with Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(lr_paramGrid): 8\n",
      "train time: 1099.297649383545\n"
     ]
    }
   ],
   "source": [
    "# our colulms for lr\n",
    "predictor_col_for_lr = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "#assemble the vector or LR\n",
    "\n",
    "lr_va = VectorAssembler(inputCols=predictor_col_for_lr, outputCol=\"features\") \n",
    "\n",
    "#scale our LR\n",
    "\n",
    "lr_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "#what do we want to do if we are doing a parameter search? make the parameters as variables and just do a loop?\n",
    "#we learned that this week.  May also need to add in cv step\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\",\n",
    "                        labelCol=\"label\") # regParam=0.1, elasticNetParam=0.3, maxIter=10,\n",
    "\n",
    "# Build the pipeline\n",
    "lr_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, lr_va, lr_scaler, lr])\n",
    "\n",
    "# Set up the parameter grid\n",
    "lr_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.02, 0.03]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.1, 0.15]) \\\n",
    "    .addGrid(lr.maxIter, [5, 10]) \\\n",
    "    .build()\n",
    "\n",
    "print('len(lr_paramGrid): {}'.format(len(lr_paramGrid)))\n",
    "'''\n",
    "25k set\n",
    "best from tuning inital (accuracy):\n",
    "addGrid(lr.regParam, [0.03, 0.05, 0.07]) \\\n",
    ".addGrid(lr.elasticNetParam, [0.15, 0.2, 0.25]) \\\n",
    ".addGrid(lr.maxIter, [8, 9, 10, 11, 12]) \n",
    "\n",
    "regParam= 0.03\n",
    "elasticNetParam = 0.15\n",
    "maxIter = 12\n",
    " \n",
    "Confusion Matrix\n",
    "[[1842. 2203.]\n",
    " [ 193.  595.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.5042416718394372\n",
    "Accuracy from MulticlassMetrics:  0.5042416718394372\n",
    "\n",
    "Area Under the ROC 0.6052265753923187\n",
    "\n",
    "Area Under the PR Curve 0.2065770273222743\n",
    "Summary Stats\n",
    "Precision = 0.5042416718394372\n",
    "Recall = 0.5042416718394372\n",
    "F1 Score = 0.5042416718394372\n",
    "Weighted recall = 0.5042416718394371\n",
    "Weighted precision = 0.7922492654683645\n",
    "Weighted F(1) Score = 0.5612342974368173\n",
    "Weighted F(0.5) Score = 0.6730989071456968\n",
    "Weighted false positive rate = 0.2937885210547999\n",
    "\n",
    "2nd round:\n",
    "\n",
    "lr_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01, 0.02, 0.03]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.05, 0.1, 0.15]) \\\n",
    "    .addGrid(lr.maxIter, [11, 12, 13, 15]) \\\n",
    "\n",
    "regParam= 0.03\n",
    "elasticNetParam = 0.15\n",
    "maxIter = 11\n",
    "\n",
    "Confusion Matrix\n",
    "[[1815. 2230.]\n",
    " [ 183.  605.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.5007241878750258\n",
    "Accuracy from MulticlassMetrics:  0.5007241878750258\n",
    "\n",
    "Area Under the ROC 0.6082342994108162\n",
    "\n",
    "Area Under the PR Curve 0.2075564549699384\n",
    "Summary Stats\n",
    "Precision = 0.5007241878750258\n",
    "Recall = 0.5007241878750258\n",
    "F1 Score = 0.5007241878750258\n",
    "Weighted recall = 0.5007241878750258\n",
    "Weighted precision = 0.7950908896146499\n",
    "Weighted F(1) Score = 0.5572078454446675\n",
    "Weighted F(0.5) Score = 0.6716684076809212\n",
    "Weighted false positive rate = 0.28425558905339354\n",
    "\n",
    "'''\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "lr_crossval = CrossValidator(estimator=lr_pipeline,\n",
    "                          estimatorParamMaps=lr_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='accuracy'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "\n",
    "t0 = time.time()\n",
    "lr_cvModel = lr_crossval.setParallelism(6).fit(train) # train 6 models in parallel\n",
    "\n",
    "print(\"train time:\", time.time() - t0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to find all our items we can call\n",
    "#dir(crossval.evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#not sure what this metric is... apparently it is RMSE https://projector-video-pdf-converter.datacamp.com/14989/chapter4.pdf\n",
    "#lr_cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magic code from https://stackoverflow.com/questions/36697304/how-to-extract-model-hyper-parameters-from-spark-ml-in-pyspark\n",
    "\n",
    "# lr_cvModel.getEstimatorParamMaps()[ np.argmax(lr_cvModel.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_7d4d6d3af10c', name='regParam', doc='regularization parameter (>= 0).'): 0.03,\n",
       " Param(parent='LogisticRegression_7d4d6d3af10c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.15,\n",
       " Param(parent='LogisticRegression_7d4d6d3af10c', name='maxIter', doc='max number of iterations (>= 0).'): 5}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://dsharpc.github.io/SparkMLFlights/\n",
    "#best?\n",
    "#cvModel.getEstimatorParamMaps()[ np.argmin(cvModel.avgMetrics) ]\n",
    "\n",
    "lr_cvModel.getEstimatorParamMaps()[ np.argmin(lr_cvModel.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_7d4d6d3af10c', name='regParam', doc='regularization parameter (>= 0).'): 0.02,\n",
       " Param(parent='LogisticRegression_7d4d6d3af10c', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.1,\n",
       " Param(parent='LogisticRegression_7d4d6d3af10c', name='maxIter', doc='max number of iterations (>= 0).'): 10}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_cvModel.getEstimatorParamMaps()[ np.argmax(lr_cvModel.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "lr_prediction = lr_cvModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cmacc(lr_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[258980. 216417.]\n",
      " [143151. 331597.]]\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.6215651295328608\n",
      "Accuracy from MulticlassMetrics:  0.6215651295328608\n",
      "\n",
      "Area Under the ROC 0.6216176234893992\n",
      "\n",
      "Area Under the PR Curve 0.5891933635195167\n",
      "Summary Stats\n",
      "Precision = 0.6215651295328608\n",
      "Recall = 0.6215651295328608\n",
      "F1 Score = 0.6215651295328608\n",
      "Weighted recall = 0.6215651295328608\n",
      "Weighted precision = 0.6245670682712414\n",
      "Weighted F(1) Score = 0.6193217829971516\n",
      "Weighted F(0.5) Score = 0.6215444248056616\n",
      "Weighted false positive rate = 0.3783298825540624\n",
      "--------------------------------------------------\n",
      "Metrics2 time: 11.47052264213562\n"
     ]
    }
   ],
   "source": [
    "cmacc2(lr_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline RF with Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(rf_paramGrid): 8\n",
      "train time: 1360.484427690506\n"
     ]
    }
   ],
   "source": [
    "# our colulms for rf\n",
    "predictor_col_for_rf = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "# assemble feature vector\n",
    "rf_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "               \n",
    "# set classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \n",
    "                            featuresCol=\"features\")\n",
    "    \n",
    "# Build the pipeline\n",
    "rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, rf_va, rf])\n",
    "\n",
    "# Set up the parameter grid\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5, 10]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .addGrid(rf.impurity, [\"gini\", \"entropy\"])\\\n",
    "    .build()\n",
    "    #.addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt'])\\\n",
    "    \n",
    "print('len(rf_paramGrid): {}'.format(len(rf_paramGrid)))\n",
    "\n",
    "#https://medium.com/rahasak/random-forest-classifier-with-apache-spark-c63b4a23a7cc\n",
    "#maxDepth, maxBins, impurity, auto and seed \n",
    "#.addGrid(randomForestClassifier.impurity, Array(\"entropy\", \"gini\"))\n",
    "#name='featureSubsetStrategy', auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n]\n",
    "\n",
    "'''\n",
    "best from tuning inital (accuracy):\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5, 10]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .addGrid(rf.impurity, [\"entropy\", \"gini\"])\\\n",
    "    .build()\n",
    "\n",
    "numTrees = 10\n",
    "maxDepth = 10\n",
    "impurity = gini\n",
    " \n",
    "Confusion Matrix\n",
    "[[2901. 1144.]\n",
    " [ 456.  332.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6689426857024623\n",
    "Accuracy from MulticlassMetrics:  0.6689426857024623\n",
    "\n",
    "Area Under the ROC 0.5692507513819781\n",
    "\n",
    "Area Under the PR Curve 0.2070259967551608\n",
    "Summary Stats\n",
    "Precision = 0.6689426857024623\n",
    "Recall = 0.6689426857024623\n",
    "F1 Score = 0.6689426857024623\n",
    "Weighted recall = 0.6689426857024622\n",
    "Weighted precision = 0.7599403563099746\n",
    "Weighted F(1) Score = 0.7038591473392332\n",
    "Weighted F(0.5) Score = 0.735232181263078\n",
    "Weighted false positive rate = 0.530441182938506\n",
    "\n",
    "2nd attempt:\n",
    "\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5, 10, 15]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10, 15]) \\\n",
    "    .addGrid(rf.impurity, [\"entropy\", \"gini\"])\\\n",
    "    .addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt'])\\\n",
    "    .build()\n",
    "\n",
    "\n",
    "numTrees = 10\n",
    "maxDepth = 15\n",
    "impurity = gini\n",
    "featureSubsetStrategy = auto\n",
    "\n",
    "Confusion Matrix\n",
    "[[2663. 1382.]\n",
    " [ 388.  400.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6337678460583489\n",
    "Accuracy from MulticlassMetrics:  0.6337678460583489\n",
    "\n",
    "Area Under the ROC 0.5829789236570811\n",
    "\n",
    "Area Under the PR Curve 0.209345437091233\n",
    "Summary Stats\n",
    "Precision = 0.6337678460583489\n",
    "Recall = 0.6337678460583489\n",
    "F1 Score = 0.6337678460583489\n",
    "Weighted recall = 0.6337678460583488\n",
    "Weighted precision = 0.7671159775546591\n",
    "Weighted F(1) Score = 0.6789410276493224\n",
    "Weighted F(0.5) Score = 0.7270236282319229\n",
    "Weighted false positive rate = 0.46780999874418644\n",
    "\n",
    "'''\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "rf_crossval = CrossValidator(estimator=rf_pipeline,\n",
    "                          estimatorParamMaps=rf_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='accuracy'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "\n",
    "t0 = time.time()\n",
    "cvModel_rf = rf_crossval.setParallelism(6).fit(train) # train 6 models in parallel\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction_rf = cvModel_rf.transform(test)\n",
    "\n",
    "print(\"train time:\", time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction_rf = cvModel_rf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[356675. 118722.]\n",
      " [269179. 205569.]]\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5917454704281978\n",
      "Accuracy from MulticlassMetrics:  0.5917454704281978\n",
      "\n",
      "Area Under the ROC 0.5916371172511604\n",
      "\n",
      "Area Under the PR Curve 0.5958450337450366\n",
      "Summary Stats\n",
      "Precision = 0.5917454704281978\n",
      "Recall = 0.5917454704281978\n",
      "F1 Score = 0.5917454704281978\n",
      "Weighted recall = 0.5917454704281978\n",
      "Weighted precision = 0.6018802269396942\n",
      "Weighted F(1) Score = 0.5811974532996568\n",
      "Weighted F(0.5) Score = 0.5893879719422019\n",
      "Weighted false positive rate = 0.4084712359258768\n",
      "--------------------------------------------------\n",
      "Metrics2 time: 13.019006490707397\n"
     ]
    }
   ],
   "source": [
    "cmacc2(prediction_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to find all our items we can call\n",
    "#dir(crossval.evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5855043851048654,\n",
       " 0.5880303476189277,\n",
       " 0.593714324922341,\n",
       " 0.5905547727116429,\n",
       " 0.5811094961300449,\n",
       " 0.583791821161717,\n",
       " 0.5952770626796756,\n",
       " 0.5984883305576575]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not sure what this metric is... rmse\n",
    "cvModel_rf.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_0080c2e2c57d', name='numTrees', doc='Number of trees to train (>= 1).'): 10,\n",
       " Param(parent='RandomForestClassifier_0080c2e2c57d', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       " Param(parent='RandomForestClassifier_0080c2e2c57d', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# magic code from https://stackoverflow.com/questions/36697304/how-to-extract-model-hyper-parameters-from-spark-ml-in-pyspark\n",
    "\n",
    "cvModel_rf.getEstimatorParamMaps()[ np.argmax(cvModel_rf.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_0080c2e2c57d', name='numTrees', doc='Number of trees to train (>= 1).'): 10,\n",
       " Param(parent='RandomForestClassifier_0080c2e2c57d', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       " Param(parent='RandomForestClassifier_0080c2e2c57d', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://dsharpc.github.io/SparkMLFlights/\n",
    "#best?\n",
    "#cvModel.getEstimatorParamMaps()[ np.argmin(cvModel.avgMetrics) ]\n",
    "\n",
    "cvModel_rf.getEstimatorParamMaps()[ np.argmin(cvModel_rf.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_0080c2e2c57d', name='numTrees', doc='Number of trees to train (>= 1).'): 10,\n",
       " Param(parent='RandomForestClassifier_0080c2e2c57d', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10,\n",
       " Param(parent='RandomForestClassifier_0080c2e2c57d', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'entropy'}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel_rf.getEstimatorParamMaps()[ np.argmax(cvModel_rf.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline GBT with Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(gbt_paramGrid): 4\n",
      "train time: 4965.340165376663\n"
     ]
    }
   ],
   "source": [
    "# our colulms for gbt\n",
    "predictor_col_for_gbt = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "gbt_va = VectorAssembler(inputCols=predictor_col_for_gbt, outputCol=\"features\") \n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"label\", featuresCol=\"features\") #, maxIter=5\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "gbt_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, gbt_va, gbt]) #labelIndexer, featureIndexer\n",
    "\n",
    "# Set up the parameter grid\n",
    "gbt_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [5, 10])\\\n",
    "    .addGrid(gbt.maxDepth, [5, 10])\\\n",
    "    .build()\n",
    "\n",
    "print('len(gbt_paramGrid): {}'.format(len(gbt_paramGrid)))\n",
    "\n",
    "\n",
    "'''\n",
    "best from tuning inital (accuracy):\n",
    "gbt_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [5, 10, 20]) \\\n",
    "    .build()\n",
    "\n",
    "maxIter = 20\n",
    "\n",
    "Confusion Matrix\n",
    "[[2798. 1247.]\n",
    " [ 423.  365.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.654458928201945\n",
    "Accuracy from MulticlassMetrics:  0.654458928201945\n",
    "\n",
    "Area Under the ROC 0.5774580700620556\n",
    "\n",
    "Area Under the PR Curve 0.2094152550126291\n",
    "Summary Stats\n",
    "Precision = 0.654458928201945\n",
    "Recall = 0.654458928201945\n",
    "F1 Score = 0.654458928201945\n",
    "Weighted recall = 0.654458928201945\n",
    "Weighted precision = 0.7639586098089827\n",
    "Weighted F(1) Score = 0.6941837869282138\n",
    "Weighted F(0.5) Score = 0.7327747544723259\n",
    "Weighted false positive rate = 0.4995427880778336\n",
    "\n",
    "\n",
    "maxIter = 40\n",
    "\n",
    "Confusion Matrix\n",
    "[[2571. 1474.]\n",
    " [ 382.  406.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6159735154148562\n",
    "Accuracy from MulticlassMetrics:  0.6159735154148562\n",
    "\n",
    "Area Under the ROC 0.5754139659791808\n",
    "\n",
    "Area Under the PR Curve 0.20313239804234073\n",
    "Summary Stats\n",
    "Precision = 0.6159735154148562\n",
    "Recall = 0.6159735154148562\n",
    "F1 Score = 0.6159735154148562\n",
    "Weighted recall = 0.6159735154148562\n",
    "Weighted precision = 0.7638968296438198\n",
    "Weighted F(1) Score = 0.6646010165217533\n",
    "Weighted F(0.5) Score = 0.7183436330713325\n",
    "Weighted false positive rate = 0.4651455834564943\n",
    "\n",
    "\n",
    "gbt_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(gbt.maxIter, [5, 10])\\\n",
    "    .addGrid(gbt.maxDepth, [5, 10])\\\n",
    "    .build()\n",
    "    \n",
    "maxIter = 5\n",
    "maxDepth = 5\n",
    "\n",
    "Confusion Matrix\n",
    "[[2863. 1182.]\n",
    " [ 469.  319.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6583902338092282\n",
    "Accuracy from MulticlassMetrics:  0.6583902338092282\n",
    "\n",
    "Area Under the ROC 0.5563048634335804\n",
    "\n",
    "Area Under the PR Curve 0.19780050930331394\n",
    "Summary Stats\n",
    "Precision = 0.6583902338092282\n",
    "Recall = 0.6583902338092282\n",
    "F1 Score = 0.6583902338092282\n",
    "Weighted recall = 0.6583902338092282\n",
    "Weighted precision = 0.7537989743798752\n",
    "Weighted F(1) Score = 0.6950856095348379\n",
    "Weighted F(0.5) Score = 0.7279222226014918\n",
    "Weighted false positive rate = 0.5457805069420676\n",
    "'''\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "gbt_crossval = CrossValidator(estimator=gbt_pipeline,\n",
    "                          estimatorParamMaps=gbt_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='accuracy'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "\n",
    "t0 = time.time()\n",
    "cvModel_gbt = gbt_crossval.setParallelism(6).fit(train) # train 6 models in parallel\n",
    "print(\"train time:\", time.time() - t0)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction_gbt = cvModel_gbt.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[306188. 169209.]\n",
      " [200380. 274368.]]\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.6110183182566872\n",
      "Accuracy from MulticlassMetrics:  0.6110183182566872\n",
      "\n",
      "Area Under the ROC 0.6109957281138295\n",
      "\n",
      "Area Under the PR Curve 0.5934476809925365\n",
      "Summary Stats\n",
      "Precision = 0.6110183182566872\n",
      "Recall = 0.6110183182566872\n",
      "F1 Score = 0.6110183182566872\n",
      "Weighted recall = 0.6110183182566871\n",
      "Weighted precision = 0.6114808613609575\n",
      "Weighted F(1) Score = 0.6105904720912074\n",
      "Weighted F(0.5) Score = 0.6109656999099813\n",
      "Weighted false positive rate = 0.3890268620290281\n",
      "--------------------------------------------------\n",
      "Metrics2 time: 13.175491571426392\n"
     ]
    }
   ],
   "source": [
    "cmacc2(prediction_gbt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to find all our items we can call\n",
    "#dir(crossval.evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5952295992563201,\n",
       " 0.6052778306592042,\n",
       " 0.6014306543937586,\n",
       " 0.6105873712720494]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not sure what this metric is...\n",
    "cvModel_gbt.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='GBTClassifier_aee1714e173e', name='maxIter', doc='max number of iterations (>= 0).'): 10,\n",
       " Param(parent='GBTClassifier_aee1714e173e', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 10}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# magic code from https://stackoverflow.com/questions/36697304/how-to-extract-model-hyper-parameters-from-spark-ml-in-pyspark\n",
    "\n",
    "#cvModel_gbt.getEstimatorParamMaps()[ np.argmax(cvModel_rf.avgMetrics) ]\n",
    "\n",
    "cvModel_gbt.getEstimatorParamMaps()[np.argmax(cvModel_gbt.avgMetrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='GBTClassifier_aee1714e173e', name='maxIter', doc='max number of iterations (>= 0).'): 5,\n",
       " Param(parent='GBTClassifier_aee1714e173e', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel_gbt.getEstimatorParamMaps()[np.argmin(cvModel_gbt.avgMetrics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline LR with CV and no Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(lr_paramGrid): 1\n",
      "train time: 181.59805846214294\n",
      "Confusion Matrix\n",
      "[[288388. 187009.]\n",
      " [179953. 294795.]]\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.6137831594125107\n",
      "Accuracy from MulticlassMetrics:  0.6137831594125107\n",
      "\n",
      "Area Under the ROC 0.6137880517373892\n",
      "\n",
      "Area Under the PR Curve 0.5905923489395983\n",
      "Summary Stats\n",
      "Precision = 0.6137831594125107\n",
      "Recall = 0.6137831594125107\n",
      "F1 Score = 0.6137831594125107\n",
      "Weighted recall = 0.6137831594125107\n",
      "Weighted precision = 0.6138121835166755\n",
      "Weighted F(1) Score = 0.6137638181652783\n",
      "Weighted F(0.5) Score = 0.6137847105445953\n",
      "Weighted false positive rate = 0.38620705593773236\n",
      "--------------------------------------------------\n",
      "Metrics2 time: 12.068689346313477\n"
     ]
    }
   ],
   "source": [
    "# our colulms for lr\n",
    "predictor_col_for_lr = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ] # 'Date' not supported datatype\n",
    "\n",
    "#assemble the vector ror lr\n",
    "lr_va = VectorAssembler(inputCols=predictor_col_for_lr, outputCol=\"features\") \n",
    "\n",
    "#scale our LR\n",
    "\n",
    "lr_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "#what do we want to do if we are doing a parameter search? make the parameters as variables and just do a loop?\n",
    "#we learned that this week.  May also need to add in cv step\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\",\n",
    "                        labelCol=\"label\") # regParam=0.1, elasticNetParam=0.3, maxIter=10,\n",
    "\n",
    "# Build the pipeline\n",
    "lr_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, lr_va, lr_scaler, lr])\n",
    "\n",
    "# Set up the parameter grid\n",
    "lr_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.03]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.15]) \\\n",
    "    .addGrid(lr.maxIter, [5]) \\\n",
    "    .build()\n",
    "\n",
    "print('len(lr_paramGrid): {}'.format(len(lr_paramGrid)))\n",
    "'''\n",
    "lr_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.3]) \\\n",
    "    .addGrid(lr.maxIter, [10]) \\\n",
    "    .build()\n",
    "\n",
    "train time: 140.95259499549866\n",
    "Confusion Matrix\n",
    "[[205206. 204047.]\n",
    " [ 21926.  59887.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.5398317130487551\n",
    "Accuracy from MulticlassMetrics:  0.5398317130487551\n",
    "\n",
    "Area Under the ROC 0.6167072883197446\n",
    "\n",
    "Area Under the PR Curve 0.2188213722126973\n",
    "Summary Stats\n",
    "Precision = 0.5398317130487551\n",
    "Recall = 0.5398317130487551\n",
    "F1 Score = 0.5398317130487551\n",
    "Weighted recall = 0.5398317130487552\n",
    "Weighted precision = 0.7907482614736813\n",
    "Weighted F(1) Score = 0.5951821122400512\n",
    "Weighted F(0.5) Score = 0.6927412010642031\n",
    "Weighted false positive rate = 0.3064171364092659\n",
    "\n",
    "\n",
    "lr_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.3]) \\\n",
    "    .addGrid(lr.maxIter, [10]) \\\n",
    "    .build()\n",
    "\n",
    "train time: 103.50798845291138\n",
    "Confusion Matrix\n",
    "[[190906. 218347.]\n",
    " [ 19609.  62204.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.5154296978410234\n",
    "Accuracy from MulticlassMetrics:  0.5154296978410234\n",
    "\n",
    "Area Under the ROC 0.61339677414919\n",
    "\n",
    "Area Under the PR Curve 0.21511547038697104\n",
    "Summary Stats\n",
    "Precision = 0.5154296978410234\n",
    "Recall = 0.5154296978410234\n",
    "F1 Score = 0.5154296978410234\n",
    "Weighted recall = 0.5154296978410234\n",
    "Weighted precision = 0.792707390100297\n",
    "Weighted F(1) Score = 0.5706182258743312\n",
    "Weighted F(0.5) Score = 0.678770901909123\n",
    "Weighted false positive rate = 0.2886361495426433\n",
    "\n",
    "'''\n",
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "lr_crossval = CrossValidator(estimator=lr_pipeline,\n",
    "                          estimatorParamMaps=lr_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='accuracy'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass\n",
    "\n",
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "\n",
    "t0 = time.time()\n",
    "lr_cvModel = lr_crossval.setParallelism(5).fit(train) # train 5 models in parallel\n",
    "print(\"train time:\", time.time() - t0)\n",
    "\n",
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "lr_prediction = lr_cvModel.transform(test)\n",
    "\n",
    "cmacc2(lr_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline RF with CV and no Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(rf_paramGrid): 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nrf_paramGrid = ParamGridBuilder()     .addGrid(rf.numTrees, [5])     .addGrid(rf.maxDepth, [10])     .addGrid(rf.impurity, [\"gini\"])    .build()\\n\\nConfusion Matrix\\n[[310741.  98512.]\\n [ 48819.  32994.]]\\n\\nAccuracy from Confusion Matrix:  0.6999771924751459\\nAccuracy from MulticlassMetrics:  0.6999771924751459\\n\\nArea Under the ROC 0.5812869028226872\\n\\nArea Under the PR Curve 0.22574477490483819\\nSummary Stats\\nPrecision = 0.6999771924751459\\nRecall = 0.6999771924751459\\nF1 Score = 0.6999771924751459\\nWeighted recall = 0.6999771924751459\\nWeighted precision = 0.7620428175754068\\nWeighted F(1) Score = 0.725226449674273\\nWeighted F(0.5) Score = 0.746087327758354\\nWeighted false positive rate = 0.5374033868297713\\n\\nrf_paramGrid = ParamGridBuilder()     .addGrid(rf.numTrees, [5, 10])     .addGrid(rf.maxDepth, [10])     .addGrid(rf.impurity, [\"gini\"])    .build()\\n    #.addGrid(rf.featureSubsetStrategy, [\\'auto\\', \\'sqrt\\'])\\nConfusion Matrix\\n[[314738.  94515.]\\n [ 49387.  32426.]]\\n\\nAccuracy from Confusion Matrix:  0.7069599605755642\\nAccuracy from MulticlassMetrics:  0.7069599605755642\\n\\nArea Under the ROC 0.5826988592158698\\n\\nArea Under the PR Curve 0.22862746418070495\\nSummary Stats\\nPrecision = 0.7069599605755642\\nRecall = 0.7069599605755642\\nF1 Score = 0.7069599605755642\\nWeighted recall = 0.7069599605755641\\nWeighted precision = 0.7629191089280811\\nWeighted F(1) Score = 0.7300846426136949\\nWeighted F(0.5) Score = 0.7487527818041555\\nWeighted false positive rate = 0.5415622421438244\\n\\nrf_paramGrid = ParamGridBuilder()     .addGrid(rf.numTrees, [10])     .addGrid(rf.maxDepth, [5, 10])     .addGrid(rf.impurity, [\"gini\"])    .build()\\n    \\nConfusion Matrix\\n[[314738.  94515.]\\n [ 49387.  32426.]]\\n\\nAccuracy from Confusion Matrix:  0.7069599605755642\\nAccuracy from MulticlassMetrics:  0.7069599605755642\\n\\nArea Under the ROC 0.5826988592158698\\n\\nArea Under the PR Curve 0.22862746418070495\\nSummary Stats\\nPrecision = 0.7069599605755642\\nRecall = 0.7069599605755642\\nF1 Score = 0.7069599605755642\\nWeighted recall = 0.7069599605755641\\nWeighted precision = 0.7629191089280811\\nWeighted F(1) Score = 0.7300846426136949\\nWeighted F(0.5) Score = 0.7487527818041555\\nWeighted false positive rate = 0.5415622421438244\\n\\n\\nrf_paramGrid = ParamGridBuilder()     .addGrid(rf.numTrees, [15])     .addGrid(rf.maxDepth, [10])     .addGrid(rf.impurity, [\"gini\"])    .build()\\n\\nConfusion Matrix\\n[[314741.  94512.]\\n [ 49347.  32466.]]\\n\\nAccuracy from Confusion Matrix:  0.7070475251799148\\nAccuracy from MulticlassMetrics:  0.7070475251799148\\n\\nArea Under the ROC 0.5829469843572036\\n\\nArea Under the PR Curve 0.22881720820050683\\nSummary Stats\\nPrecision = 0.7070475251799148\\nRecall = 0.7070475251799148\\nF1 Score = 0.7070475251799148\\nWeighted recall = 0.7070475251799148\\nWeighted precision = 0.7630392635253729\\nWeighted F(1) Score = 0.7301782260281282\\nWeighted F(0.5) Score = 0.7488602512258918\\nWeighted false positive rate = 0.5411535564655076\\n\\nrf_paramGrid = ParamGridBuilder()     .addGrid(rf.numTrees, [15])     .addGrid(rf.maxDepth, [15])     .addGrid(rf.impurity, [\"gini\"])    .build()\\n\\nConfusion Matrix\\n[[283025. 126228.]\\n [ 40908.  40905.]]\\n\\nAccuracy from Confusion Matrix:  0.6596465648202074\\nAccuracy from MulticlassMetrics:  0.6596465648202074\\n\\nArea Under the ROC 0.5957732705112914\\n\\nArea Under the PR Curve 0.22520890081666428\\nSummary Stats\\nPrecision = 0.6596465648202074\\nRecall = 0.6596465648202074\\nF1 Score = 0.6596465648202074\\nWeighted recall = 0.6596465648202074\\nWeighted precision = 0.76892652146907\\nWeighted F(1) Score = 0.6981671019368805\\nWeighted F(0.5) Score = 0.7371252023470279\\nWeighted false positive rate = 0.4681000237976247\\n\\nrf_paramGrid = ParamGridBuilder()     .addGrid(rf.numTrees, [15])     .addGrid(rf.maxDepth, [5])     .addGrid(rf.impurity, [\"gini\"])    .build()\\n\\nConfusion Matrix\\n[[309640.  99613.]\\n [ 49083.  32730.]]\\n\\nAccuracy from Confusion Matrix:  0.6971975253835533\\nAccuracy from MulticlassMetrics:  0.6971975253835533\\n\\nArea Under the ROC 0.5783283336102997\\n\\nArea Under the PR Curve 0.22310156202954437\\nSummary Stats\\nPrecision = 0.6971975253835533\\nRecall = 0.6971975253835533\\nF1 Score = 0.6971975253835533\\nWeighted recall = 0.6971975253835534\\nWeighted precision = 0.7605687622026887\\nWeighted F(1) Score = 0.7229589255192178\\nWeighted F(0.5) Score = 0.7442644365033869\\nWeighted false positive rate = 0.540540858162954\\n\\nrf_paramGrid = ParamGridBuilder()     .addGrid(rf.numTrees, [20])     .addGrid(rf.maxDepth, [10])     .addGrid(rf.impurity, [\"gini\"])    .build()\\n\\nConfusion Matrix\\n[[287361. 121892.]\\n [ 43803.  38010.]]\\n\\nAccuracy from Confusion Matrix:  0.6625809972590242\\nAccuracy from MulticlassMetrics:  0.6625809972590242\\n\\nArea Under the ROC 0.5833779398869698\\n\\nArea Under the PR Curve 0.21867308547708184\\nSummary Stats\\nPrecision = 0.6625809972590242\\nRecall = 0.6625809972590242\\nF1 Score = 0.6625809972590242\\nWeighted recall = 0.6625809972590243\\nWeighted precision = 0.7627667057602532\\nWeighted F(1) Score = 0.6992915166799253\\nWeighted F(0.5) Score = 0.7344847606612861\\nWeighted false positive rate = 0.4958251174850846\\n'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our colulms for rf\n",
    "predictor_col_for_rf = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges_str',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec',\n",
    "                        'Trip_Year', \n",
    "                        'Trip_Month',\n",
    "                        'Trip_WeekNumber_vec', \n",
    "                        'Trip_DayofWeek_vec', \n",
    "                        'Trip_Start_Hour_vec',\n",
    "                        'Trip_Start_Minute_vec',\n",
    "                        'PostShutdownFlag'\n",
    "                        ]\n",
    "\n",
    "# assemble feature vector\n",
    "rf_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "\n",
    "# set classifier\n",
    "rf = RandomForestClassifier(labelCol=\"label\", \n",
    "                            featuresCol=\"features\")\n",
    "\n",
    "# # Build the pipeline\n",
    "# rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, rf_va, rf])\n",
    "\n",
    "# Build the pipeline\n",
    "rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, ohe_twn, ohe_dw, ohe_sh, ohe_sm, rf_va, rf])\n",
    "\n",
    "# Set up the parameter grid\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10]) \\\n",
    "    .addGrid(rf.maxDepth, [5]) \\\n",
    "    .addGrid(rf.impurity, [\"gini\"])\\\n",
    "    .build()\n",
    "    #.addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt'])\\\n",
    "    \n",
    "\n",
    "print('len(rf_paramGrid): {}'.format(len(rf_paramGrid)))\n",
    "\n",
    "#https://medium.com/rahasak/random-forest-classifier-with-apache-spark-c63b4a23a7cc\n",
    "#maxDepth, maxBins, impurity, auto and seed \n",
    "#.addGrid(randomForestClassifier.impurity, Array(\"entropy\", \"gini\"))\n",
    "#name='featureSubsetStrategy', auto, all, onethird, sqrt, log2, (0.0-1.0], [1-n]\n",
    "\n",
    "'''\n",
    "\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5]) \\\n",
    "    .addGrid(rf.maxDepth, [10]) \\\n",
    "    .addGrid(rf.impurity, [\"gini\"])\\\n",
    "    .build()\n",
    "\n",
    "Confusion Matrix\n",
    "[[310741.  98512.]\n",
    " [ 48819.  32994.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6999771924751459\n",
    "Accuracy from MulticlassMetrics:  0.6999771924751459\n",
    "\n",
    "Area Under the ROC 0.5812869028226872\n",
    "\n",
    "Area Under the PR Curve 0.22574477490483819\n",
    "Summary Stats\n",
    "Precision = 0.6999771924751459\n",
    "Recall = 0.6999771924751459\n",
    "F1 Score = 0.6999771924751459\n",
    "Weighted recall = 0.6999771924751459\n",
    "Weighted precision = 0.7620428175754068\n",
    "Weighted F(1) Score = 0.725226449674273\n",
    "Weighted F(0.5) Score = 0.746087327758354\n",
    "Weighted false positive rate = 0.5374033868297713\n",
    "\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [5, 10]) \\\n",
    "    .addGrid(rf.maxDepth, [10]) \\\n",
    "    .addGrid(rf.impurity, [\"gini\"])\\\n",
    "    .build()\n",
    "    #.addGrid(rf.featureSubsetStrategy, ['auto', 'sqrt'])\\\n",
    "\n",
    "Confusion Matrix\n",
    "[[314738.  94515.]\n",
    " [ 49387.  32426.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.7069599605755642\n",
    "Accuracy from MulticlassMetrics:  0.7069599605755642\n",
    "\n",
    "Area Under the ROC 0.5826988592158698\n",
    "\n",
    "Area Under the PR Curve 0.22862746418070495\n",
    "Summary Stats\n",
    "Precision = 0.7069599605755642\n",
    "Recall = 0.7069599605755642\n",
    "F1 Score = 0.7069599605755642\n",
    "Weighted recall = 0.7069599605755641\n",
    "Weighted precision = 0.7629191089280811\n",
    "Weighted F(1) Score = 0.7300846426136949\n",
    "Weighted F(0.5) Score = 0.7487527818041555\n",
    "Weighted false positive rate = 0.5415622421438244\n",
    "\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [10]) \\\n",
    "    .addGrid(rf.maxDepth, [5, 10]) \\\n",
    "    .addGrid(rf.impurity, [\"gini\"])\\\n",
    "    .build()\n",
    "    \n",
    "Confusion Matrix\n",
    "[[314738.  94515.]\n",
    " [ 49387.  32426.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.7069599605755642\n",
    "Accuracy from MulticlassMetrics:  0.7069599605755642\n",
    "\n",
    "Area Under the ROC 0.5826988592158698\n",
    "\n",
    "Area Under the PR Curve 0.22862746418070495\n",
    "Summary Stats\n",
    "Precision = 0.7069599605755642\n",
    "Recall = 0.7069599605755642\n",
    "F1 Score = 0.7069599605755642\n",
    "Weighted recall = 0.7069599605755641\n",
    "Weighted precision = 0.7629191089280811\n",
    "Weighted F(1) Score = 0.7300846426136949\n",
    "Weighted F(0.5) Score = 0.7487527818041555\n",
    "Weighted false positive rate = 0.5415622421438244\n",
    "\n",
    "\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [15]) \\\n",
    "    .addGrid(rf.maxDepth, [10]) \\\n",
    "    .addGrid(rf.impurity, [\"gini\"])\\\n",
    "    .build()\n",
    "\n",
    "Confusion Matrix\n",
    "[[314741.  94512.]\n",
    " [ 49347.  32466.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.7070475251799148\n",
    "Accuracy from MulticlassMetrics:  0.7070475251799148\n",
    "\n",
    "Area Under the ROC 0.5829469843572036\n",
    "\n",
    "Area Under the PR Curve 0.22881720820050683\n",
    "Summary Stats\n",
    "Precision = 0.7070475251799148\n",
    "Recall = 0.7070475251799148\n",
    "F1 Score = 0.7070475251799148\n",
    "Weighted recall = 0.7070475251799148\n",
    "Weighted precision = 0.7630392635253729\n",
    "Weighted F(1) Score = 0.7301782260281282\n",
    "Weighted F(0.5) Score = 0.7488602512258918\n",
    "Weighted false positive rate = 0.5411535564655076\n",
    "\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [15]) \\\n",
    "    .addGrid(rf.maxDepth, [15]) \\\n",
    "    .addGrid(rf.impurity, [\"gini\"])\\\n",
    "    .build()\n",
    "\n",
    "Confusion Matrix\n",
    "[[283025. 126228.]\n",
    " [ 40908.  40905.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6596465648202074\n",
    "Accuracy from MulticlassMetrics:  0.6596465648202074\n",
    "\n",
    "Area Under the ROC 0.5957732705112914\n",
    "\n",
    "Area Under the PR Curve 0.22520890081666428\n",
    "Summary Stats\n",
    "Precision = 0.6596465648202074\n",
    "Recall = 0.6596465648202074\n",
    "F1 Score = 0.6596465648202074\n",
    "Weighted recall = 0.6596465648202074\n",
    "Weighted precision = 0.76892652146907\n",
    "Weighted F(1) Score = 0.6981671019368805\n",
    "Weighted F(0.5) Score = 0.7371252023470279\n",
    "Weighted false positive rate = 0.4681000237976247\n",
    "\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [15]) \\\n",
    "    .addGrid(rf.maxDepth, [5]) \\\n",
    "    .addGrid(rf.impurity, [\"gini\"])\\\n",
    "    .build()\n",
    "\n",
    "Confusion Matrix\n",
    "[[309640.  99613.]\n",
    " [ 49083.  32730.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6971975253835533\n",
    "Accuracy from MulticlassMetrics:  0.6971975253835533\n",
    "\n",
    "Area Under the ROC 0.5783283336102997\n",
    "\n",
    "Area Under the PR Curve 0.22310156202954437\n",
    "Summary Stats\n",
    "Precision = 0.6971975253835533\n",
    "Recall = 0.6971975253835533\n",
    "F1 Score = 0.6971975253835533\n",
    "Weighted recall = 0.6971975253835534\n",
    "Weighted precision = 0.7605687622026887\n",
    "Weighted F(1) Score = 0.7229589255192178\n",
    "Weighted F(0.5) Score = 0.7442644365033869\n",
    "Weighted false positive rate = 0.540540858162954\n",
    "\n",
    "rf_paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [20]) \\\n",
    "    .addGrid(rf.maxDepth, [10]) \\\n",
    "    .addGrid(rf.impurity, [\"gini\"])\\\n",
    "    .build()\n",
    "\n",
    "Confusion Matrix\n",
    "[[287361. 121892.]\n",
    " [ 43803.  38010.]]\n",
    "\n",
    "Accuracy from Confusion Matrix:  0.6625809972590242\n",
    "Accuracy from MulticlassMetrics:  0.6625809972590242\n",
    "\n",
    "Area Under the ROC 0.5833779398869698\n",
    "\n",
    "Area Under the PR Curve 0.21867308547708184\n",
    "Summary Stats\n",
    "Precision = 0.6625809972590242\n",
    "Recall = 0.6625809972590242\n",
    "F1 Score = 0.6625809972590242\n",
    "Weighted recall = 0.6625809972590243\n",
    "Weighted precision = 0.7627667057602532\n",
    "Weighted F(1) Score = 0.6992915166799253\n",
    "Weighted F(0.5) Score = 0.7344847606612861\n",
    "Weighted false positive rate = 0.4958251174850846\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "rf_crossval = CrossValidator(estimator=rf_pipeline,\n",
    "                          estimatorParamMaps=rf_paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='accuracy'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to find all our items we can call\n",
    "#dir(crossval.evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 227.34068822860718\n"
     ]
    }
   ],
   "source": [
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "\n",
    "t0 = time.time()\n",
    "cvModel_rf = rf_crossval.setParallelism(5).fit(train) # train 5 models in parallel\n",
    "print(\"train time:\", time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5856482067911174]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not sure what this metric is... rmse\n",
    "cvModel_rf.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_239c676a5646', name='numTrees', doc='Number of trees to train (>= 1).'): 10,\n",
       " Param(parent='RandomForestClassifier_239c676a5646', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       " Param(parent='RandomForestClassifier_239c676a5646', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# magic code from https://stackoverflow.com/questions/36697304/how-to-extract-model-hyper-parameters-from-spark-ml-in-pyspark\n",
    "\n",
    "cvModel_rf.getEstimatorParamMaps()[ np.argmax(cvModel_rf.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "prediction_rf = cvModel_rf.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[352170. 123227.]\n",
      " [267404. 207344.]]\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5888722247656937\n",
      "Accuracy from MulticlassMetrics:  0.5888722247656937\n",
      "\n",
      "Area Under the ROC 0.588768384905192\n",
      "\n",
      "Area Under the PR Curve 0.5913022696245284\n",
      "Summary Stats\n",
      "Precision = 0.5888722247656937\n",
      "Recall = 0.5888722247656937\n",
      "F1 Score = 0.5888722247656937\n",
      "Weighted recall = 0.5888722247656937\n",
      "Weighted precision = 0.5977981769216145\n",
      "Weighted F(1) Score = 0.5791369373921629\n",
      "Weighted F(0.5) Score = 0.5865359799475878\n",
      "Weighted false positive rate = 0.4113354549553096\n",
      "--------------------------------------------------\n",
      "Metrics2 time: 12.298969507217407\n"
     ]
    }
   ],
   "source": [
    "cmacc2(prediction_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_239c676a5646', name='numTrees', doc='Number of trees to train (>= 1).'): 10,\n",
       " Param(parent='RandomForestClassifier_239c676a5646', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       " Param(parent='RandomForestClassifier_239c676a5646', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://dsharpc.github.io/SparkMLFlights/\n",
    "#best?\n",
    "#cvModel.getEstimatorParamMaps()[ np.argmin(cvModel.avgMetrics) ]\n",
    "\n",
    "cvModel_rf.getEstimatorParamMaps()[ np.argmin(cvModel_rf.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='RandomForestClassifier_239c676a5646', name='numTrees', doc='Number of trees to train (>= 1).'): 10,\n",
       " Param(parent='RandomForestClassifier_239c676a5646', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes.'): 5,\n",
       " Param(parent='RandomForestClassifier_239c676a5646', name='impurity', doc='Criterion used for information gain calculation (case-insensitive). Supported options: entropy, gini'): 'gini'}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvModel_rf.getEstimatorParamMaps()[ np.argmax(cvModel_rf.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
