{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import context manager: SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"mllib_classifier\") \\\n",
    "        .config(\"spark.executor.memory\", '20g') \\\n",
    "        .config('spark.executor.cores', '2') \\\n",
    "        .config('spark.executor.instances', '3') \\\n",
    "        .config(\"spark.driver.memory\",'1g') \\\n",
    "        .getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark DF Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = spark.read.csv(\"/../../project/ds5559/Alice_Ed_Michael_Sam_project/BigTrips.csv\", header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip ID: string (nullable = true)\n",
      " |-- Trip Start Timestamp: string (nullable = true)\n",
      " |-- Trip End Timestamp: string (nullable = true)\n",
      " |-- Trip Seconds: string (nullable = true)\n",
      " |-- Trip Miles: string (nullable = true)\n",
      " |-- Pickup Census Tract: string (nullable = true)\n",
      " |-- Dropoff Census Tract: string (nullable = true)\n",
      " |-- Pickup Community Area: string (nullable = true)\n",
      " |-- Dropoff Community Area: string (nullable = true)\n",
      " |-- Fare: string (nullable = true)\n",
      " |-- Tip: string (nullable = true)\n",
      " |-- Additional Charges: string (nullable = true)\n",
      " |-- Trip Total: string (nullable = true)\n",
      " |-- Shared Trip Authorized: string (nullable = true)\n",
      " |-- Trips Pooled: string (nullable = true)\n",
      " |-- Pickup Centroid Latitude: string (nullable = true)\n",
      " |-- Pickup Centroid Longitude: string (nullable = true)\n",
      " |-- Pickup Centroid Location: string (nullable = true)\n",
      " |-- Dropoff Centroid Latitude: string (nullable = true)\n",
      " |-- Dropoff Centroid Longitude: string (nullable = true)\n",
      " |-- Dropoff Centroid Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_file.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw data file is ~12 gigabytes. Take a 25% sample, stratified by sample, to get a 3 gigabyte file. Commented out line is for testing smaller subsamples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Trip ID: string, Trip Start Timestamp: string, Trip End Timestamp: string, Trip Seconds: string, Trip Miles: string, Pickup Census Tract: string, Dropoff Census Tract: string, Pickup Community Area: string, Dropoff Community Area: string, Fare: string, Tip: string, Additional Charges: string, Trip Total: string, Shared Trip Authorized: string, Trips Pooled: string, Pickup Centroid Latitude: string, Pickup Centroid Longitude: string, Pickup Centroid Location: string, Dropoff Centroid Latitude: string, Dropoff Centroid Longitude: string, Dropoff Centroid Location: string]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final_DF = data_file.sample(0.25).sample(0.0001)\n",
    "final_DF = data_file\n",
    "del(data_file)\n",
    "final_DF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/53304688/spark-date-format-mmm-dd-yyyy-hhmmss-am-to-timestamp-in-df\n",
    "#https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html\n",
    "#start_times = final_DF.select(\"Trip ID\",\"Trip Start Timestamp\")\n",
    "#st = start_times.withColumn(\"Trip_Start_Timestamp\",F.to_timestamp(F.col(\"Trip Start Timestamp\"), \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "\n",
    "#end_times = final_DF.select(\"Trip ID\",\"Trip End Timestamp\")\n",
    "#et = end_times.withColumn(\"Trip_End_Timestamp\",F.to_timestamp(F.col(\"Trip End Timestamp\"), \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "final_DF = final_DF.withColumn(\"Trip Start Timestamp\",F.to_timestamp(F.col(\"Trip Start Timestamp\"), \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "final_DF = final_DF.withColumn(\"Trip End Timestamp\",F.to_timestamp(F.col(\"Trip End Timestamp\"), \"MM/dd/yyyy hh:mm:ss a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final_DF = final_DF.join(st.select(\"Trip ID\",\"Trip_Start_Timestamp\"),on=\"Trip ID\").join(et.select(\"Trip ID\",\"Trip_End_Timestamp\"),on=\"Trip ID\")\n",
    "#https://stackoverflow.com/questions/49397966/in-pyspark-how-do-you-add-concat-a-string-to-a-column\n",
    "final_DF = final_DF.withColumn(\"Day_Month_str\", F.concat(F.dayofmonth(F.col(\"Trip Start Timestamp\")),F.lit(\"-\"),F.month(F.col(\"Trip Start Timestamp\"))).cast(\"string\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_DF = final_DF.withColumn('Trip Seconds',F.col('Trip Seconds').cast(\"integer\"))\n",
    "final_DF = final_DF.withColumn('Trip Miles',F.col('Trip Miles').cast(\"double\"))\n",
    "final_DF = final_DF.withColumn('Pickup Community Area',F.col('Pickup Community Area').cast(\"integer\"))\n",
    "final_DF = final_DF.withColumn('Dropoff Community Area',F.col('Dropoff Community Area').cast(\"integer\"))\n",
    "final_DF = final_DF.withColumn('Fare',F.col('Fare').cast(\"double\"))\n",
    "final_DF = final_DF.withColumn('Tip',F.col('Tip').cast(\"double\"))\n",
    "final_DF = final_DF.withColumn('Additional Charges',F.col('Additional Charges').cast(\"double\"))\n",
    "final_DF = final_DF.withColumn('Trip Total',F.col('Trip Total').cast(\"double\"))\n",
    "final_DF = final_DF.withColumn('Shared Trip Authorized',F.col('Shared Trip Authorized').cast(\"boolean\"))\n",
    "final_DF = final_DF.withColumn('Trips Pooled',F.col('Trips Pooled').cast(\"integer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_DF = final_DF.withColumn(\"Tip_Flag\", F.when(F.col(\"Tip\") > 0,1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql.html#data-types\n",
    "final_DF = final_DF.withColumn(\"Trip_Year\", F.year(F.col(\"Trip Start Timestamp\"))) \\\n",
    "                    .withColumn(\"Trip_Month\", F.month(F.col(\"Trip Start Timestamp\"))) \\\n",
    "                    .withColumn(\"Trip_WeekNumber\", F.weekofyear(F.col(\"Trip Start Timestamp\"))) \\\n",
    "                    .withColumn(\"Trip_DayofWeek\", F.dayofweek(F.col(\"Trip Start Timestamp\"))) \\\n",
    "                    .withColumn(\"Trip_Start_Hour\", F.hour(F.col(\"Trip Start Timestamp\"))) \\\n",
    "                    .withColumn(\"Trip_End_Hour\", F.hour(F.col(\"Trip End Timestamp\"))) \\\n",
    "                    .withColumn(\"Date\", F.to_date(F.col(\"Trip Start Timestamp\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_DF = final_DF.withColumnRenamed(\"Trip ID\",\"Trip_ID\") \\\n",
    "                    .withColumnRenamed(\"Trip Start Timestamp\",\"Trip_Start_Timestamp\") \\\n",
    "                    .withColumnRenamed(\"Trip End Timestamp\",\"Trip_End_Timestamp\") \\\n",
    "                    .withColumnRenamed(\"Trip Seconds\",\"Trip_Seconds\") \\\n",
    "                    .withColumnRenamed(\"Trip Miles\",\"Trip_Miles\") \\\n",
    "                    .withColumnRenamed(\"Pickup Census Tract\",\"Pickup_Census_Tract\") \\\n",
    "                    .withColumnRenamed(\"Dropoff Census Tract\",\"Dropoff_Census_Tract\") \\\n",
    "                    .withColumnRenamed(\"Pickup Community Area\",\"Pickup_Community_Area\") \\\n",
    "                    .withColumnRenamed(\"Dropoff Community Area\",\"Dropoff_Community_Area\") \\\n",
    "                    .withColumnRenamed(\"Additional Charges\",\"Additional_Charges_str\") \\\n",
    "                    .withColumnRenamed(\"Trip Total\",\"Trip_Total\") \\\n",
    "                    .withColumnRenamed(\"Shared Trip Authorized\",\"Shared_Trip_Authorized\") \\\n",
    "                    .withColumnRenamed(\"Trips Pooled\",\"Trips_Pooled\") \\\n",
    "                    .withColumnRenamed(\"Pickup Centroid Latitude\",\"Pickup_Centroid_Latitude\") \\\n",
    "                    .withColumnRenamed(\"Pickup Centroid Longitude\",\"Pickup_Centroid_Longitude\") \\\n",
    "                    .withColumnRenamed(\"Pickup Centroid Location\",\"Pickup_Centroid_Location\") \\\n",
    "                    .withColumnRenamed(\"Dropoff Centroid Latitude\",\"Dropoff_Centroid_Latitude\") \\\n",
    "                    .withColumnRenamed(\"Dropoff Centroid Longitude\",\"Dropoff_Centroid_Longitude\") \\\n",
    "                    .withColumnRenamed(\"Dropoff Centroid Location\",\"Dropoff_Centroid_Location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.71 ms, sys: 616 µs, total: 2.33 ms\n",
      "Wall time: 6.09 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49108003"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "final_DF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip_ID: string (nullable = true)\n",
      " |-- Trip_Start_Timestamp: timestamp (nullable = true)\n",
      " |-- Trip_End_Timestamp: timestamp (nullable = true)\n",
      " |-- Trip_Seconds: integer (nullable = true)\n",
      " |-- Trip_Miles: double (nullable = true)\n",
      " |-- Pickup_Census_Tract: string (nullable = true)\n",
      " |-- Dropoff_Census_Tract: string (nullable = true)\n",
      " |-- Pickup_Community_Area: integer (nullable = true)\n",
      " |-- Dropoff_Community_Area: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: double (nullable = true)\n",
      " |-- Additional_Charges_str: double (nullable = true)\n",
      " |-- Trip_Total: double (nullable = true)\n",
      " |-- Shared_Trip_Authorized: boolean (nullable = true)\n",
      " |-- Trips_Pooled: integer (nullable = true)\n",
      " |-- Pickup_Centroid_Latitude: string (nullable = true)\n",
      " |-- Pickup_Centroid_Longitude: string (nullable = true)\n",
      " |-- Pickup_Centroid_Location: string (nullable = true)\n",
      " |-- Dropoff_Centroid_Latitude: string (nullable = true)\n",
      " |-- Dropoff_Centroid_Longitude: string (nullable = true)\n",
      " |-- Dropoff_Centroid_Location: string (nullable = true)\n",
      " |-- Day_Month_str: string (nullable = true)\n",
      " |-- Tip_Flag: integer (nullable = false)\n",
      " |-- Trip_Year: integer (nullable = true)\n",
      " |-- Trip_Month: integer (nullable = true)\n",
      " |-- Trip_WeekNumber: integer (nullable = true)\n",
      " |-- Trip_DayofWeek: integer (nullable = true)\n",
      " |-- Trip_Start_Hour: integer (nullable = true)\n",
      " |-- Trip_End_Hour: integer (nullable = true)\n",
      " |-- Date: date (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_DF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.5 ms, sys: 38.4 ms, total: 80.9 ms\n",
      "Wall time: 11min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "final_DF.write.parquet(\"final_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 796 µs, sys: 768 µs, total: 1.56 ms\n",
      "Wall time: 289 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = spark.read.parquet(\"final_dataset.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49108003"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code cell takes approximately 700-800 milliseconds to run (five trials all fell within this range)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark RDD Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "all_data = sc.textFile('/../../project/ds5559/Alice_Ed_Michael_Sam_project/BigTrips.csv')\n",
    "all_data = all_data.map(lambda x: x.split(\",\"))\n",
    "\n",
    "rdd = sc.parallelize(all_data.sample(False,0.25).sample(False,0.0001).collect())\n",
    "\n",
    "header = rdd.take(1)[0]\n",
    "rdd = rdd.filter(lambda x: x != header)\n",
    "final_DF = rdd.toDF()\n",
    "\n",
    "del(all_data)\n",
    "final_DF.cache()\n",
    "start_times = rdd.map(lambda x: (x[0],x[1]))\n",
    "start_times = start_times.toDF()\n",
    "st = start_times.withColumn(\"Trip_Start_Timestamp\",F.to_timestamp(F.col(\"_2\"), \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "\n",
    "end_times = rdd.map(lambda x: (x[0],x[2]))\n",
    "end_times = end_times.toDF()\n",
    "et = end_times.withColumn(\"Trip_End_Timestamp\",F.to_timestamp(F.col(\"_2\"), \"MM/dd/yyyy hh:mm:ss a\"))\n",
    "\n",
    "final_DF = final_DF.join(st.select(\"_1\",\"Trip_Start_Timestamp\"),on=\"_1\").join(et.select(\"_1\",\"Trip_End_Timestamp\"),on=\"_1\")\n",
    "final_DF = final_DF.withColumn(\"Day_Month_str\", F.concat(F.dayofmonth(F.col(\"Trip_Start_Timestamp\")),F.lit(\"-\"),F.month(F.col(\"Trip_Start_Timestamp\"))).cast(\"string\"))\n",
    "final_DF.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code cell takes approximately 6 seconds to run (five trials fell within ~0.5 seconds of this timemark)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Subselection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/40421845/pyspark-dataframe-filter-or-include-based-on-list\n",
    "#filter by holidays - Christmas, New Year's Day, Valentine's Day\n",
    "final_DF.filter(final_DF.Day_Month_str.isin([\"25-12\", \\\n",
    "                                             \"1-1\", \\\n",
    "                                             \"14-2\"\n",
    "                                            ])).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, include year, for holidays not set on a particular date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_DF = final_DF.withColumn(\"Date_str\", F.to_date(F.col(\"Trip_Start_Timestamp\")).cast(\"string\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter by full date, Christmas 2019, Easter 2020\n",
    "final_DF.filter(final_DF.Date_str.isin([\"2019-12-25\", \\\n",
    "                                        \"2020-04-12\",\n",
    "                                        ])).show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559 Spark 3",
   "language": "python",
   "name": "ds5559_spark3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
