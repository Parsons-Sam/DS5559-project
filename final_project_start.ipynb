{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of DS5559 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Left Twix Members\n",
    "\n",
    "* Alice Wright - aew7j\n",
    "* Edward Thompson - ejt8b\n",
    "* Michael Davies -  mld9s\n",
    "* Sam Parsons - sp8hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In STAT 6021 members of our cohort looked at Transportation Network Company data sets to see if there was a potential relationship between tipping and other indicators, specifically with “transportation network providers” i.e. rideshares such as Uber, Lyft, etc.  At that point in our Data Science journey we did not have the skills or equipment to investigate this question in depth.  \n",
    "\n",
    "Utilizing machine learning skills from SYS 6018 and applying Spark to this dataset we hope to come up with a more robust set of answers and potentially a better predictor of tipping. With other classification algorithms such as random forest and the heavy-weight data processing of Spark, will we be able to create a more robust predictive model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Questions from the TNC Data:\n",
    "\n",
    "* Can it be predicted what fares are most likely to tip the driver?\n",
    "* Is there a relationship between time of the fare and tipping? (workday stat, bar close, weekday, weekend, etc)\n",
    "* Is there a relationship between start or end location of the ride and tipping? (downtown pickup, north shore, airport, etc)\n",
    "* Is there a relationship between length or cost of ride and tipping? (do longer rides result in tips)\n",
    "* Using this data would we be able to make recommendations to drivers to maximize likelihood of receiving a tip?\n",
    "* Is the likelihood of tipping changing over time?  Are more rides being tipped?\n",
    "* Are there re-identification abilities in this dataset? For instance, can we find records for a person who reliably takes a rideshare to/from work every day thereby linking a home address to a work address?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, joining in additional datasets may yield answers to questions about external factors such as:\n",
    "* How did news reporting/social media on rideshare companies correlate with tipping?\n",
    "* What relationship(s) does trip demand have with the stocks of these companies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source:\n",
    "The best data source for this appears to be from the City of Chicago, as it is large (169M records and 21 columns), relatively clean, anonymized, and accessible via API.\n",
    "\n",
    "City of Chicago:\n",
    "https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips/m6dm-c72p\n",
    "\n",
    "So far we have only pulled the data down via a CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Rubric\n",
    "\n",
    "* Data Import and PreProcessing | 2 pts\n",
    "\n",
    "* Data splitting/sampling | 1 pt\n",
    "\n",
    "* EDA (min two graphs) | 2 pts\n",
    "\n",
    "* Model construction (min 3 models) | 3 pts\n",
    "\n",
    "* Model evaluation | 2 pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import context manager: SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# import data types\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType\n",
    "import pyspark.sql.types as typ\n",
    "import pyspark.sql.functions as F\n",
    "import os\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"mllib_classifier\") \\\n",
    "        .config(\"spark.executor.memory\", '21g') \\\n",
    "        .config('spark.executor.cores', '2') \\\n",
    "        .config('spark.executor.instances', '3') \\\n",
    "        .config(\"spark.driver.memory\",'1g') \\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                       Type               Data/Info\n",
      "-----------------------------------------------------------\n",
      "ArrayType                      type               <class 'pyspark.sql.types.ArrayType'>\n",
      "Binarizer                      type               <class 'pyspark.ml.feature.Binarizer'>\n",
      "BinaryType                     type               <class 'pyspark.sql.types.BinaryType'>\n",
      "BooleanType                    type               <class 'pyspark.sql.types.BooleanType'>\n",
      "ByteType                       type               <class 'pyspark.sql.types.ByteType'>\n",
      "DataType                       type               <class 'pyspark.sql.types.DataType'>\n",
      "DateType                       type               <class 'pyspark.sql.types.DateType'>\n",
      "DecimalType                    type               <class 'pyspark.sql.types.DecimalType'>\n",
      "DenseVector                    type               <class 'pyspark.ml.linalg.DenseVector'>\n",
      "DoubleType                     type               <class 'pyspark.sql.types.DoubleType'>\n",
      "F                              module             <module 'pyspark.sql.func<...>yspark/sql/functions.py'>\n",
      "FloatType                      type               <class 'pyspark.sql.types.FloatType'>\n",
      "IntegerType                    type               <class 'pyspark.sql.types.IntegerType'>\n",
      "LongType                       type               <class 'pyspark.sql.types.LongType'>\n",
      "MapType                        type               <class 'pyspark.sql.types.MapType'>\n",
      "MulticlassMetrics              type               <class 'pyspark.mllib.eva<...>ation.MulticlassMetrics'>\n",
      "NullType                       type               <class 'pyspark.sql.types.NullType'>\n",
      "OneHotEncoder                  type               <class 'pyspark.ml.feature.OneHotEncoder'>\n",
      "ShortType                      type               <class 'pyspark.sql.types.ShortType'>\n",
      "SparkSession                   type               <class 'pyspark.sql.session.SparkSession'>\n",
      "StringType                     type               <class 'pyspark.sql.types.StringType'>\n",
      "StructField                    type               <class 'pyspark.sql.types.StructField'>\n",
      "StructType                     type               <class 'pyspark.sql.types.StructType'>\n",
      "TimestampType                  type               <class 'pyspark.sql.types.TimestampType'>\n",
      "VectorAssembler                type               <class 'pyspark.ml.feature.VectorAssembler'>\n",
      "Vectors                        type               <class 'pyspark.mllib.linalg.Vectors'>\n",
      "assembler                      VectorAssembler    VectorAssembler_d7e29bc12855\n",
      "binarizedTip                   DataFrame          DataFrame[Trip_ID: string<...>g, binarized_tip: double]\n",
      "binarizer                      Binarizer          Binarizer_11f645e68a7f\n",
      "customSchema                   StructType         StructType(List(StructFie<...>cation,StringType,true)))\n",
      "df4                            DataFrame          DataFrame[Trip_ID: string<...>mmunity_Area_vec: vector]\n",
      "df5                            DataFrame          DataFrame[Trip_ID: string<...>vector, features: vector]\n",
      "onehotencoder_dropoff_vector   OneHotEncoder      OneHotEncoder_4ca71734600c\n",
      "onehotencoder_pickup_vector    OneHotEncoder      OneHotEncoder_f4d708f9de88\n",
      "os                             module             <module 'os' from '/opt/c<...>nda/lib/python3.7/os.py'>\n",
      "predictor_col_for_lr           list               n=8\n",
      "sc                             SparkContext       <SparkContext master=loca<...>appName=mllib_classifier>\n",
      "spark                          SparkSession       <pyspark.sql.session.Spar<...>object at 0x7f7e584c9390>\n",
      "transformed                    DataFrame          DataFrame[Trip_ID: string<...>vector, features: vector]\n",
      "typ                            module             <module 'pyspark.sql.type<...>on/pyspark/sql/types.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clear old df\n",
    "#del (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in our Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Custom Schema.  \n",
    "This schema was been primarly determined by using a much smaller dataset and letting spark infer the schema.  We encountered an issue with spark reading in the ENTIRE dataset as NULL when there was a type mismatch.  Only the data we are likely to use later has been assigned to a specific type, otherwise it is left as a string type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+------------+----------+-------------------+--------------------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+------------------------+-------------------------+------------------------+-------------------------+--------------------------+-------------------------+\n",
      "|             Trip_ID|Trip_Start_Timestamp|  Trip_End_Timestamp|Trip_Seconds|Trip_Miles|Pickup_Census_Tract|Dropoff_Census_Tract|Pickup_Community_Area|Dropoff_Community_Area|Fare|Tip|Additional_Charges|Trip_Total|Shared_Trip_Authorized|Trips_Pooled|Pickup_Centroid_Latitude|Pickup_Centroid_Longitude|Pickup_Centroid_Location|Dropoff_Centroid_Latitude|Dropoff_Centroid_Longitude|Dropoff_Centroid_Location|\n",
      "+--------------------+--------------------+--------------------+------------+----------+-------------------+--------------------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+------------------------+-------------------------+------------------------+-------------------------+--------------------------+-------------------------+\n",
      "|bea79abbef050980e...|12/01/2019 12:15:...|12/01/2019 01:00:...|      2675.0|      32.5|        17031980000|                null|                 76.0|                  null|70.0|0.0|              9.06|     79.06|                 false|         1.0|           41.9790708201|           -87.9030396611|    POINT (-87.903039...|                     null|                      null|                     null|\n",
      "|00f26da5601bbcf98...|12/01/2019 12:15:...|12/01/2019 12:15:...|       550.0|       2.8|        17031242100|         17031081700|                 24.0|                   8.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|           41.8996701799|           -87.6698377982|    POINT (-87.669837...|            41.8920421365|            -87.6318639497|     POINT (-87.631863...|\n",
      "|02256ef89c5c4be82...|12/01/2019 12:15:...|12/01/2019 12:30:...|       922.0|       2.8|        17031080300|         17031281900|                  8.0|                  28.0|10.0|0.0|              3.11|     13.11|                 false|         1.0|           41.9074919303|           -87.6357600901|    POINT (-87.635760...|            41.8792550844|             -87.642648998|     POINT (-87.642648...|\n",
      "|072cb06b1a88042c4...|12/01/2019 12:15:...|12/01/2019 12:30:...|      1475.0|      12.5|        17031310600|         17031063302|                 31.0|                   6.0|17.5|4.0|              2.55|     24.05|                 false|         1.0|           41.8563332167|           -87.6595642391|    POINT (-87.659564...|            41.9347624564|            -87.6398538587|     POINT (-87.639853...|\n",
      "|099257be99c66c8b2...|12/01/2019 12:15:...|12/01/2019 12:30:...|       594.0|       2.5|        17031310600|         17031330100|                 31.0|                  33.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|           41.8563332167|           -87.6595642391|    POINT (-87.659564...|             41.859349715|            -87.6173580061|     POINT (-87.617358...|\n",
      "+--------------------+--------------------+--------------------+------------+----------+-------------------+--------------------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+------------------------+-------------------------+------------------------+-------------------------+--------------------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a custom schema.  \n",
    "\n",
    "customSchema = StructType([\n",
    "    StructField('Trip_ID', StringType(), True),        \n",
    "    StructField('Trip_Start_Timestamp', StringType(), True),\n",
    "    StructField('Trip_End_Timestamp', StringType(), True),\n",
    "    StructField('Trip_Seconds', DoubleType(), True),\n",
    "    StructField('Trip_Miles', DoubleType(), True),\n",
    "    StructField('Pickup_Census_Tract', StringType(), True),\n",
    "    StructField('Dropoff_Census_Tract', StringType(), True),\n",
    "    StructField('Pickup_Community_Area', DoubleType(), True),\n",
    "    StructField('Dropoff_Community_Area', DoubleType(), True),\n",
    "    StructField(\"Fare\", DoubleType(), True),\n",
    "    StructField(\"Tip\", DoubleType(), True),\n",
    "    StructField(\"Additional_Charges\", DoubleType(), True),\n",
    "    StructField(\"Trip_Total\", StringType(), True),\n",
    "    StructField(\"Shared_Trip_Authorized\", BooleanType(), True),\n",
    "    StructField(\"Trips_Pooled\", DoubleType(), True),\n",
    "    StructField('Pickup_Centroid_Latitude', StringType(), True),\n",
    "    StructField('Pickup_Centroid_Longitude', StringType(), True),\n",
    "    StructField('Pickup_Centroid_Location', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Latitude', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Longitude', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Location', StringType(), True)\n",
    "])\n",
    "\n",
    "#old readin.  Infer is slow for large dataset\n",
    "#df = spark.read.csv('/../../project/ds5559/Alice_Ed_Michael_Sam_project/BigTrips.csv', header = True, inferSchema=True)\n",
    "\n",
    "#read in the data to a dataframe\n",
    "df = spark.read.csv('/../../project/ds5559/Alice_Ed_Michael_Sam_project/BigTrips.csv', header = True, schema=customSchema)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile('/../../project/ds5559/Alice_Ed_Michael_Sam_project/BigTrips.csv')\n",
    "rdd = rdd.map(lambda x: x.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/53304688/spark-date-format-mmm-dd-yyyy-hhmmss-am-to-timestamp-in-df\n",
    "#https://spark.apache.org/docs/latest/sql-ref-datetime-pattern.html\n",
    "start_times = rdd.map(lambda x: (x[0],x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_times = start_times.toDF()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = start_times.withColumn(\"_2\",to_timestamp(col(\"_2\"), \"MM/dd/yyyy hh:mm:ss a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = start_times.withColumn(\"_2\",to_timestamp(col(\"_2\"), \"MM/dd/yyyy hh:mm:ss a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doesn't update if you don't resave the variable\n",
    "\n",
    "df = df.drop('Trip_End_Timestamp', \n",
    "             'Pickup_Census_Tract',\n",
    "             'Dropoff_Census_Tract',\n",
    "             'Pickup_Centroid_Latitude',\n",
    "             'Pickup_Centroid_Longitude', \n",
    "             'Pickup_Centroid_Location', \n",
    "             'Dropoff_Centroid_Latitude', \n",
    "             'Dropoff_Centroid_Longitude', \n",
    "             'Dropoff_Centroid_Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip_ID: string (nullable = true)\n",
      " |-- Trip_Start_Timestamp: string (nullable = true)\n",
      " |-- Trip_Seconds: double (nullable = true)\n",
      " |-- Trip_Miles: double (nullable = true)\n",
      " |-- Pickup_Community_Area: double (nullable = true)\n",
      " |-- Dropoff_Community_Area: double (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: double (nullable = true)\n",
      " |-- Additional_Charges: double (nullable = true)\n",
      " |-- Trip_Total: string (nullable = true)\n",
      " |-- Shared_Trip_Authorized: boolean (nullable = true)\n",
      " |-- Trips_Pooled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49108003"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a sampled dataframe for faster work while developing all the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.sample(False, .005, seed = 2021).cache() #increased our sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "244762"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the big df for now\n",
    "del (df)\n",
    "\n",
    "#hopefully that will make things faster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.select('Trip_ID').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From reading the data dictionary it appears that there are multiple ways that pickup and drop off locations are being reported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we do histograms of the pickup and drop off areas?  To see if there are desinations that are popular (Airports, downtown, ball parks, museum row... etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fare and Tip Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://spark.apache.org/docs/2.2.0/api/python/pyspark.sql.html#module-pyspark.sql.functions\n",
    "heatmap_data = df2.groupby('Fare','Tip').count().sort('Fare','Tip').groupby('Fare').pivot('Tip').sum(\"count\").sort('Fare')\n",
    "heatmap_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_data = np.array(heatmap_data.drop('Fare').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://numpy.org/doc/stable/reference/generated/numpy.flipud.html#numpy.flipud\n",
    "hm_data = np.flipud(hm_data.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://mungingdata.com/pyspark/column-to-list-collect-tolocaliterator/\n",
    "fares = list(heatmap_data.select('Fare').toPandas()['Fare'])\n",
    "tips = sorted([float(x) for x in heatmap_data.columns if x != 'Fare'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.pythonpool.com/matplotlib-figsize/\n",
    "plt.figure(figsize=(20,15))\n",
    "plt.axes().set_facecolor(\"#ffffff\")\n",
    "plt.axes().set_ylabel(\"Tip Amt\")\n",
    "plt.axes().set_xlabel(\"Fare Amt\")\n",
    "#https://www.pythonpool.com/matplotlib-heatmap/\n",
    "plt.xticks(ticks=np.arange(len(fares)),labels=fares,rotation=90)\n",
    "plt.yticks(ticks=np.arange(len(tips)),labels=tips)\n",
    "hm = plt.imshow(hm_data,cmap='Blues',interpolation=\"none\")\n",
    "plt.colorbar(hm)\n",
    "plt.title(\"Tip Amounts by Fare Amounts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = df2.groupby('Pickup_Community_Area','Dropoff_Community_Area').count().\\\n",
    "                    sort('Pickup_Community_Area','Dropoff_Community_Area').groupby('Pickup_Community_Area').pivot('Dropoff_Community_Area').sum(\"count\").sort('Pickup_Community_Area')\n",
    "#heatmap_data = heatmap_data.groupby('Pickup_Community_Area').pivot('Dropoff_Community_Area').count()\n",
    "heatmap_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_data = np.array(heatmap_data.drop('Pickup_Community_Area').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_data = np.flipud(hm_data.transpose())\n",
    "#https://mungingdata.com/pyspark/column-to-list-collect-tolocaliterator/\n",
    "pickups = sorted(list(heatmap_data.select('Pickup_Community_Area').toPandas()['Pickup_Community_Area']))\n",
    "dropoffs = sorted([float(\"nan\") if x == \"null\" else float(x) for x in heatmap_data.columns if x != 'Pickup_Community_Area'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.pythonpool.com/matplotlib-figsize/\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.axes().set_facecolor(\"#ffffff\")\n",
    "plt.axes().set_ylabel(\"Pickup Areas\")\n",
    "plt.axes().set_xlabel(\"Dropoff Areas\")\n",
    "#https://www.pythonpool.com/matplotlib-heatmap/\n",
    "plt.xticks(ticks=np.arange(len(pickups)),labels=pickups,rotation=90)\n",
    "plt.yticks(ticks=np.arange(len(dropoffs)),labels=dropoffs)\n",
    "hm = plt.imshow(hm_data,cmap='Blues',interpolation=\"none\")\n",
    "plt.colorbar(hm)\n",
    "plt.title(\"Tip Heatmap by Pickup and Dropoff Community Areas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_data = df2.groupby('Pickup_Community_Area','Dropoff_Community_Area').count().\\\n",
    "                    sort('Pickup_Community_Area','Dropoff_Community_Area').groupby('Pickup_Community_Area').pivot('Dropoff_Community_Area').sum(\"count\").sort('Pickup_Community_Area')\n",
    "#heatmap_data = heatmap_data.groupby('Pickup_Community_Area').pivot('Dropoff_Community_Area').count()\n",
    "heatmap_data.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_data = np.array(heatmap_data.drop('Pickup_Community_Area').toPandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_data = np.flipud(hm_data.transpose())\n",
    "#https://mungingdata.com/pyspark/column-to-list-collect-tolocaliterator/\n",
    "pickups = sorted(list(heatmap_data.select('Pickup_Community_Area').toPandas()['Pickup_Community_Area']))\n",
    "dropoffs = sorted([float(\"nan\") if x == \"null\" else float(x) for x in heatmap_data.columns if x != 'Pickup_Community_Area'], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.pythonpool.com/matplotlib-figsize/\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.axes().set_facecolor(\"#ffffff\")\n",
    "plt.axes().set_ylabel(\"Pickup Areas\")\n",
    "plt.axes().set_xlabel(\"Dropoff Areas\")\n",
    "#https://www.pythonpool.com/matplotlib-heatmap/\n",
    "plt.xticks(ticks=np.arange(len(pickups)),labels=pickups,rotation=90)\n",
    "plt.yticks(ticks=np.arange(len(dropoffs)),labels=dropoffs)\n",
    "hm = plt.imshow(hm_data,cmap='Blues',interpolation=\"none\")\n",
    "plt.colorbar(hm)\n",
    "plt.title(\"Tip Heatmap by Pickup and Dropoff Community Areas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickups_hist = df2.groupby('Pickup_Community_Area').count().withColumnRenamed(\"count\",\"area_count\").sort(\"area_count\")\n",
    "#https://stackoverflow.com/questions/38610559/convert-spark-dataframe-column-to-python-list\n",
    "areas = [str(x.Pickup_Community_Area) for x in pickups_hist.collect()]\n",
    "area_count = [x.area_count for x in pickups_hist.collect()]\n",
    "plt.figure(figsize=(35,10))\n",
    "plt.bar(areas,area_count, color='lightblue')\n",
    "plt.title('Pickup Community Areas Histogram')\n",
    "plt.axes().set_facecolor(\"#ffffff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropoffs_hist = df2.groupby('Dropoff_Community_Area').count().withColumnRenamed(\"count\",\"area_count\").sort(\"area_count\")\n",
    "areas = [str(x.Dropoff_Community_Area) for x in dropoffs_hist.collect()]\n",
    "area_count = [x.area_count for x in dropoffs_hist.collect()]\n",
    "plt.figure(figsize=(35,10))\n",
    "plt.bar(areas,area_count, color='lightblue')\n",
    "plt.title('Dropoff Community Areas Histogram')\n",
    "plt.axes().set_facecolor(\"#ffffff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only showing top 10 as we have pretty large fall off.  Now to replace nulls with actual values.  Will use 99 for areas outside the city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets sort the list, added desc to order the list from largest to smallest\n",
    "\n",
    "df2.groupby('Pickup_Community_Area').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just for reference https://www.google.com/maps/d/u/0/viewer?ll=41.91066822076546%2C-87.63676464181398&spn=0.340714%2C0.699692&msa=0&mid=1O-3Uot4mSetKW-M_govahruUjDc&z=12\n",
    "\n",
    "Top Pickup Areas\n",
    "\n",
    "* 8 is the area of Magnificiant Mile (high end shopping), the riverwalk (tourism, boat tours), Gold Coast Neigherborhood (very high income neigherhood), and Navy Pier (tourist trap)\n",
    "* 28 is the Near West Side neigherborhoods of West Loop, Greektown, and Fulton's Market.  Lots of new condos and resturants.  Also has University of Illinois Chicago, the Medical District (University and VA hospitals) and the United Center (home of the Bull and Blackhawks)\n",
    "* null is outside the city\n",
    "* 32 is \"The Loop\" downtown busisness district, train El hub\n",
    "* 6 is Lakeview, Near north neigherbood perdominatly white and has the Chciago Cubs Stadium\n",
    "* 24 West Town and has the neigherborhoods of Wicker Park, Ukranian Village, and River West.  These neigherbohoods have all been ungergroing gentrification.\n",
    "* 7 Lincoln Park.  Like Lakeview but more expensive.  Was one of the first neigherborhoods in Chicago to gentrify.  \n",
    "* 22 Logan Square.  Edge of transitioning neigherbood.  More afforable for new gentrifiying owners.\n",
    "* 76 O'Hare Airport\n",
    "* 3 Uptown, north of Lakeview, similar to Logan Square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same for the dropoffs\n",
    "df2.groupby('Dropoff_Community_Area').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby('Dropoff_Community_Area').count().orderBy('Dropoff_Community_Area', ascending=False).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just for reference https://www.google.com/maps/d/u/0/viewer?ll=41.91066822076546%2C-87.63676464181398&spn=0.340714%2C0.699692&msa=0&mid=1O-3Uot4mSetKW-M_govahruUjDc&z=12\n",
    "\n",
    "Dropoff Areas\n",
    "\n",
    "* 8is the area of Magnificiant Mile (high end shopping), the riverwalk (tourism, boat tours), Gold Coast Neigherborhood (very high income neigherhood), and Navy Pier (tourist trap)\n",
    "* 32 is \"The Loop\" downtown busisness district, train El hub\n",
    "* 28 is the Near West Side neigherborhoods of West Loop, Greektown, and Fulton's Market.  Lots of new condos and resturants.  Also has University of Illinois Chicago, the Medical District (University and VA hospitals) and the United Center (home of the Bull and Blackhawks)\n",
    "* null is outside the city\n",
    "* 6 is Lakeview, Near north neigherbood perdominatly white and has the Chciago Cubs Stadium\n",
    "* 24 West Town and has the neigherborhoods of Wicker Park, Ukranian Village, and River West.  These neigherbohoods have all been ungergroing gentrification.\n",
    "* 7 Lincoln Park. Like Lakeview but more expensive.  Was one of the first neigherborhoods in Chicago to gentrify.  \n",
    "* 76 O'Hare Airport\n",
    "* 22 Logan Square.  Edge of transitioning neigherbood.  More afforable for new gentrifiying owners.\n",
    "* 3 Uptown, north of Lakeview, similar to Logan Square."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lists are almost identical, just a few order changes.\n",
    "\n",
    "How much of the traffic comes from these heavy use neigherborhoods?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace our null values in the pickup and dropoff locations\n",
    "# https://stackoverflow.com/questions/42312042/how-to-replace-all-null-values-of-a-dataframe-in-pyspark\n",
    "\n",
    "# choosing 78 as it is not a Chicago Community Area and using a larger number will result in a larger OHE matrix later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.na.fill(value=78,subset=['Pickup_Community_Area', 'Dropoff_Community_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----+\n",
      "|Dropoff_Community_Area|count|\n",
      "+----------------------+-----+\n",
      "|                   8.0|33047|\n",
      "|                  78.0|19837|\n",
      "|                  28.0|19285|\n",
      "|                  32.0|18833|\n",
      "|                   6.0|14692|\n",
      "|                  24.0|12973|\n",
      "|                   7.0|11656|\n",
      "|                  76.0| 8499|\n",
      "|                  22.0| 7867|\n",
      "|                   3.0| 5058|\n",
      "+----------------------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.groupby('Dropoff_Community_Area').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.groupby('Pickup_Community_Area').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like it works to change the nulls to a 78 for the community area.\n",
    "\n",
    "Next lets add a colum with the tip or no tip as a binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old code, Michaels worked better.  This should be deleted later\n",
    "\n",
    "#do we need this lit function?\n",
    "#https://hackersandslackers.com/transforming-pyspark-dataframes/\n",
    "#from pyspark.sql.functions import lit, when, col\n",
    "#df4 = df3.withColumn('testColumn', F.lit('this is a test'))\n",
    "# that worked\n",
    "#df4 = df3.withColumn('Tip_Bool', when((col(\"tip\") > 0), 1).otherwise(0))\n",
    "# df = df.withColumn([COLUMN_NAME]. F.when([CONDITIONAL], [COLUMN_VALUE]).otherwsie([COLUMN_VALUE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Trip_ID: string, Trip_Start_Timestamp: string, Trip_Seconds: double, Trip_Miles: double, Pickup_Community_Area: double, Dropoff_Community_Area: double, Fare: double, Tip: double, Additional_Charges: double, Trip_Total: string, Shared_Trip_Authorized: boolean, Trips_Pooled: double, binarized_tip: double]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the biniazier that Michael found\n",
    "\n",
    "# https://spark.apache.org/docs/2.2.0/ml-features.html#binarizer\n",
    "\n",
    "from pyspark.ml.feature import Binarizer\n",
    "#binarizer = Binarizer(threshold=0.5, inputCol=\"feature\", outputCol=\"binarized_feature\")\n",
    "binarizer = Binarizer(threshold=0, inputCol=\"Tip\", outputCol=\"binarized_tip\")\n",
    "binarizedTip = binarizer.transform(df3)\n",
    "df4=binarizedTip.cache()\n",
    "\n",
    "display(binarizedTip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+\n",
      "|             Trip_ID|Trip_Start_Timestamp|Trip_Seconds|Trip_Miles|Pickup_Community_Area|Dropoff_Community_Area|Fare|Tip|Additional_Charges|Trip_Total|Shared_Trip_Authorized|Trips_Pooled|binarized_tip|\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+\n",
      "|1d7fc864aa5f775df...|12/01/2019 12:15:...|       543.0|       3.1|                  7.0|                   8.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|          0.0|\n",
      "|1dc1dd5e6d3fb5bf1...|12/01/2019 12:15:...|      1242.0|      19.5|                 32.0|                  28.0| 5.0|0.0|               0.0|         5|                  true|         3.0|          0.0|\n",
      "|2cbdf4e75915f9538...|12/01/2019 12:15:...|      1035.0|       5.0|                 24.0|                   7.0|10.0|0.0|              2.55|     12.55|                 false|         1.0|          0.0|\n",
      "|307ad0d42bc538fd7...|12/01/2019 12:15:...|       448.0|       3.4|                  8.0|                  22.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|          0.0|\n",
      "|311b0496dad70cde4...|12/01/2019 12:15:...|       694.0|       4.2|                 31.0|                  24.0|10.0|0.0|              2.55|     12.55|                 false|         1.0|          0.0|\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.groupby('Dropoff_Community_Area', 'binarized_tip').count().orderBy('count', ascending=False).show(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i guess now we should start doing more statistics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.groupby(\"binarized_tip\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can we do a logistic model with what we have now?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+-------------------------+--------------------------+\n",
      "|             Trip_ID|Trip_Start_Timestamp|Trip_Seconds|Trip_Miles|Pickup_Community_Area|Dropoff_Community_Area|Fare|Tip|Additional_Charges|Trip_Total|Shared_Trip_Authorized|Trips_Pooled|binarized_tip|Pickup_Community_Area_vec|Dropoff_Community_Area_vec|\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+-------------------------+--------------------------+\n",
      "|1d7fc864aa5f775df...|12/01/2019 12:15:...|       543.0|       3.1|                  7.0|                   8.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|          0.0|           (78,[7],[1.0])|            (78,[8],[1.0])|\n",
      "|1dc1dd5e6d3fb5bf1...|12/01/2019 12:15:...|      1242.0|      19.5|                 32.0|                  28.0| 5.0|0.0|               0.0|         5|                  true|         3.0|          0.0|          (78,[32],[1.0])|           (78,[28],[1.0])|\n",
      "|2cbdf4e75915f9538...|12/01/2019 12:15:...|      1035.0|       5.0|                 24.0|                   7.0|10.0|0.0|              2.55|     12.55|                 false|         1.0|          0.0|          (78,[24],[1.0])|            (78,[7],[1.0])|\n",
      "|307ad0d42bc538fd7...|12/01/2019 12:15:...|       448.0|       3.4|                  8.0|                  22.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|          0.0|           (78,[8],[1.0])|           (78,[22],[1.0])|\n",
      "|311b0496dad70cde4...|12/01/2019 12:15:...|       694.0|       4.2|                 31.0|                  24.0|10.0|0.0|              2.55|     12.55|                 false|         1.0|          0.0|          (78,[31],[1.0])|           (78,[24],[1.0])|\n",
      "|387c40aa5f66f8c85...|12/01/2019 12:15:...|       664.0|       4.1|                 24.0|                   5.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|          0.0|          (78,[24],[1.0])|            (78,[5],[1.0])|\n",
      "|38c1b328d17420404...|12/01/2019 12:15:...|       763.0|       5.5|                 24.0|                   6.0|12.5|5.0|              3.11|     20.61|                 false|         1.0|          1.0|          (78,[24],[1.0])|            (78,[6],[1.0])|\n",
      "|4530f5f266da1fa88...|12/01/2019 12:15:...|      1116.0|      13.7|                 76.0|                  22.0|27.5|3.0|               0.0|      30.5|                  true|         1.0|          1.0|          (78,[76],[1.0])|           (78,[22],[1.0])|\n",
      "|4ddb1c2b374a8a082...|12/01/2019 12:15:...|      1332.0|      12.8|                 56.0|                   8.0|27.5|7.0|              7.55|     42.05|                 false|         1.0|          1.0|          (78,[56],[1.0])|            (78,[8],[1.0])|\n",
      "|4e9c78d3be9bb757d...|12/01/2019 12:15:...|      1107.0|       5.6|                  4.0|                  78.0|12.5|0.0|              2.55|     15.05|                 false|         1.0|          0.0|           (78,[4],[1.0])|                (78,[],[])|\n",
      "|523f6729929444c18...|12/01/2019 12:15:...|       267.0|       0.9|                 30.0|                  30.0| 5.0|0.0|              2.55|      7.55|                 false|         1.0|          0.0|          (78,[30],[1.0])|           (78,[30],[1.0])|\n",
      "|5938c0f302aafeba0...|12/01/2019 12:15:...|       785.0|       4.7|                 27.0|                  25.0| 7.5|0.0|              2.55|     10.05|                  true|         1.0|          0.0|          (78,[27],[1.0])|           (78,[25],[1.0])|\n",
      "|5ca498521f0284ae1...|12/01/2019 12:15:...|       298.0|       0.9|                 32.0|                   8.0| 7.5|4.0|              2.85|     14.35|                 false|         1.0|          1.0|          (78,[32],[1.0])|            (78,[8],[1.0])|\n",
      "|5cbad0e9bf06aa3c6...|12/01/2019 12:15:...|      1116.0|       5.4|                  3.0|                  11.0|12.5|0.0|              2.55|     15.05|                 false|         1.0|          0.0|           (78,[3],[1.0])|           (78,[11],[1.0])|\n",
      "|649b42138fca921ba...|12/01/2019 12:15:...|       481.0|       1.8|                  7.0|                   6.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|          0.0|           (78,[7],[1.0])|            (78,[6],[1.0])|\n",
      "|6e0ca94ec3031e105...|12/01/2019 12:15:...|       873.0|       6.1|                  8.0|                   6.0| 7.5|2.0|               0.0|       9.5|                  true|         3.0|          1.0|           (78,[8],[1.0])|            (78,[6],[1.0])|\n",
      "|87a29fa8ba3fc324d...|12/01/2019 12:15:...|      1814.0|      15.1|                 67.0|                  78.0| 7.5|0.0|              2.55|     10.05|                  true|         3.0|          0.0|          (78,[67],[1.0])|                (78,[],[])|\n",
      "|998322f0b4f6765d7...|12/01/2019 12:15:...|       153.0|       0.4|                  6.0|                   6.0| 7.5|0.0|              2.85|     10.35|                 false|         1.0|          0.0|           (78,[6],[1.0])|            (78,[6],[1.0])|\n",
      "|a3da0ea6352ff25c9...|12/01/2019 12:15:...|       655.0|       2.8|                  8.0|                  24.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|          0.0|           (78,[8],[1.0])|           (78,[24],[1.0])|\n",
      "|b7c41becbaae0747d...|12/01/2019 12:15:...|      1004.0|       7.5|                  3.0|                   8.0|15.0|0.0|              2.55|     17.55|                 false|         1.0|          0.0|           (78,[3],[1.0])|            (78,[8],[1.0])|\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+-------------------------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/@nutanbhogendrasharma/role-of-onehotencoder-and-pipelines-in-pyspark-ml-feature-part-2-3275767e74f0\n",
    "# apparently the spark doc is wrong, we don't need fit, just transform.  Maybe thats a spark 3 thing?\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "#onehotencoder to pickup\n",
    "onehotencoder_pickup_vector = OneHotEncoder(inputCol=\"Pickup_Community_Area\", outputCol=\"Pickup_Community_Area_vec\")\n",
    "df4 = onehotencoder_pickup_vector.transform(df4)\n",
    "\n",
    "#onehotencoder to dropoff\n",
    "onehotencoder_dropoff_vector = OneHotEncoder(inputCol=\"Dropoff_Community_Area\", outputCol=\"Dropoff_Community_Area_vec\")\n",
    "df4 = onehotencoder_dropoff_vector.transform(df4).cache()\n",
    "\n",
    "df4.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Trip_ID: string, Trip_Start_Timestamp: string, Trip_Seconds: double, Trip_Miles: double, Pickup_Community_Area: double, Dropoff_Community_Area: double, Fare: double, Tip: double, Additional_Charges: double, Trip_Total: string, Shared_Trip_Authorized: boolean, Trips_Pooled: double, binarized_tip: double, Pickup_Community_Area_vec: vector, Dropoff_Community_Area_vec: vector]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip_ID: string (nullable = true)\n",
      " |-- Trip_Start_Timestamp: string (nullable = true)\n",
      " |-- Trip_Seconds: double (nullable = true)\n",
      " |-- Trip_Miles: double (nullable = true)\n",
      " |-- Pickup_Community_Area: double (nullable = false)\n",
      " |-- Dropoff_Community_Area: double (nullable = false)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: double (nullable = true)\n",
      " |-- Additional_Charges: double (nullable = true)\n",
      " |-- Trip_Total: string (nullable = true)\n",
      " |-- Shared_Trip_Authorized: boolean (nullable = true)\n",
      " |-- Trips_Pooled: double (nullable = true)\n",
      " |-- binarized_tip: double (nullable = true)\n",
      " |-- Pickup_Community_Area_vec: vector (nullable = true)\n",
      " |-- Dropoff_Community_Area_vec: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_col_for_lr = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec']\n",
    "\n",
    "# removed to see if works better\n",
    "#  'Pickup_Community_Area',\n",
    "#                         'Dropoff_Community_Area',\n",
    "\n",
    "# leaving out Trip_start_Timestamp for now as I don't know know to use the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.ml.feature import VectorAssembler \n",
    "from pyspark.mllib.linalg import Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+-------------------------+--------------------------+--------------------+\n",
      "|             Trip_ID|Trip_Start_Timestamp|Trip_Seconds|Trip_Miles|Pickup_Community_Area|Dropoff_Community_Area|Fare|Tip|Additional_Charges|Trip_Total|Shared_Trip_Authorized|Trips_Pooled|binarized_tip|Pickup_Community_Area_vec|Dropoff_Community_Area_vec|            features|\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+-------------------------+--------------------------+--------------------+\n",
      "|1d7fc864aa5f775df...|12/01/2019 12:15:...|       543.0|       3.1|                  7.0|                   8.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|          0.0|           (78,[7],[1.0])|            (78,[8],[1.0])|(162,[0,1,2,3,5,1...|\n",
      "|1dc1dd5e6d3fb5bf1...|12/01/2019 12:15:...|      1242.0|      19.5|                 32.0|                  28.0| 5.0|0.0|               0.0|         5|                  true|         3.0|          0.0|          (78,[32],[1.0])|           (78,[28],[1.0])|(162,[0,1,2,4,5,3...|\n",
      "|2cbdf4e75915f9538...|12/01/2019 12:15:...|      1035.0|       5.0|                 24.0|                   7.0|10.0|0.0|              2.55|     12.55|                 false|         1.0|          0.0|          (78,[24],[1.0])|            (78,[7],[1.0])|(162,[0,1,2,3,5,3...|\n",
      "|307ad0d42bc538fd7...|12/01/2019 12:15:...|       448.0|       3.4|                  8.0|                  22.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|          0.0|           (78,[8],[1.0])|           (78,[22],[1.0])|(162,[0,1,2,3,5,1...|\n",
      "|311b0496dad70cde4...|12/01/2019 12:15:...|       694.0|       4.2|                 31.0|                  24.0|10.0|0.0|              2.55|     12.55|                 false|         1.0|          0.0|          (78,[31],[1.0])|           (78,[24],[1.0])|(162,[0,1,2,3,5,3...|\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+-------------------------+--------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from last weeks homework\n",
    "# use all of the fields as features\n",
    "\n",
    "#not sure if we should be scaling the OHE vectors but we'll try first\n",
    "\n",
    "assembler = VectorAssembler(inputCols=predictor_col_for_lr, outputCol=\"features\") \n",
    "transformed = assembler.transform(df4)\n",
    "df5 = transformed.cache()\n",
    "\n",
    "df5.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling from our homework\n",
    "\n",
    "#from https://spark.apache.org/docs/latest/ml-features#standardscaler\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "# Compute summary statistics by fitting the StandardScaler\n",
    "scalerModel = scaler.fit(df5)\n",
    "\n",
    "# Normalize each feature to have unit standard deviation.\n",
    "scaledData = scalerModel.transform(df5)\n",
    "\n",
    "\n",
    "df6 = scaledData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaledData.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our model didn't work on the standard test train split.  Prof. Tashman recomended upscalling the help with the imbalanced dataset.\n",
    "#from https://spark.apache.org/docs/2.1.0/ml-tuning.html#train-validation-split\n",
    "\n",
    "train_inital, test = df6.randomSplit([0.8, 0.2], seed=2021)\n",
    "\n",
    "train_inital.show(5)\n",
    "\n",
    "test.cache()\n",
    "test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampleing code sample\n",
    "# https://stackoverflow.com/questions/53273133/how-to-perform-up-sampling-using-sample-functionpy-spark\n",
    "\n",
    "df_a = train_inital.filter(train_inital['binarized_tip'] == 0)\n",
    "df_b = train_inital.filter(train_inital['binarized_tip'] == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_count = df_a.count()\n",
    "b_count = df_b.count() \n",
    "print(a_count)\n",
    "print(b_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = a_count / b_count\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b_overampled = df_b.sample(withReplacement=True, fraction=ratio, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = df_a.unionAll(df_b_overampled)\n",
    "train_final.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_af = train_final.filter(train_inital['binarized_tip'] == 0)\n",
    "df_bf = train_final.filter(train_inital['binarized_tip'] == 1)\n",
    "a_count = df_af.count()\n",
    "b_count = df_bf.count() \n",
    "print(a_count)\n",
    "print(b_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training size has increased.  This is to be expected in upscaling.\n",
    "\n",
    "Good reference: https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#just as a reminder what was the truth in our test data?\n",
    "\n",
    "dft_a = test.filter(train_inital['binarized_tip'] == 0)\n",
    "dft_b = test.filter(train_inital['binarized_tip'] == 1)\n",
    "count_test_a = dft_a.count()\n",
    "count_test_b = dft_b.count()\n",
    "print(count_test_a)\n",
    "print(count_test_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from the docs https://spark.apache.org/docs/latest/ml-classification-regression.html#logistic-regression\n",
    "\n",
    "# Load training data\n",
    "# training = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")\n",
    "\n",
    "#elastic net was killing all of our predictors... maybe that was good but I've turned it off for now.  Was at 0.8\n",
    "\n",
    "lr = LogisticRegression(maxIter=3,\n",
    "                        regParam=0.1,\n",
    "                        elasticNetParam=0.3,\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"binarized_tip\")\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(train_final)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModel.coefficients))\n",
    "print(\"Intercept: \" + str(lrModel.intercept))\n",
    "\n",
    "# not doing multinominal... this was from the example\n",
    "# We can also use the multinomial family for binary classification\n",
    "# mlr = LogisticRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8, family=\"multinomial\")\n",
    "\n",
    "# Fit the model\n",
    "# mlrModel = mlr.fit(train)\n",
    "\n",
    "# Print the coefficients and intercepts for logistic regression with multinomial family\n",
    "# print(\"Multinomial coefficients: \" + str(mlrModel.coefficientMatrix))\n",
    "# print(\"Multinomial intercepts: \" + str(mlrModel.interceptVector))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = lrModel.transform(test)\n",
    "prediction.show(5)\n",
    "\n",
    "df7 = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df7.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classificiation evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can't find how to do this in a Dataframe.  Rip to an RDD I guess.  This feels stupid.\n",
    "\n",
    "pred_rdd= df7.select('prediction').rdd.flatMap(lambda x: x)\n",
    "label_rdd = df7.select('binarized_tip').rdd.flatMap(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_rdd.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looks like we can zip them together\n",
    "\n",
    "predictionAndLabels =  pred_rdd.zip(label_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictionAndLabels.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics2 = MulticlassMetrics(predictionAndLabels)\n",
    "\n",
    "cm1 = metrics2.confusionMatrix().toArray()\n",
    "acc = (cm1[0][0] + cm1[1][1])/(cm1[0][0] + cm1[1][1] + cm1[0][1] + cm1[1][0]) #should be a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cm1)\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tashman's sugestion of upsampleing worked.  We no longer have a useless classifier\n",
    "\n",
    "#well that doesn't look aweseome.  Looks like we are only predicting no tip.  Might have to do some weighting magic.  Despite confusing myself, the number of results are correct since only 20% was used for the test, and 80% used in the training\n",
    "\n",
    "#maybe we should check the sample to see if there are any tips in the dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "play with paramaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#increase iterations to 10\n",
    "\n",
    "lrt = LogisticRegression(maxIter=10,\n",
    "                        regParam=0.1,\n",
    "                        elasticNetParam=0.3,\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"binarized_tip\")\n",
    "\n",
    "# Fit the model\n",
    "lrModelt = lrt.fit(train_final)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModelt.coefficients))\n",
    "print(\"Intercept: \" + str(lrModelt.intercept))\n",
    "\n",
    "predictiont = lrModelt.transform(test)\n",
    "\n",
    "pred_rddt= predictiont.select('prediction').rdd.flatMap(lambda x: x)\n",
    "label_rddt = predictiont.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "\n",
    "predictionAndLabelst =  pred_rddt.zip(label_rddt)\n",
    "\n",
    "metrics2t = MulticlassMetrics(predictionAndLabelst)\n",
    "\n",
    "cmt = metrics2t.confusionMatrix().toArray()\n",
    "acc = (cmt[0][0] + cmt[1][1])/(cmt[0][0] + cmt[1][1] + cmt[0][1] + cmt[1][0]) #should be a function\n",
    "\n",
    "print(cmt)\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regParam to 0.01\n",
    "\n",
    "lrt = LogisticRegression(maxIter=3,\n",
    "                        regParam=0.01,\n",
    "                        elasticNetParam=0.3,\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"binarized_tip\")\n",
    "\n",
    "# Fit the model\n",
    "lrModelt = lrt.fit(train_final)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModelt.coefficients))\n",
    "print(\"Intercept: \" + str(lrModelt.intercept))\n",
    "\n",
    "predictiont = lrModelt.transform(test)\n",
    "\n",
    "pred_rddt= predictiont.select('prediction').rdd.flatMap(lambda x: x)\n",
    "label_rddt = predictiont.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "\n",
    "predictionAndLabelst =  pred_rddt.zip(label_rddt)\n",
    "\n",
    "metrics2t = MulticlassMetrics(predictionAndLabelst)\n",
    "\n",
    "cmt = metrics2t.confusionMatrix().toArray()\n",
    "acc = (cmt[0][0] + cmt[1][1])/(cmt[0][0] + cmt[1][1] + cmt[0][1] + cmt[1][0]) #should be a function\n",
    "\n",
    "print(cmt)\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elasticNet to 0\n",
    "\n",
    "lrt = LogisticRegression(maxIter=3,\n",
    "                        regParam=0.1,\n",
    "                        elasticNetParam=0,\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"binarized_tip\")\n",
    "\n",
    "# Fit the model\n",
    "lrModelt = lrt.fit(train_final)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModelt.coefficients))\n",
    "print(\"Intercept: \" + str(lrModelt.intercept))\n",
    "\n",
    "predictiont = lrModelt.transform(test)\n",
    "\n",
    "pred_rddt= predictiont.select('prediction').rdd.flatMap(lambda x: x)\n",
    "label_rddt = predictiont.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "\n",
    "predictionAndLabelst =  pred_rddt.zip(label_rddt)\n",
    "\n",
    "metrics2t = MulticlassMetrics(predictionAndLabelst)\n",
    "\n",
    "cmt = metrics2t.confusionMatrix().toArray()\n",
    "\n",
    "acc = (cmt[0][0] + cmt[1][1])/(cmt[0][0] + cmt[1][1] + cmt[0][1] + cmt[1][0]) #should be a function\n",
    "\n",
    "print(cmt)\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regParam to 0.9\n",
    "\n",
    "lrt = LogisticRegression(maxIter=3,\n",
    "                        regParam=0.9,\n",
    "                        elasticNetParam=0.3,\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"binarized_tip\")\n",
    "\n",
    "# Fit the model\n",
    "lrModelt = lrt.fit(train_final)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModelt.coefficients))\n",
    "print(\"Intercept: \" + str(lrModelt.intercept))\n",
    "\n",
    "predictiont = lrModelt.transform(test)\n",
    "\n",
    "pred_rddt= predictiont.select('prediction').rdd.flatMap(lambda x: x)\n",
    "label_rddt = predictiont.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "\n",
    "predictionAndLabelst =  pred_rddt.zip(label_rddt)\n",
    "\n",
    "metrics2t = MulticlassMetrics(predictionAndLabelst)\n",
    "\n",
    "cmt = metrics2t.confusionMatrix().toArray()\n",
    "\n",
    "acc = (cmt[0][0] + cmt[1][1])/(cmt[0][0] + cmt[1][1] + cmt[0][1] + cmt[1][0]) #should be a function\n",
    "\n",
    "print(cmt)\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regParam to 0.05 elasticNet = 0\n",
    "\n",
    "lrt = LogisticRegression(maxIter=3,\n",
    "                        regParam=0.05,\n",
    "                        elasticNetParam=0,\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"binarized_tip\")\n",
    "\n",
    "# Fit the model\n",
    "lrModelt = lrt.fit(train_final)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModelt.coefficients))\n",
    "print(\"Intercept: \" + str(lrModelt.intercept))\n",
    "\n",
    "predictiont = lrModelt.transform(test)\n",
    "\n",
    "pred_rddt= predictiont.select('prediction').rdd.flatMap(lambda x: x)\n",
    "label_rddt = predictiont.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "\n",
    "predictionAndLabelst =  pred_rddt.zip(label_rddt)\n",
    "\n",
    "metrics2t = MulticlassMetrics(predictionAndLabelst)\n",
    "\n",
    "cmt = metrics2t.confusionMatrix().toArray()\n",
    "\n",
    "acc = (cmt[0][0] + cmt[1][1])/(cmt[0][0] + cmt[1][1] + cmt[0][1] + cmt[1][0]) #should be a function\n",
    "\n",
    "print(cmt)\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regParam to 0.03 elasticNet = 0.1\n",
    "\n",
    "lrt = LogisticRegression(maxIter=3,\n",
    "                        regParam=0.03,\n",
    "                        elasticNetParam=0.1,\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"binarized_tip\")\n",
    "\n",
    "# Fit the model\n",
    "lrModelt = lrt.fit(train_final)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModelt.coefficients))\n",
    "print(\"Intercept: \" + str(lrModelt.intercept))\n",
    "\n",
    "predictiont = lrModelt.transform(test)\n",
    "\n",
    "pred_rddt= predictiont.select('prediction').rdd.flatMap(lambda x: x)\n",
    "label_rddt = predictiont.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "\n",
    "predictionAndLabelst =  pred_rddt.zip(label_rddt)\n",
    "\n",
    "metrics2t = MulticlassMetrics(predictionAndLabelst)\n",
    "\n",
    "cmt = metrics2t.confusionMatrix().toArray()\n",
    "\n",
    "acc = (cmt[0][0] + cmt[1][1])/(cmt[0][0] + cmt[1][1] + cmt[0][1] + cmt[1][0]) #should be a function\n",
    "\n",
    "print(cmt)\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regParam to 0.01 elasticNet = 0.1\n",
    "\n",
    "lrt = LogisticRegression(maxIter=3,\n",
    "                        regParam=0.01,\n",
    "                        elasticNetParam=0.1,\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"binarized_tip\")\n",
    "\n",
    "# Fit the model\n",
    "lrModelt = lrt.fit(train_final)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModelt.coefficients))\n",
    "print(\"Intercept: \" + str(lrModelt.intercept))\n",
    "\n",
    "predictiont = lrModelt.transform(test)\n",
    "\n",
    "pred_rddt= predictiont.select('prediction').rdd.flatMap(lambda x: x)\n",
    "label_rddt = predictiont.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "\n",
    "predictionAndLabelst =  pred_rddt.zip(label_rddt)\n",
    "\n",
    "metrics2t = MulticlassMetrics(predictionAndLabelst)\n",
    "\n",
    "cmt = metrics2t.confusionMatrix().toArray()\n",
    "\n",
    "acc = (cmt[0][0] + cmt[1][1])/(cmt[0][0] + cmt[1][1] + cmt[0][1] + cmt[1][0]) #should be a function\n",
    "\n",
    "print(cmt)\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regParam to 0.05 elasticNet = 0, maxIter = 10\n",
    "\n",
    "lrt = LogisticRegression(maxIter=10,\n",
    "                        regParam=0.05,\n",
    "                        elasticNetParam=0,\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"binarized_tip\")\n",
    "\n",
    "# Fit the model\n",
    "lrModelt = lrt.fit(train_final)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModelt.coefficients))\n",
    "print(\"Intercept: \" + str(lrModelt.intercept))\n",
    "\n",
    "predictiont = lrModelt.transform(test)\n",
    "\n",
    "pred_rddt= predictiont.select('prediction').rdd.flatMap(lambda x: x)\n",
    "label_rddt = predictiont.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "\n",
    "predictionAndLabelst =  pred_rddt.zip(label_rddt)\n",
    "\n",
    "metrics2t = MulticlassMetrics(predictionAndLabelst)\n",
    "\n",
    "cmt = metrics2t.confusionMatrix().toArray()\n",
    "\n",
    "acc = (cmt[0][0] + cmt[1][1])/(cmt[0][0] + cmt[1][1] + cmt[0][1] + cmt[1][0]) #should be a function\n",
    "\n",
    "print(cmt)\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regParam to 0.07 elasticNet = 0, maxIter = 10\n",
    "\n",
    "lrt = LogisticRegression(maxIter=10,\n",
    "                        regParam=0.07,\n",
    "                        elasticNetParam=0,\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"binarized_tip\")\n",
    "\n",
    "# Fit the model\n",
    "lrModelt = lrt.fit(train_final)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModelt.coefficients))\n",
    "print(\"Intercept: \" + str(lrModelt.intercept))\n",
    "\n",
    "predictiont = lrModelt.transform(test)\n",
    "\n",
    "pred_rddt= predictiont.select('prediction').rdd.flatMap(lambda x: x)\n",
    "label_rddt = predictiont.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "\n",
    "predictionAndLabelst =  pred_rddt.zip(label_rddt)\n",
    "\n",
    "metrics2t = MulticlassMetrics(predictionAndLabelst)\n",
    "\n",
    "cmt = metrics2t.confusionMatrix().toArray()\n",
    "\n",
    "acc = (cmt[0][0] + cmt[1][1])/(cmt[0][0] + cmt[1][1] + cmt[0][1] + cmt[1][0]) #should be a function\n",
    "\n",
    "print(cmt)\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#regParam to 0.03 elasticNet = 0, maxIter = 10\n",
    "\n",
    "lrt = LogisticRegression(maxIter=10,\n",
    "                        regParam=0.03,\n",
    "                        elasticNetParam=0,\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"binarized_tip\")\n",
    "\n",
    "# Fit the model\n",
    "lrModelt = lrt.fit(train_final)\n",
    "\n",
    "# Print the coefficients and intercept for logistic regression\n",
    "print(\"Coefficients: \" + str(lrModelt.coefficients))\n",
    "print(\"Intercept: \" + str(lrModelt.intercept))\n",
    "\n",
    "predictiont = lrModelt.transform(test)\n",
    "\n",
    "pred_rddt= predictiont.select('prediction').rdd.flatMap(lambda x: x)\n",
    "label_rddt = predictiont.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "\n",
    "predictionAndLabelst =  pred_rddt.zip(label_rddt)\n",
    "\n",
    "metrics2t = MulticlassMetrics(predictionAndLabelst)\n",
    "\n",
    "cmt = metrics2t.confusionMatrix().toArray()\n",
    "\n",
    "acc = (cmt[0][0] + cmt[1][1])/(cmt[0][0] + cmt[1][1] + cmt[0][1] + cmt[1][0]) #should be a function\n",
    "\n",
    "print(cmt)\n",
    "print()\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enough wasting pixels\n",
    "# can we make a lr pipeline using our notes from this week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.ml import Pipeline  \n",
    "# from pyspark.ml.feature import *  \n",
    "# from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# # Configure pipeline stages\n",
    "# # process review data\n",
    "# tok = Tokenizer(inputCol=\"review\", outputCol=\"words\")  \n",
    "# htf = HashingTF(inputCol=\"words\", outputCol=\"tf\", numFeatures=200)  \n",
    "\n",
    "# # process review data\n",
    "# w2v = Word2Vec(inputCol=\"review\", outputCol=\"w2v\")  \n",
    "\n",
    "# # process rating data\n",
    "# ohe = OneHotEncoder(inputCol=\"rating\", outputCol=\"rc\")  \n",
    "\n",
    "# va = VectorAssembler(inputCols=[\"tf\", \"w2v\", \"rc\"], outputCol=\"features\")  \n",
    "# lr = LogisticRegression(maxIter=10, regParam=0.01)\n",
    "\n",
    "# # Build the pipeline\n",
    "# pipeline = Pipeline(stages=[tok, htf, w2v, ohe, va, lr])\n",
    "\n",
    "# # Fit the pipeline\n",
    "# model = pipeline.fit(train_df)\n",
    "\n",
    "# # Make a prediction\n",
    "# prediction = model.transform(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline  \n",
    "from pyspark.ml.feature import *  \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "# Configure pipeline stages\n",
    "\n",
    "#onehotencoder to pickup\n",
    "ohe_pu = OneHotEncoder(inputCol=\"Pickup_Community_Area\", outputCol=\"Pickup_Community_Area_vec\")\n",
    "#df4 = onehotencoder_pickup_vector.transform(df4)\n",
    "\n",
    "#onehotencoder to dropoff\n",
    "ohe_do = OneHotEncoder(inputCol=\"Dropoff_Community_Area\", outputCol=\"Dropoff_Community_Area_vec\")\n",
    "#df4 = onehotencoder_pickup_vector.transform(df4)\n",
    "\n",
    "# our colulms for lr\n",
    "predictor_col_for_lr = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec']\n",
    "\n",
    "lr_va = VectorAssembler(inputCols=predictor_col_for_lr, outputCol=\"features\") \n",
    "# transformed = assembler.transform(df4)\n",
    "# df5 = transformed\n",
    "\n",
    "lr_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "#what do we want to do if we are doing a parameter search? make the parameters as variables and just do a loop?\n",
    "lr = LogisticRegression(maxIter=10,\n",
    "                        regParam=0.1,\n",
    "                        elasticNetParam=0.3,\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"binarized_tip\")\n",
    "\n",
    "#split data\n",
    "train_inital, test = df6.randomSplit([0.8, 0.2], seed=2021)\n",
    "\n",
    "# Build the pipeline\n",
    "data_pipeline = Pipeline(stages=[ohe_pu, ohe_do, lr_va, lr_scaler, lr])\n",
    "\n",
    "# Fit the pipeline\n",
    "lr_model = lr_pipeline.fit(train_final)\n",
    "\n",
    "# Make a prediction\n",
    "lr_prediction = lr_model.transform(test)\n",
    "\n",
    "lr_pred_rdd= prediction.select('prediction').rdd.flatMap(lambda x: x)\n",
    "lr_label_rddt = prediction.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "\n",
    "lr_predictionAndLabels =  lr_pred_rddt.zip(lr_label_rdd)\n",
    "\n",
    "lr_metrics = MulticlassMetrics(lr_predictionAndLabels)\n",
    "\n",
    "lr_cm = lr_metrics.confusionMatrix().toArray()\n",
    "\n",
    "lr_acc = (lr_cm[0][0] + lr_cm[1][1])/(lr_cm[0][0] + lr_cm[1][1] + lr_cm[0][1] + lr_cm[1][0]) #should be a function\n",
    "\n",
    "print(lr_cm)\n",
    "print()\n",
    "print(lr_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # our model didn't work on the standard test train split.  Prof. Tashman recomended upscalling the help with the imbalanced dataset.\n",
    "# #from https://spark.apache.org/docs/2.1.0/ml-tuning.html#train-validation-split\n",
    "\n",
    "# train_inital, test = df6.randomSplit([0.8, 0.2], seed=2021)\n",
    "\n",
    "# train_inital.show(5)\n",
    "\n",
    "# test.cache()\n",
    "# test.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # oversampleing code sample\n",
    "# # https://stackoverflow.com/questions/53273133/how-to-perform-up-sampling-using-sample-functionpy-spark\n",
    "\n",
    "# df_a = train_inital.filter(train_inital['binarized_tip'] == 0)\n",
    "# df_b = train_inital.filter(train_inital['binarized_tip'] == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_count = df_a.count()\n",
    "# b_count = df_b.count() \n",
    "# print(a_count)\n",
    "# print(b_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio = a_count / b_count\n",
    "# print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_b_overampled = df_b.sample(withReplacement=True, fraction=ratio, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_final = df_a.unionAll(df_b_overampled)\n",
    "# train_final.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used the in the lr.  This cell can be deleted\n",
    "\n",
    "# https://medium.com/@nutanbhogendrasharma/role-of-onehotencoder-and-pipelines-in-pyspark-ml-feature-part-2-3275767e74f0\n",
    "# apparently the spark doc is wrong, we don't need fit, just transform.  Maybe thats a spark 3 thing?\n",
    "\n",
    "# from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "# #onehotencoder to pickup\n",
    "# onehotencoder_pickup_vector = OneHotEncoder(inputCol=\"Pickup_Community_Area\", outputCol=\"Pickup_Community_Area_vec\")\n",
    "# df4 = onehotencoder_pickup_vector.transform(df4)\n",
    "\n",
    "# #onehotencoder to dropoff\n",
    "# onehotencoder_dropoff_vector = OneHotEncoder(inputCol=\"Dropoff_Community_Area\", outputCol=\"Dropoff_Community_Area_vec\")\n",
    "# df4 = onehotencoder_dropoff_vector.transform(df4)\n",
    "\n",
    "# df4.show(20)c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+-------------------------+--------------------------+--------------------+\n",
      "|             Trip_ID|Trip_Start_Timestamp|Trip_Seconds|Trip_Miles|Pickup_Community_Area|Dropoff_Community_Area|Fare|Tip|Additional_Charges|Trip_Total|Shared_Trip_Authorized|Trips_Pooled|binarized_tip|Pickup_Community_Area_vec|Dropoff_Community_Area_vec|            features|\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+-------------------------+--------------------------+--------------------+\n",
      "|1d7fc864aa5f775df...|12/01/2019 12:15:...|       543.0|       3.1|                  7.0|                   8.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|          0.0|           (78,[7],[1.0])|            (78,[8],[1.0])|(162,[0,1,2,3,5,1...|\n",
      "|1dc1dd5e6d3fb5bf1...|12/01/2019 12:15:...|      1242.0|      19.5|                 32.0|                  28.0| 5.0|0.0|               0.0|         5|                  true|         3.0|          0.0|          (78,[32],[1.0])|           (78,[28],[1.0])|(162,[0,1,2,4,5,3...|\n",
      "|2cbdf4e75915f9538...|12/01/2019 12:15:...|      1035.0|       5.0|                 24.0|                   7.0|10.0|0.0|              2.55|     12.55|                 false|         1.0|          0.0|          (78,[24],[1.0])|            (78,[7],[1.0])|(162,[0,1,2,3,5,3...|\n",
      "|307ad0d42bc538fd7...|12/01/2019 12:15:...|       448.0|       3.4|                  8.0|                  22.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|          0.0|           (78,[8],[1.0])|           (78,[22],[1.0])|(162,[0,1,2,3,5,1...|\n",
      "|311b0496dad70cde4...|12/01/2019 12:15:...|       694.0|       4.2|                 31.0|                  24.0|10.0|0.0|              2.55|     12.55|                 false|         1.0|          0.0|          (78,[31],[1.0])|           (78,[24],[1.0])|(162,[0,1,2,3,5,3...|\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+-------------------------+--------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# can we do RF in DF?\n",
    "# from https://spark.apache.org/docs/latest/ml-classification-regression.html#random-forest-classifier\n",
    "\n",
    "#I don't think we need this setup, we can use the same one from lr now\n",
    "\n",
    "#lets start with the earlier datafram before any of the LR transforms\n",
    "df8 =  df5.cache() \n",
    "\n",
    "# we need to regroup the features\n",
    "# did this for lr.  skip\n",
    "\n",
    "# RF doesn't like the community areas as they are too big.  Drop them for now\n",
    "# predictor_col_for_rf = ['Trip_Seconds',\n",
    "#                         'Trip_Miles',\n",
    "#                         'Pickup_Community_Area_vec',\n",
    "#                         'Dropoff_Community_Area_vec',\n",
    "#                         'Fare',\n",
    "#                         'Additional_Charges',\n",
    "#                         'Shared_Trip_Authorized',\n",
    "#                         'Trips_Pooled']\n",
    "\n",
    "\n",
    "# from pyspark.ml.linalg import DenseVector\n",
    "# from pyspark.ml.feature import VectorAssembler \n",
    "# from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "# assembler = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "# transformed = assembler.transform(df8)\n",
    "# df8 = transformed\n",
    "\n",
    "df8.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                       Type               Data/Info\n",
      "-----------------------------------------------------------\n",
      "ArrayType                      type               <class 'pyspark.sql.types.ArrayType'>\n",
      "Binarizer                      type               <class 'pyspark.ml.feature.Binarizer'>\n",
      "BinaryType                     type               <class 'pyspark.sql.types.BinaryType'>\n",
      "BooleanType                    type               <class 'pyspark.sql.types.BooleanType'>\n",
      "ByteType                       type               <class 'pyspark.sql.types.ByteType'>\n",
      "DataType                       type               <class 'pyspark.sql.types.DataType'>\n",
      "DateType                       type               <class 'pyspark.sql.types.DateType'>\n",
      "DecimalType                    type               <class 'pyspark.sql.types.DecimalType'>\n",
      "DenseVector                    type               <class 'pyspark.ml.linalg.DenseVector'>\n",
      "DoubleType                     type               <class 'pyspark.sql.types.DoubleType'>\n",
      "F                              module             <module 'pyspark.sql.func<...>yspark/sql/functions.py'>\n",
      "FloatType                      type               <class 'pyspark.sql.types.FloatType'>\n",
      "IntegerType                    type               <class 'pyspark.sql.types.IntegerType'>\n",
      "LongType                       type               <class 'pyspark.sql.types.LongType'>\n",
      "MapType                        type               <class 'pyspark.sql.types.MapType'>\n",
      "MulticlassMetrics              type               <class 'pyspark.mllib.eva<...>ation.MulticlassMetrics'>\n",
      "NullType                       type               <class 'pyspark.sql.types.NullType'>\n",
      "OneHotEncoder                  type               <class 'pyspark.ml.feature.OneHotEncoder'>\n",
      "ShortType                      type               <class 'pyspark.sql.types.ShortType'>\n",
      "SparkSession                   type               <class 'pyspark.sql.session.SparkSession'>\n",
      "StringType                     type               <class 'pyspark.sql.types.StringType'>\n",
      "StructField                    type               <class 'pyspark.sql.types.StructField'>\n",
      "StructType                     type               <class 'pyspark.sql.types.StructType'>\n",
      "TimestampType                  type               <class 'pyspark.sql.types.TimestampType'>\n",
      "VectorAssembler                type               <class 'pyspark.ml.feature.VectorAssembler'>\n",
      "Vectors                        type               <class 'pyspark.mllib.linalg.Vectors'>\n",
      "assembler                      VectorAssembler    VectorAssembler_7a1fd45c798e\n",
      "binarizedTip                   DataFrame          DataFrame[Trip_ID: string<...>e, binarized_tip: double]\n",
      "binarizer                      Binarizer          Binarizer_cb88c4cb325e\n",
      "customSchema                   StructType         StructType(List(StructFie<...>cation,StringType,true)))\n",
      "df4                            DataFrame          DataFrame[Trip_ID: string<...>mmunity_Area_vec: vector]\n",
      "df5                            DataFrame          DataFrame[Trip_ID: string<...>vector, features: vector]\n",
      "df8                            DataFrame          DataFrame[Trip_ID: string<...>vector, features: vector]\n",
      "onehotencoder_dropoff_vector   OneHotEncoder      OneHotEncoder_2e67244009d2\n",
      "onehotencoder_pickup_vector    OneHotEncoder      OneHotEncoder_3b2a5c6756e4\n",
      "os                             module             <module 'os' from '/opt/c<...>nda/lib/python3.7/os.py'>\n",
      "predictor_col_for_lr           list               n=8\n",
      "rdd                            PipelinedRDD       PythonRDD[157] at RDD at PythonRDD.scala:53\n",
      "sc                             SparkContext       <SparkContext master=loca<...>appName=mllib_classifier>\n",
      "spark                          SparkSession       <pyspark.sql.session.Spar<...>object at 0x7f7e584c9390>\n",
      "transformed                    DataFrame          DataFrame[Trip_ID: string<...>vector, features: vector]\n",
      "typ                            module             <module 'pyspark.sql.type<...>on/pyspark/sql/types.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(df4)\n",
    "del(df5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "\n",
    "labelIndexer = StringIndexer(inputCol=\"binarized_tip\", outputCol=\"indexedLabel\").fit(df8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.feature.StringIndexerModel"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(labelIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "\n",
    "# Set max to 78 as we have 77 CA plus out of city.  Doesn't work, max is 32.  This may move us to OHE.  Code can't handle CAs as it is.  Need to try something else. \n",
    "# short term to get code to run, drop pickup, droppoff areas.\n",
    "\n",
    "# https://stackoverflow.com/questions/44959122/how-to-handle-categorical-features-for-decision-tree-random-forest-in-spark-ml\n",
    "# https://spark.apache.org/docs/latest/ml-features.html#onehotencoder\n",
    "# https://docs.databricks.com/_static/notebooks/binary-classification.html\n",
    "\n",
    "featureIndexer = VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=10).fit(df8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.feature.VectorIndexerModel"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(featureIndexer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (20% held out for testing)\n",
    "# it won't be the same splits at this point, we'll have to fix that later once we have everything working\n",
    "\n",
    "(trainingData_inital, testData) = df8.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampleing code sample\n",
    "# https://stackoverflow.com/questions/53273133/how-to-perform-up-sampling-using-sample-functionpy-spark\n",
    "\n",
    "df_a = trainingData_inital.filter(trainingData_inital['binarized_tip'] == 0)\n",
    "df_b = trainingData_inital.filter(trainingData_inital['binarized_tip'] == 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162981\n",
      "32930\n"
     ]
    }
   ],
   "source": [
    "a_count = df_a.count()\n",
    "b_count = df_b.count() \n",
    "print(a_count)\n",
    "print(b_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.9493167324628\n"
     ]
    }
   ],
   "source": [
    "ratio = a_count / b_count\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_b_overampled = df_b.sample(withReplacement=True, fraction=ratio, seed=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingData_final = df_a.unionAll(df_b_overampled).cache()\n",
    "\n",
    "testData = testData.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+-------------------------+--------------------------+--------------------+\n",
      "|             Trip_ID|Trip_Start_Timestamp|Trip_Seconds|Trip_Miles|Pickup_Community_Area|Dropoff_Community_Area|Fare|Tip|Additional_Charges|Trip_Total|Shared_Trip_Authorized|Trips_Pooled|binarized_tip|Pickup_Community_Area_vec|Dropoff_Community_Area_vec|            features|\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+-------------------------+--------------------------+--------------------+\n",
      "|000e879212e519b17...|12/02/2019 01:45:...|      2376.0|      14.6|                 24.0|                  56.0|25.0|0.0|              7.55|     32.55|                 false|         1.0|          0.0|          (78,[24],[1.0])|           (78,[56],[1.0])|(162,[0,1,2,3,5,3...|\n",
      "|00340cc3ffecd7a5d...|12/01/2019 10:45:...|      3252.0|      39.9|                 31.0|                  78.0|37.5|0.0|               0.0|      37.5|                  true|         1.0|          0.0|          (78,[31],[1.0])|                (78,[],[])|(162,[0,1,2,4,5,3...|\n",
      "|003ca5c025410fcc9...|12/01/2019 11:15:...|       739.0|       4.7|                  6.0|                  32.0|10.0|0.0|              2.55|     12.55|                 false|         1.0|          0.0|           (78,[6],[1.0])|           (78,[32],[1.0])|(162,[0,1,2,3,5,1...|\n",
      "|006131af958b8a181...|12/01/2019 05:00:...|       677.0|       4.0|                  6.0|                   7.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|          0.0|           (78,[6],[1.0])|            (78,[7],[1.0])|(162,[0,1,2,3,5,1...|\n",
      "|008c500db458d3746...|12/01/2019 02:15:...|       101.0|       0.3|                 58.0|                  58.0| 2.5|0.0|              2.55|      5.05|                 false|         1.0|          0.0|          (78,[58],[1.0])|           (78,[58],[1.0])|(162,[0,1,2,3,5,6...|\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-------------+-------------------------+--------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainingData_final.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162981\n",
      "163175\n"
     ]
    }
   ],
   "source": [
    "df_af = trainingData_final.filter(trainingData_final['binarized_tip'] == 0)\n",
    "df_bf = trainingData_final.filter(trainingData_final['binarized_tip'] == 1)\n",
    "a_count = df_af.count()\n",
    "b_count = df_bf.count() \n",
    "print(a_count)\n",
    "print(b_count)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training size has increased.  This is to be expected in upscaling.\n",
    "\n",
    "Good reference: https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40583\n",
      "8268\n"
     ]
    }
   ],
   "source": [
    "#just as a reminder what was the truth in our test data?\n",
    "\n",
    "dft_a = testData.filter(testData['binarized_tip'] == 0)\n",
    "dft_b = testData.filter(testData['binarized_tip'] == 1)\n",
    "count_test_a = dft_a.count()\n",
    "count_test_b = dft_b.count()\n",
    "print(count_test_a)\n",
    "print(count_test_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RandomForest model.\n",
    "# these are all defalt settings\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert indexed labels back to original labels.\n",
    "# more pipeline steps\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions.\n",
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+--------------------+\n",
      "|predictedLabel|binarized_tip|            features|\n",
      "+--------------+-------------+--------------------+\n",
      "|           0.0|          0.0|(162,[0,1,2,3,5,3...|\n",
      "|           0.0|          0.0|(162,[0,1,2,3,5,1...|\n",
      "|           0.0|          0.0|(162,[0,1,2,4,5,2...|\n",
      "|           0.0|          0.0|(162,[0,1,2,3,5,1...|\n",
      "|           1.0|          0.0|(162,[0,1,2,3,5,3...|\n",
      "+--------------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select example rows to display.\n",
    "predictions.select(\"predictedLabel\", \"binarized_tip\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.289308\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_a094af962c62) with 10 trees\n"
     ]
    }
   ],
   "source": [
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_rdd= predictions.select('prediction').rdd.flatMap(lambda x: x)\n",
    "rf_label_rdd = predictions.select('binarized_tip').rdd.flatMap(lambda x: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_predictionAndLabels =  rf_pred_rdd.zip(rf_label_rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_metrics = MulticlassMetrics(rf_predictionAndLabels)\n",
    "rf_cm = rf_metrics.confusionMatrix().toArray()\n",
    "rf_acc = (rf_cm[0][0] + rf_cm[1][1])/(rf_cm[0][0] + rf_cm[1][1] + rf_cm[0][1] + rf_cm[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[31722.  8861.]\n",
      " [ 5272.  2996.]]\n",
      "\n",
      "0.7106916951546539\n"
     ]
    }
   ],
   "source": [
    "print(rf_cm)\n",
    "print()\n",
    "print(rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.28501\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_8549690ea16a) with 100 trees\n",
      "[[31911.  8672.]\n",
      " [ 5251.  3017.]]\n",
      "\n",
      "0.7149904812593396\n"
     ]
    }
   ],
   "source": [
    "#what is we play with our trees now 100\n",
    "\n",
    "# Train a RandomForest model.\n",
    "# these are all defalt settings\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=100)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "# more pipeline steps\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData_final)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only\n",
    "\n",
    "rf_pred_rdd= predictions.select('prediction').rdd.flatMap(lambda x: x)\n",
    "rf_label_rdd = predictions.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "rf_predictionAndLabels =  rf_pred_rdd.zip(rf_label_rdd)\n",
    "\n",
    "rf_metrics = MulticlassMetrics(rf_predictionAndLabels)\n",
    "rf_cm = rf_metrics.confusionMatrix().toArray()\n",
    "rf_acc = (rf_cm[0][0] + rf_cm[1][1])/(rf_cm[0][0] + rf_cm[1][1] + rf_cm[0][1] + rf_cm[1][0])\n",
    "\n",
    "print(rf_cm)\n",
    "print()\n",
    "print(rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.363084\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_57c53127580d) with 10 trees\n",
      "[[26758. 13825.]\n",
      " [ 3912.  4356.]]\n",
      "\n",
      "0.6369163374342388\n"
     ]
    }
   ],
   "source": [
    "#what is we play with our trees now 10, max depth to 10\n",
    "\n",
    "# Train a RandomForest model.\n",
    "# these are all defalt settings\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10, maxDepth=10)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "# more pipeline steps\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData_final)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only\n",
    "\n",
    "rf_pred_rdd= predictions.select('prediction').rdd.flatMap(lambda x: x)\n",
    "rf_label_rdd = predictions.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "rf_predictionAndLabels =  rf_pred_rdd.zip(rf_label_rdd)\n",
    "\n",
    "rf_metrics = MulticlassMetrics(rf_predictionAndLabels)\n",
    "rf_cm = rf_metrics.confusionMatrix().toArray()\n",
    "rf_acc = (rf_cm[0][0] + rf_cm[1][1])/(rf_cm[0][0] + rf_cm[1][1] + rf_cm[0][1] + rf_cm[1][0])\n",
    "\n",
    "print(rf_cm)\n",
    "print()\n",
    "print(rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.386809\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_1c374aa63e6c) with 10 trees\n",
      "[[25118. 15465.]\n",
      " [ 3431.  4837.]]\n",
      "\n",
      "0.6131911322183783\n"
     ]
    }
   ],
   "source": [
    "#what is we play with our trees now 10, max depth to 20\n",
    "\n",
    "# Train a RandomForest model.\n",
    "# these are all defalt settings\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=10, maxDepth=20)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "# more pipeline steps\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData_final)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only\n",
    "\n",
    "rf_pred_rdd= predictions.select('prediction').rdd.flatMap(lambda x: x)\n",
    "rf_label_rdd = predictions.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "rf_predictionAndLabels =  rf_pred_rdd.zip(rf_label_rdd)\n",
    "\n",
    "rf_metrics = MulticlassMetrics(rf_predictionAndLabels)\n",
    "rf_cm = rf_metrics.confusionMatrix().toArray()\n",
    "rf_acc = (rf_cm[0][0] + rf_cm[1][1])/(rf_cm[0][0] + rf_cm[1][1] + rf_cm[0][1] + rf_cm[1][0])\n",
    "\n",
    "print(rf_cm)\n",
    "print()\n",
    "print(rf_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "deeper trees seems to be worse, and slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.309635\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_eec0ebddb69e) with 1000 trees\n",
      "[[30268. 10315.]\n",
      " [ 4811.  3457.]]\n",
      "\n",
      "0.6903645780024974\n"
     ]
    }
   ],
   "source": [
    "#what is we play with our trees now 1000\n",
    "\n",
    "# Train a RandomForest model.\n",
    "# these are all defalt settings\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=1000)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "# more pipeline steps\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData_final)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only\n",
    "\n",
    "rf_pred_rdd= predictions.select('prediction').rdd.flatMap(lambda x: x)\n",
    "rf_label_rdd = predictions.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "rf_predictionAndLabels =  rf_pred_rdd.zip(rf_label_rdd)\n",
    "\n",
    "rf_metrics = MulticlassMetrics(rf_predictionAndLabels)\n",
    "rf_cm = rf_metrics.confusionMatrix().toArray()\n",
    "rf_acc = (rf_cm[0][0] + rf_cm[1][1])/(rf_cm[0][0] + rf_cm[1][1] + rf_cm[0][1] + rf_cm[1][0])\n",
    "\n",
    "print(rf_cm)\n",
    "print()\n",
    "print(rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.324599\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_811859f57f5a) with 500 trees\n",
      "[[29337. 11246.]\n",
      " [ 4611.  3657.]]\n",
      "\n",
      "0.6754007082761868\n"
     ]
    }
   ],
   "source": [
    "#what is we play with our trees now 500\n",
    "\n",
    "# Train a RandomForest model.\n",
    "# these are all defalt settings\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=500)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "# more pipeline steps\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData_final)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only\n",
    "\n",
    "rf_pred_rdd= predictions.select('prediction').rdd.flatMap(lambda x: x)\n",
    "rf_label_rdd = predictions.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "rf_predictionAndLabels =  rf_pred_rdd.zip(rf_label_rdd)\n",
    "\n",
    "rf_metrics = MulticlassMetrics(rf_predictionAndLabels)\n",
    "rf_cm = rf_metrics.confusionMatrix().toArray()\n",
    "rf_acc = (rf_cm[0][0] + rf_cm[1][1])/(rf_cm[0][0] + rf_cm[1][1] + rf_cm[0][1] + rf_cm[1][0])\n",
    "\n",
    "print(rf_cm)\n",
    "print()\n",
    "print(rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error = 0.281939\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_f1194e034f89) with 50 trees\n",
      "[[32152.  8431.]\n",
      " [ 5342.  2926.]]\n",
      "\n",
      "0.7180610427626866\n"
     ]
    }
   ],
   "source": [
    "#what is we play with our trees now 50\n",
    "\n",
    "# Train a RandomForest model.\n",
    "# these are all defalt settings\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", numTrees=50)\n",
    "\n",
    "# Convert indexed labels back to original labels.\n",
    "# more pipeline steps\n",
    "labelConverter = IndexToString(inputCol=\"prediction\", outputCol=\"predictedLabel\",\n",
    "                               labels=labelIndexer.labels)\n",
    "\n",
    "# Chain indexers and forest in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, rf, labelConverter])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData_final)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = model.stages[2]\n",
    "print(rfModel)  # summary only\n",
    "\n",
    "rf_pred_rdd= predictions.select('prediction').rdd.flatMap(lambda x: x)\n",
    "rf_label_rdd = predictions.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "rf_predictionAndLabels =  rf_pred_rdd.zip(rf_label_rdd)\n",
    "\n",
    "rf_metrics = MulticlassMetrics(rf_predictionAndLabels)\n",
    "rf_cm = rf_metrics.confusionMatrix().toArray()\n",
    "rf_acc = (rf_cm[0][0] + rf_cm[1][1])/(rf_cm[0][0] + rf_cm[1][1] + rf_cm[0][1] + rf_cm[1][0])\n",
    "\n",
    "print(rf_cm)\n",
    "print()\n",
    "print(rf_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try a GBT \n",
    "\n",
    "# https://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       0.0|         0.0|(162,[0,1,2,3,5,3...|\n",
      "|       1.0|         0.0|(162,[0,1,2,3,5,1...|\n",
      "|       0.0|         0.0|(162,[0,1,2,4,5,2...|\n",
      "|       1.0|         0.0|(162,[0,1,2,3,5,1...|\n",
      "|       1.0|         0.0|(162,[0,1,2,3,5,3...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.372091\n",
      "GBTClassificationModel (uid=GBTClassifier_86f44db64d7b) with 10 trees\n",
      "[[26294. 14289.]\n",
      " [ 3888.  4380.]]\n",
      "\n",
      "0.6279093570244212\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "# data = spark.read.format(\"libsvm\").load(\"data/mllib/sample_libsvm_data.txt\")\n",
    "# use same data as rf\n",
    "\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "#labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(data)\n",
    "# use same data as rf\n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "# featureIndexer =\\\n",
    "#     VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4).fit(data)\n",
    "\n",
    "# Split the data into training and test sets (30% held out for testing)\n",
    "# (trainingData, testData) = data.randomSplit([0.7, 0.3])\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10)\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData_final)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "gbtModel = model.stages[2]\n",
    "print(gbtModel)  # summary only\n",
    "\n",
    "gbt_pred_rdd= predictions.select('prediction').rdd.flatMap(lambda x: x)\n",
    "gbt_label_rdd = predictions.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "gbt_predictionAndLabels =  gbt_pred_rdd.zip(gbt_label_rdd)\n",
    "\n",
    "gbt_metrics = MulticlassMetrics(gbt_predictionAndLabels)\n",
    "gbt_cm = gbt_metrics.confusionMatrix().toArray()\n",
    "gbt_acc = (gbt_cm[0][0] + gbt_cm[1][1])/(gbt_cm[0][0] + gbt_cm[1][1] + gbt_cm[0][1] + gbt_cm[1][0])\n",
    "\n",
    "print(gbt_cm)\n",
    "print()\n",
    "print(gbt_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       0.0|         0.0|(162,[0,1,2,3,5,3...|\n",
      "|       1.0|         0.0|(162,[0,1,2,3,5,1...|\n",
      "|       0.0|         0.0|(162,[0,1,2,4,5,2...|\n",
      "|       1.0|         0.0|(162,[0,1,2,3,5,1...|\n",
      "|       1.0|         0.0|(162,[0,1,2,3,5,3...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.408262\n",
      "GBTClassificationModel (uid=GBTClassifier_a46ec092a825) with 50 trees\n",
      "[[23692. 16891.]\n",
      " [ 3053.  5215.]]\n",
      "\n",
      "0.5917381425149946\n"
     ]
    }
   ],
   "source": [
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=50)\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData_final)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "gbtModel = model.stages[2]\n",
    "print(gbtModel)  # summary only\n",
    "\n",
    "gbt_pred_rdd= predictions.select('prediction').rdd.flatMap(lambda x: x)\n",
    "gbt_label_rdd = predictions.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "gbt_predictionAndLabels =  gbt_pred_rdd.zip(gbt_label_rdd)\n",
    "\n",
    "gbt_metrics = MulticlassMetrics(gbt_predictionAndLabels)\n",
    "gbt_cm = gbt_metrics.confusionMatrix().toArray()\n",
    "gbt_acc = (gbt_cm[0][0] + gbt_cm[1][1])/(gbt_cm[0][0] + gbt_cm[1][1] + gbt_cm[0][1] + gbt_cm[1][0])\n",
    "\n",
    "print(gbt_cm)\n",
    "print()\n",
    "print(gbt_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------------+\n",
      "|prediction|indexedLabel|            features|\n",
      "+----------+------------+--------------------+\n",
      "|       0.0|         0.0|(162,[0,1,2,3,5,3...|\n",
      "|       1.0|         0.0|(162,[0,1,2,3,5,1...|\n",
      "|       0.0|         0.0|(162,[0,1,2,4,5,2...|\n",
      "|       1.0|         0.0|(162,[0,1,2,3,5,1...|\n",
      "|       1.0|         0.0|(162,[0,1,2,3,5,3...|\n",
      "+----------+------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.376267\n",
      "GBTClassificationModel (uid=GBTClassifier_e2dd117300c1) with 10 trees\n",
      "[[25879. 14704.]\n",
      " [ 3677.  4591.]]\n",
      "\n",
      "0.6237333933798694\n"
     ]
    }
   ],
   "source": [
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=10, maxDepth=10)\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "pipeline = Pipeline(stages=[labelIndexer, featureIndexer, gbt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "model = pipeline.fit(trainingData_final)\n",
    "\n",
    "# Make predictions.\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Select example rows to display.\n",
    "predictions.select(\"prediction\", \"indexedLabel\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "gbtModel = model.stages[2]\n",
    "print(gbtModel)  # summary only\n",
    "\n",
    "gbt_pred_rdd= predictions.select('prediction').rdd.flatMap(lambda x: x)\n",
    "gbt_label_rdd = predictions.select('binarized_tip').rdd.flatMap(lambda x: x)\n",
    "gbt_predictionAndLabels =  gbt_pred_rdd.zip(gbt_label_rdd)\n",
    "\n",
    "gbt_metrics = MulticlassMetrics(gbt_predictionAndLabels)\n",
    "gbt_cm = gbt_metrics.confusionMatrix().toArray()\n",
    "gbt_acc = (gbt_cm[0][0] + gbt_cm[1][1])/(gbt_cm[0][0] + gbt_cm[1][1] + gbt_cm[0][1] + gbt_cm[1][0])\n",
    "\n",
    "print(gbt_cm)\n",
    "print()\n",
    "print(gbt_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stuff coppied for other Tahsman Notebooks that might be useful.  Not developed yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each field, compute missing percentage\n",
    "# from preprcessing example notebook\n",
    "\n",
    "df.agg(*[\n",
    "    (1 - F.count(c) / F.count('*')).alias(c + '_miss')\n",
    "    for c in df.columns\n",
    "]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bayes example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "# Load the data file. Note this data is in sparse format.\n",
    "data = MLUtils.loadLibSVMFile(sc, 'sample_libsvm_data.txt')\n",
    "data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data approximately into training (60%) and test (40%)\n",
    "training, test = data.randomSplit([0.6, 0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a naive Bayes model.\n",
    "model = NaiveBayes.train(training, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction and test accuracy.\n",
    "labelsAndPreds = test.map(lambda p: (p.label, model.predict(p.features)))\n",
    "accuracy = 1.0 * labelsAndPreds.filter(lambda pl: pl[0] == pl[1]).count() / test.count()\n",
    "print('model accuracy {}'.format(accuracy))\n",
    "\n",
    "# Source: https://spark.apache.org/docs/latest/mllib-naive-bayes.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision tree examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import DecisionTree\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "# Load and parse the data file\n",
    "data = MLUtils.loadLibSVMFile(sc, 'sample_libsvm_data.txt')\n",
    "data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a DecisionTree model.\n",
    "#  Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "model = DecisionTree.trainClassifier(trainingData, numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     impurity='gini', maxDepth=5, maxBins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test instances and compute test error\n",
    "predictions = model.predict(testData.map(lambda x: x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(\n",
    "    lambda lp: lp[0] != lp[1]).count() / float(testData.count())\n",
    "print('Test Error = ' + str(testErr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my personal favorite... trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tree-Based Ensemble Methods**\n",
    "\n",
    "*Ensembles* combine multiple models together to produce a new model.  \n",
    "They may consist of models of the same type (e.g., all decision trees) or mixed type (e.g., decision tree + neural net + svm)  \n",
    "\n",
    "One of the fundamental results in machine learning is that multiple weak classifiers can be combined to produce a strong classifier.  \n",
    "\n",
    "Ensembles are useful in reducing overfitting, since predictions are based on several different trees  \n",
    "\n",
    "The two most popular tree-based ensemble methods are *Random Forests* and *Boosted Trees* (e.g. *Gradient-Boosted Trees*)  \n",
    "\n",
    "They are popular because they are often very competitive  \n",
    "\n",
    "The nice properties of decision trees carry over to ensembles of trees  \n",
    "\n",
    "This combining step can proceed using different methods, including:  \n",
    "\n",
    "- voting (for classification)\n",
    "- averaging (for regression) \n",
    "- running model predictions through another model (classification and regression)\n",
    "\n",
    "There are downsides to ensembles:  \n",
    "\n",
    "- Multiple models need to be trained, loaded, and maintained  \n",
    "- Model explanation is harder: no p-values like regression, several trees are feeding overall decision.  \n",
    "There are methods to provide feature importance information, such as partial dependence plots.\n",
    "\n",
    "**Random Forest**  \n",
    "Ensembles of decision trees  \n",
    "\n",
    "RFs inject two sources of randomness into modeling:  \n",
    "\n",
    "1. At each step, randomly select $p$ features out of $n$ total features for possible inclusion (random subspace method)\n",
    "2. Sample the original training set with replacement, up to the size of the original training set (bootstrapping of the training set)\n",
    "\n",
    "The number of features to randomly select $p$ is a parameter  \n",
    "The number of bootstrapped trees to grow $N$ is a parameter  \n",
    "\n",
    "Since the trees are grown independently, the training and prediction tasks are embarrassingly parallel and can be assigned to multiple workers.\n",
    "\n",
    "Classification prediction done by majority vote across trees\n",
    "\n",
    "**Random Forest Implementation**\n",
    "\n",
    "`from pyspark.mllib.tree import RandomForest`  \n",
    "\n",
    "Two most important parameters (which should be tuned using $k$-fold cross validation):  \n",
    "\n",
    "- `numTrees`: Number of trees in forest\n",
    "More trees will increase accuracy but also training time  \n",
    "\n",
    "- `maxDepth`: Maximum depth of each tree in forest\n",
    "Increasing depth can increase power of model, but will take longer to train and can overfit  \n",
    "\n",
    "Other important parameters:\n",
    "\n",
    "- `subsamplingRate`: fraction of size of original training set (default=1.0 recommended)\n",
    "\n",
    "- `featureSubsetStrategy`: specified as fraction or function of total number of features\n",
    "\n",
    "**Random Forest Example: load data/train model/predict**  \n",
    "NOTE: Very similar to Decision Tree code above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "data = MLUtils.loadLibSVMFile(sc, 'sample_libsvm_data.txt')\n",
    "data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test sets (30% held out for testing)\n",
    "(trainingData, testData) = data.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RandomForest model.\n",
    "#  Empty categoricalFeaturesInfo indicates all features are continuous.\n",
    "#  Setting featureSubsetStrategy=\"auto\" lets the algorithm choose.\n",
    "model = RandomForest.trainClassifier(trainingData, numClasses=2, categoricalFeaturesInfo={},\n",
    "                                     numTrees=1000, featureSubsetStrategy=\"auto\",\n",
    "                                     impurity='gini', maxDepth=5, maxBins=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model on test instances and compute test error\n",
    "predictions = model.predict(testData.map(lambda x: x.features))\n",
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)\n",
    "testErr = labelsAndPredictions.filter(\n",
    "    lambda lp: lp[0] != lp[1]).count() / float(testData.count())\n",
    "print('Test Error = ' + str(testErr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gradient-Boosted Trees**  \n",
    "\n",
    "GBTs work by building a sequence of trees and combining their predictions at each iteration.  The trees constructed are generally *stumps* which use a single decision split.  A stump is an example of a weak learner.\n",
    "\n",
    "This is different from random forests, where each tree independently gives predictions on each training instance.\n",
    "\n",
    "\n",
    "\n",
    "A loss is specified and an optimization problem is solved whereby the objective is to minimize the loss of the model by adding weak learners using a gradient-descent-like procedure.\n",
    "\n",
    "The procedure follows a stage-wise additive model, meaning that one new weak learner is\n",
    "added at a time and existing weak learners are left unchanged.\n",
    "For the original work, see:\n",
    "\n",
    "*Friedman, Jerome H. \"Greedy function approximation: a gradient boosting machine.\" Annals of Statistics (2001): 1189–1232.*\n",
    "\n",
    "\n",
    "**Gradient-Boosted Trees Implementation**  \n",
    "\n",
    "Since the trees are built in a sequential fashion, the algorithm can not be run in parallel.  \n",
    "However, shallow trees (e.g., stumps) can be used effectively; this saves time versus random forests, which use deeper trees.\n",
    "\n",
    "The loss function in classification problems is the log loss, equal to twice the binomial negative log likelihood.\n",
    "\n",
    "Important parameters:\n",
    "- `numIterations`:  equal to the number of trees in the ensemble.  More trees means longer runtime but also better performance up to a point.\n",
    "- `learningRate`:  how quickly the model adapts on each iteration. A smaller value may help the algo have better performance, but at the cost of additional runtime. The documentation recommends NOT tuning this param.\n",
    "\n",
    "The method `runWithValidation` can help mitigate overfitting.  It takes a training RDD and a validation RDD.\n",
    "\n",
    "The training is stopped when the improvement in the validation error is not more than a certain tolerance (supplied by the `validationTol` argument in `BoostingStrategy`).\n",
    "\n",
    "**GBT Example: load data/train model/predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
