{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of DS5559 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Team Left Twix Members\n",
    "\n",
    "* Alice Wright - aew7j\n",
    "* Edward Thompson - ejt8b\n",
    "* Michael Davies -  mld9s\n",
    "* Sam Parsons - sp8hp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In STAT 6021 members of our cohort looked at Transportation Network Company data sets to see if there was a potential relationship between tipping and other indicators, specifically with “transportation network providers” i.e. rideshares such as Uber, Lyft, etc.  At that point in our Data Science journey we did not have the skills or equipment to investigate this question in depth.  \n",
    "\n",
    "Utilizing machine learning skills from SYS 6018 and applying Spark to this dataset we hope to come up with a more robust set of answers and potentially a better predictor of tipping. With other classification algorithms such as random forest and the heavy-weight data processing of Spark, will we be able to create a more robust predictive model?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Potential Questions from the TNC Data:\n",
    "\n",
    "* Can it be predicted what fares are most likely to tip the driver?\n",
    "* Is there a relationship between time of the fare and tipping? (workday stat, bar close, weekday, weekend, etc)\n",
    "* Is there a relationship between start or end location of the ride and tipping? (downtown pickup, north shore, airport, etc)\n",
    "* Is there a relationship between length or cost of ride and tipping? (do longer rides result in tips)\n",
    "* Using this data would we be able to make recommendations to drivers to maximize likelihood of receiving a tip?\n",
    "* Is the likelihood of tipping changing over time?  Are more rides being tipped?\n",
    "* Are there re-identification abilities in this dataset? For instance, can we find records for a person who reliably takes a rideshare to/from work every day thereby linking a home address to a work address?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, joining in additional datasets may yield answers to questions about external factors such as:\n",
    "* How did news reporting/social media on rideshare companies correlate with tipping?\n",
    "* What relationship(s) does trip demand have with the stocks of these companies?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source:\n",
    "The best data source for this appears to be from the City of Chicago, as it is large (169M records and 21 columns), relatively clean, anonymized, and accessible via API.\n",
    "\n",
    "City of Chicago:\n",
    "https://data.cityofchicago.org/Transportation/Transportation-Network-Providers-Trips/m6dm-c72p\n",
    "\n",
    "So far we have only pulled the data down via a CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code Rubric\n",
    "\n",
    "* Data Import and PreProcessing | 2 pts\n",
    "\n",
    "* Data splitting/sampling | 1 pt\n",
    "\n",
    "* EDA (min two graphs) | 2 pts\n",
    "\n",
    "* Model construction (min 3 models) | 3 pts\n",
    "\n",
    "* Model evaluation | 2 pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import context manager: SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# import data types\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, BooleanType\n",
    "import pyspark.sql.types as typ\n",
    "import pyspark.sql.functions as F\n",
    "import os\n",
    "\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"mllib_classifier\") \\\n",
    "        .config(\"spark.executor.memory\", '21g') \\\n",
    "        .config('spark.executor.cores', '2') \\\n",
    "        .config('spark.executor.instances', '3') \\\n",
    "        .config(\"spark.driver.memory\",'1g') \\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "# import data manipulation methods\n",
    "from pyspark.ml.feature import Binarizer\n",
    "from pyspark.ml import Pipeline  \n",
    "from pyspark.ml.feature import *  \n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "\n",
    "from pyspark.ml.linalg import DenseVector\n",
    "from pyspark.ml.feature import VectorAssembler \n",
    "from pyspark.mllib.linalg import Vectors\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "import time\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                            Type            Data/Info\n",
      "-------------------------------------------------------------\n",
      "ArrayType                           type            <class 'pyspark.sql.types.ArrayType'>\n",
      "Binarizer                           type            <class 'pyspark.ml.feature.Binarizer'>\n",
      "BinaryClassificationEvaluator       type            <class 'pyspark.ml.evalua<...>ClassificationEvaluator'>\n",
      "BinaryClassificationMetrics         type            <class 'pyspark.mllib.eva<...>ryClassificationMetrics'>\n",
      "BinaryType                          type            <class 'pyspark.sql.types.BinaryType'>\n",
      "BooleanType                         type            <class 'pyspark.sql.types.BooleanType'>\n",
      "BucketedRandomProjectionLSH         type            <class 'pyspark.ml.featur<...>etedRandomProjectionLSH'>\n",
      "BucketedRandomProjectionLSHModel    type            <class 'pyspark.ml.featur<...>andomProjectionLSHModel'>\n",
      "Bucketizer                          type            <class 'pyspark.ml.feature.Bucketizer'>\n",
      "ByteType                            type            <class 'pyspark.sql.types.ByteType'>\n",
      "ChiSqSelector                       type            <class 'pyspark.ml.feature.ChiSqSelector'>\n",
      "ChiSqSelectorModel                  type            <class 'pyspark.ml.feature.ChiSqSelectorModel'>\n",
      "CountVectorizer                     type            <class 'pyspark.ml.feature.CountVectorizer'>\n",
      "CountVectorizerModel                type            <class 'pyspark.ml.feature.CountVectorizerModel'>\n",
      "CrossValidator                      type            <class 'pyspark.ml.tuning.CrossValidator'>\n",
      "DCT                                 type            <class 'pyspark.ml.feature.DCT'>\n",
      "DataType                            type            <class 'pyspark.sql.types.DataType'>\n",
      "DateType                            type            <class 'pyspark.sql.types.DateType'>\n",
      "DecimalType                         type            <class 'pyspark.sql.types.DecimalType'>\n",
      "DenseVector                         type            <class 'pyspark.ml.linalg.DenseVector'>\n",
      "DoubleType                          type            <class 'pyspark.sql.types.DoubleType'>\n",
      "ElementwiseProduct                  type            <class 'pyspark.ml.feature.ElementwiseProduct'>\n",
      "F                                   module          <module 'pyspark.sql.func<...>yspark/sql/functions.py'>\n",
      "FeatureHasher                       type            <class 'pyspark.ml.feature.FeatureHasher'>\n",
      "FloatType                           type            <class 'pyspark.sql.types.FloatType'>\n",
      "GBTClassifier                       type            <class 'pyspark.ml.classification.GBTClassifier'>\n",
      "HashingTF                           type            <class 'pyspark.ml.feature.HashingTF'>\n",
      "IDF                                 type            <class 'pyspark.ml.feature.IDF'>\n",
      "IDFModel                            type            <class 'pyspark.ml.feature.IDFModel'>\n",
      "Imputer                             type            <class 'pyspark.ml.feature.Imputer'>\n",
      "ImputerModel                        type            <class 'pyspark.ml.feature.ImputerModel'>\n",
      "IndexToString                       type            <class 'pyspark.ml.feature.IndexToString'>\n",
      "IntegerType                         type            <class 'pyspark.sql.types.IntegerType'>\n",
      "LogisticRegression                  type            <class 'pyspark.ml.classi<...>tion.LogisticRegression'>\n",
      "LongType                            type            <class 'pyspark.sql.types.LongType'>\n",
      "MapType                             type            <class 'pyspark.sql.types.MapType'>\n",
      "MaxAbsScaler                        type            <class 'pyspark.ml.feature.MaxAbsScaler'>\n",
      "MaxAbsScalerModel                   type            <class 'pyspark.ml.feature.MaxAbsScalerModel'>\n",
      "MinHashLSH                          type            <class 'pyspark.ml.feature.MinHashLSH'>\n",
      "MinHashLSHModel                     type            <class 'pyspark.ml.feature.MinHashLSHModel'>\n",
      "MinMaxScaler                        type            <class 'pyspark.ml.feature.MinMaxScaler'>\n",
      "MinMaxScalerModel                   type            <class 'pyspark.ml.feature.MinMaxScalerModel'>\n",
      "MulticlassClassificationEvaluator   type            <class 'pyspark.ml.evalua<...>ClassificationEvaluator'>\n",
      "MulticlassMetrics                   type            <class 'pyspark.mllib.eva<...>ation.MulticlassMetrics'>\n",
      "NGram                               type            <class 'pyspark.ml.feature.NGram'>\n",
      "Normalizer                          type            <class 'pyspark.ml.feature.Normalizer'>\n",
      "NullType                            type            <class 'pyspark.sql.types.NullType'>\n",
      "OneHotEncoder                       type            <class 'pyspark.ml.feature.OneHotEncoder'>\n",
      "OneHotEncoderEstimator              type            <class 'pyspark.ml.featur<...>.OneHotEncoderEstimator'>\n",
      "OneHotEncoderModel                  type            <class 'pyspark.ml.feature.OneHotEncoderModel'>\n",
      "PCA                                 type            <class 'pyspark.ml.feature.PCA'>\n",
      "PCAModel                            type            <class 'pyspark.ml.feature.PCAModel'>\n",
      "ParamGridBuilder                    type            <class 'pyspark.ml.tuning.ParamGridBuilder'>\n",
      "Pipeline                            type            <class 'pyspark.ml.pipeline.Pipeline'>\n",
      "PolynomialExpansion                 type            <class 'pyspark.ml.feature.PolynomialExpansion'>\n",
      "QuantileDiscretizer                 type            <class 'pyspark.ml.feature.QuantileDiscretizer'>\n",
      "RFormula                            type            <class 'pyspark.ml.feature.RFormula'>\n",
      "RFormulaModel                       type            <class 'pyspark.ml.feature.RFormulaModel'>\n",
      "RandomForestClassifier              type            <class 'pyspark.ml.classi<...>.RandomForestClassifier'>\n",
      "RegexTokenizer                      type            <class 'pyspark.ml.feature.RegexTokenizer'>\n",
      "SQLTransformer                      type            <class 'pyspark.ml.feature.SQLTransformer'>\n",
      "ShortType                           type            <class 'pyspark.sql.types.ShortType'>\n",
      "SparkSession                        type            <class 'pyspark.sql.session.SparkSession'>\n",
      "StandardScaler                      type            <class 'pyspark.ml.feature.StandardScaler'>\n",
      "StandardScalerModel                 type            <class 'pyspark.ml.feature.StandardScalerModel'>\n",
      "StopWordsRemover                    type            <class 'pyspark.ml.feature.StopWordsRemover'>\n",
      "StringIndexer                       type            <class 'pyspark.ml.feature.StringIndexer'>\n",
      "StringIndexerModel                  type            <class 'pyspark.ml.feature.StringIndexerModel'>\n",
      "StringType                          type            <class 'pyspark.sql.types.StringType'>\n",
      "StructField                         type            <class 'pyspark.sql.types.StructField'>\n",
      "StructType                          type            <class 'pyspark.sql.types.StructType'>\n",
      "TimestampType                       type            <class 'pyspark.sql.types.TimestampType'>\n",
      "Tokenizer                           type            <class 'pyspark.ml.feature.Tokenizer'>\n",
      "VectorAssembler                     type            <class 'pyspark.ml.feature.VectorAssembler'>\n",
      "VectorIndexer                       type            <class 'pyspark.ml.feature.VectorIndexer'>\n",
      "VectorIndexerModel                  type            <class 'pyspark.ml.feature.VectorIndexerModel'>\n",
      "VectorSizeHint                      type            <class 'pyspark.ml.feature.VectorSizeHint'>\n",
      "VectorSlicer                        type            <class 'pyspark.ml.feature.VectorSlicer'>\n",
      "Vectors                             type            <class 'pyspark.mllib.linalg.Vectors'>\n",
      "Word2Vec                            type            <class 'pyspark.ml.feature.Word2Vec'>\n",
      "Word2VecModel                       type            <class 'pyspark.ml.feature.Word2VecModel'>\n",
      "np                                  module          <module 'numpy' from '/op<...>kages/numpy/__init__.py'>\n",
      "os                                  module          <module 'os' from '/opt/c<...>nda/lib/python3.7/os.py'>\n",
      "sc                                  SparkContext    <SparkContext master=loca<...>appName=mllib_classifier>\n",
      "spark                               SparkSession    <pyspark.sql.session.Spar<...>object at 0x7f313054f190>\n",
      "time                                module          <module 'time' (built-in)>\n",
      "typ                                 module          <module 'pyspark.sql.type<...>on/pyspark/sql/types.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#clear old df\n",
    "#del (df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in our Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Custom Schema.  \n",
    "This schema was been primarly determined by using a much smaller dataset and letting spark infer the schema.  We encountered an issue with spark reading in the ENTIRE dataset as NULL when there was a type mismatch.  Only the data we are likely to use later has been assigned to a specific type, otherwise it is left as a string type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+------------+----------+-------------------+--------------------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+------------------------+-------------------------+------------------------+-------------------------+--------------------------+-------------------------+\n",
      "|             Trip_ID|Trip_Start_Timestamp|  Trip_End_Timestamp|Trip_Seconds|Trip_Miles|Pickup_Census_Tract|Dropoff_Census_Tract|Pickup_Community_Area|Dropoff_Community_Area|Fare|Tip|Additional_Charges|Trip_Total|Shared_Trip_Authorized|Trips_Pooled|Pickup_Centroid_Latitude|Pickup_Centroid_Longitude|Pickup_Centroid_Location|Dropoff_Centroid_Latitude|Dropoff_Centroid_Longitude|Dropoff_Centroid_Location|\n",
      "+--------------------+--------------------+--------------------+------------+----------+-------------------+--------------------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+------------------------+-------------------------+------------------------+-------------------------+--------------------------+-------------------------+\n",
      "|bea79abbef050980e...|12/01/2019 12:15:...|12/01/2019 01:00:...|      2675.0|      32.5|        17031980000|                null|                 76.0|                  null|70.0|0.0|              9.06|     79.06|                 false|         1.0|           41.9790708201|           -87.9030396611|    POINT (-87.903039...|                     null|                      null|                     null|\n",
      "|00f26da5601bbcf98...|12/01/2019 12:15:...|12/01/2019 12:15:...|       550.0|       2.8|        17031242100|         17031081700|                 24.0|                   8.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|           41.8996701799|           -87.6698377982|    POINT (-87.669837...|            41.8920421365|            -87.6318639497|     POINT (-87.631863...|\n",
      "|02256ef89c5c4be82...|12/01/2019 12:15:...|12/01/2019 12:30:...|       922.0|       2.8|        17031080300|         17031281900|                  8.0|                  28.0|10.0|0.0|              3.11|     13.11|                 false|         1.0|           41.9074919303|           -87.6357600901|    POINT (-87.635760...|            41.8792550844|             -87.642648998|     POINT (-87.642648...|\n",
      "|072cb06b1a88042c4...|12/01/2019 12:15:...|12/01/2019 12:30:...|      1475.0|      12.5|        17031310600|         17031063302|                 31.0|                   6.0|17.5|4.0|              2.55|     24.05|                 false|         1.0|           41.8563332167|           -87.6595642391|    POINT (-87.659564...|            41.9347624564|            -87.6398538587|     POINT (-87.639853...|\n",
      "|099257be99c66c8b2...|12/01/2019 12:15:...|12/01/2019 12:30:...|       594.0|       2.5|        17031310600|         17031330100|                 31.0|                  33.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|           41.8563332167|           -87.6595642391|    POINT (-87.659564...|             41.859349715|            -87.6173580061|     POINT (-87.617358...|\n",
      "+--------------------+--------------------+--------------------+------------+----------+-------------------+--------------------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+------------------------+-------------------------+------------------------+-------------------------+--------------------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create a custom schema.  \n",
    "\n",
    "customSchema = StructType([\n",
    "    StructField('Trip_ID', StringType(), True),        \n",
    "    StructField('Trip_Start_Timestamp', StringType(), True),\n",
    "    StructField('Trip_End_Timestamp', StringType(), True),\n",
    "    StructField('Trip_Seconds', DoubleType(), True),\n",
    "    StructField('Trip_Miles', DoubleType(), True),\n",
    "    StructField('Pickup_Census_Tract', StringType(), True),\n",
    "    StructField('Dropoff_Census_Tract', StringType(), True),\n",
    "    StructField('Pickup_Community_Area', DoubleType(), True),\n",
    "    StructField('Dropoff_Community_Area', DoubleType(), True),\n",
    "    StructField(\"Fare\", DoubleType(), True),\n",
    "    StructField(\"Tip\", DoubleType(), True),\n",
    "    StructField(\"Additional_Charges\", DoubleType(), True),\n",
    "    StructField(\"Trip_Total\", StringType(), True),\n",
    "    StructField(\"Shared_Trip_Authorized\", BooleanType(), True),\n",
    "    StructField(\"Trips_Pooled\", DoubleType(), True),\n",
    "    StructField('Pickup_Centroid_Latitude', StringType(), True),\n",
    "    StructField('Pickup_Centroid_Longitude', StringType(), True),\n",
    "    StructField('Pickup_Centroid_Location', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Latitude', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Longitude', StringType(), True),\n",
    "    StructField('Dropoff_Centroid_Location', StringType(), True)])\n",
    "\n",
    "#old readin.  Infer is slow for large dataset\n",
    "#df = spark.read.csv('/../../project/ds5559/Alice_Ed_Michael_Sam_project/BigTrips.csv', header = True, inferSchema=True)\n",
    "\n",
    "#read in the data to a dataframe\n",
    "df = spark.read.csv('/../../project/ds5559/Alice_Ed_Michael_Sam_project/BigTrips.csv', header = True, schema=customSchema)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Doesn't update if you don't resave the variable\n",
    "\n",
    "df = df.drop('Trip_End_Timestamp', \n",
    "             'Pickup_Census_Tract',\n",
    "             'Dropoff_Census_Tract',\n",
    "             'Pickup_Centroid_Latitude',\n",
    "             'Pickup_Centroid_Longitude', \n",
    "             'Pickup_Centroid_Location', \n",
    "             'Dropoff_Centroid_Latitude', \n",
    "             'Dropoff_Centroid_Longitude', \n",
    "             'Dropoff_Centroid_Location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip_ID: string (nullable = true)\n",
      " |-- Trip_Start_Timestamp: string (nullable = true)\n",
      " |-- Trip_Seconds: double (nullable = true)\n",
      " |-- Trip_Miles: double (nullable = true)\n",
      " |-- Pickup_Community_Area: double (nullable = true)\n",
      " |-- Dropoff_Community_Area: double (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: double (nullable = true)\n",
      " |-- Additional_Charges: double (nullable = true)\n",
      " |-- Trip_Total: string (nullable = true)\n",
      " |-- Shared_Trip_Authorized: boolean (nullable = true)\n",
      " |-- Trips_Pooled: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.sample(False, .0005, seed = 2021) #decreased our sample size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24478"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete the big df for now\n",
    "del (df)\n",
    "\n",
    "#hopefully that will make things faster "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill our NA community areas\n",
    "\n",
    "df2 = df2.na.fill(value=78,subset=['Pickup_Community_Area', 'Dropoff_Community_Area'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a binary tip/no tip indicator\n",
    "# https://spark.apache.org/docs/2.2.0/ml-features.html#binarizer\n",
    "\n",
    "#binarized tip seems to be causing problems.  Change its name to label as that is that the packages are expecting\n",
    "\n",
    "binarizer = Binarizer(threshold=0, inputCol=\"Tip\", outputCol=\"label\")\n",
    "df2 = binarizer.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Trip_ID: string, Trip_Start_Timestamp: string, Trip_Seconds: double, Trip_Miles: double, Pickup_Community_Area: double, Dropoff_Community_Area: double, Fare: double, Tip: double, Additional_Charges: double, Trip_Total: string, Shared_Trip_Authorized: boolean, Trips_Pooled: double, label: double]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip_ID: string (nullable = true)\n",
      " |-- Trip_Start_Timestamp: string (nullable = true)\n",
      " |-- Trip_Seconds: double (nullable = true)\n",
      " |-- Trip_Miles: double (nullable = true)\n",
      " |-- Pickup_Community_Area: double (nullable = false)\n",
      " |-- Dropoff_Community_Area: double (nullable = false)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tip: double (nullable = true)\n",
      " |-- Additional_Charges: double (nullable = true)\n",
      " |-- Trip_Total: string (nullable = true)\n",
      " |-- Shared_Trip_Authorized: boolean (nullable = true)\n",
      " |-- Trips_Pooled: double (nullable = true)\n",
      " |-- label: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original No Tip Count:  16370\n",
      "Original Tip Count   :  3275\n",
      "\n",
      "Final No Tip Count   :  16370\n",
      "Final Tip Count      :  16425\n"
     ]
    }
   ],
   "source": [
    "# split the data\n",
    "\n",
    "# our model didn't work on the standard test train split.  Prof. Tashman recomended upscalling the help with the imbalanced dataset.\n",
    "#from https://spark.apache.org/docs/2.1.0/ml-tuning.html#train-validation-split\n",
    "\n",
    "train_inital, test = df2.randomSplit([0.8, 0.2], seed=2021)\n",
    "\n",
    "# cahce our test values for later speed\n",
    "test.cache()\n",
    "\n",
    "# oversampleing code sample\n",
    "# https://stackoverflow.com/questions/53273133/how-to-perform-up-sampling-using-sample-functionpy-spark\n",
    "\n",
    "df_a = train_inital.filter(train_inital['label'] == 0)\n",
    "df_b = train_inital.filter(train_inital['label'] == 1)\n",
    "\n",
    "org_a_count = df_a.count()\n",
    "org_b_count = df_b.count() \n",
    "\n",
    "\n",
    "ratio = df_a.count() / df_b.count()\n",
    "# print(ratio)\n",
    "\n",
    "df_b_overampled = df_b.sample(withReplacement=True, fraction=ratio, seed=2021)\n",
    "\n",
    "# cahce our train values for later speed\n",
    "train = df_a.unionAll(df_b_overampled).cache()\n",
    "\n",
    "df_af = train.filter(train_inital['label'] == 0)\n",
    "df_bf = train.filter(train_inital['label'] == 1)\n",
    "fin_a_count = df_af.count()\n",
    "fin_b_count = df_bf.count() \n",
    "\n",
    "print(\"Original No Tip Count: \", org_a_count)\n",
    "print(\"Original Tip Count   : \", org_b_count)\n",
    "print(\"\")\n",
    "print(\"Final No Tip Count   : \", fin_a_count)\n",
    "print(\"Final Tip Count      : \", fin_b_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-----+\n",
      "|             Trip_ID|Trip_Start_Timestamp|Trip_Seconds|Trip_Miles|Pickup_Community_Area|Dropoff_Community_Area|Fare|Tip|Additional_Charges|Trip_Total|Shared_Trip_Authorized|Trips_Pooled|label|\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-----+\n",
      "|01ba2ca16a9c5d6b7...|12/01/2019 04:30:...|       575.0|      14.4|                 23.0|                  22.0| 7.5|0.0|               0.0|       7.5|                  true|         3.0|  0.0|\n",
      "|0617812ed64374b3a...|12/01/2019 08:00:...|       821.0|       5.3|                  5.0|                   7.0|10.0|3.0|              2.55|     15.55|                 false|         1.0|  1.0|\n",
      "|0957f4242b84cfb83...|12/01/2019 08:00:...|      1004.0|       8.1|                  8.0|                  77.0|12.5|1.0|              2.55|     16.05|                 false|         1.0|  1.0|\n",
      "|18ab602877942f36d...|12/02/2019 03:30:...|       690.0|       2.2|                 28.0|                   8.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|  0.0|\n",
      "|1b6d204d58edb00c1...|12/02/2019 07:30:...|       378.0|       0.9|                 22.0|                  24.0| 5.0|0.0|              2.55|      7.55|                 false|         1.0|  0.0|\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-----+\n",
      "|             Trip_ID|Trip_Start_Timestamp|Trip_Seconds|Trip_Miles|Pickup_Community_Area|Dropoff_Community_Area|Fare|Tip|Additional_Charges|Trip_Total|Shared_Trip_Authorized|Trips_Pooled|label|\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-----+\n",
      "|000e879212e519b17...|12/02/2019 01:45:...|      2376.0|      14.6|                 24.0|                  56.0|25.0|0.0|              7.55|     32.55|                 false|         1.0|  0.0|\n",
      "|00bcab98504c1e0c9...|12/01/2019 08:00:...|      1414.0|       6.7|                  6.0|                  32.0|15.0|0.0|              2.55|     17.55|                 false|         1.0|  0.0|\n",
      "|0117b3a3eeb5b268d...|12/02/2019 06:45:...|       792.0|       2.1|                  8.0|                  28.0| 7.5|0.0|              2.55|     10.05|                 false|         1.0|  0.0|\n",
      "|026810744e62e4554...|12/02/2019 08:15:...|      1328.0|       4.6|                 21.0|                   7.0| 5.0|0.0|              2.55|      7.55|                 false|         2.0|  0.0|\n",
      "|057df74c802dea47c...|12/01/2019 01:00:...|      1838.0|      17.4|                 77.0|                  32.0|10.0|0.0|               0.0|        10|                  true|         2.0|  0.0|\n",
      "+--------------------+--------------------+------------+----------+---------------------+----------------------+----+---+------------------+----------+----------------------+------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.show(5)\n",
    "train.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training size has increased.  This is to be expected in upscaling.\n",
    "\n",
    "Good reference: https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4045\n",
      "788\n"
     ]
    }
   ],
   "source": [
    "#just as a reminder what was the truth in our test data?\n",
    "\n",
    "dft_a = test.filter(train_inital['label'] == 0)\n",
    "dft_b = test.filter(train_inital['label'] == 1)\n",
    "count_test_a = dft_a.count()\n",
    "count_test_b = dft_b.count()\n",
    "print(count_test_a)\n",
    "print(count_test_b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmacc(pred):\n",
    "    # make a confusion matrix and return the accuracy\n",
    "    # select predictions and labels from prediction transform as rdd as there isn't a DF function for this\n",
    "    pred_rdd= pred.select('prediction').rdd.flatMap(lambda x: x)\n",
    "    label_rdd = pred.select('label').rdd.flatMap(lambda x: x)\n",
    "    \n",
    "    #zip them together\n",
    "    predictionAndLabels =  pred_rdd.zip(label_rdd)\n",
    "    \n",
    "    #metrics transform\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    \n",
    "    metrics2 = BinaryClassificationMetrics(predictionAndLabels)\n",
    "    \n",
    "    #make our confusion matrix\n",
    "    cm = metrics.confusionMatrix().toArray()\n",
    "\n",
    "    #calc accuracy from confusion matrix\n",
    "    \n",
    "    acc = (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "    \n",
    "    #calc area under curve\n",
    "    auc = metrics2.areaUnderROC\n",
    "    \n",
    "    prc = metrics2.areaUnderPR\n",
    "    \n",
    "    print(\"Confusion Matrix\")\n",
    "    print(cm)\n",
    "    print()\n",
    "    print(\"Accuracy from Confusion Matrix: \", acc)\n",
    "    print()\n",
    "    print(\"Area Under the ROC\", auc)\n",
    "    print()\n",
    "    print(\"Area Under the PR Curve\", prc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmacc2(pred):\n",
    "    # make a confusion matrix and return the accuracy\n",
    "    # select predictions and labels from prediction transform as rdd as there isn't a DF function for this\n",
    "    pred_rdd= pred.select('prediction').rdd.flatMap(lambda x: x)\n",
    "    label_rdd = pred.select('label').rdd.flatMap(lambda x: x)\n",
    "    \n",
    "    #zip them together\n",
    "    predictionAndLabels =  pred_rdd.zip(label_rdd)\n",
    "    \n",
    "    #metrics transform\n",
    "    metrics = MulticlassMetrics(predictionAndLabels)\n",
    "    \n",
    "    metrics2 = BinaryClassificationMetrics(predictionAndLabels)\n",
    "    \n",
    "    #make our confusion matrix\n",
    "    cm = metrics.confusionMatrix().toArray()\n",
    "\n",
    "    #calc accuracy from confusion matrix\n",
    "    \n",
    "    acc = (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "    \n",
    "    #calc area under curve\n",
    "    auc = metrics2.areaUnderROC\n",
    "    \n",
    "    prc = metrics2.areaUnderPR\n",
    "    \n",
    "    precision = metrics.precision()\n",
    "    recall = metrics.recall()\n",
    "    f1Score = metrics.fMeasure()\n",
    "       \n",
    "    print(\"Confusion Matrix\")\n",
    "    print(cm)\n",
    "    print()\n",
    "    print(\"Accuracy from Confusion Matrix: \", acc)\n",
    "    print()\n",
    "    print(\"Area Under the ROC\", auc)\n",
    "    print()\n",
    "    print(\"Area Under the PR Curve\", prc)\n",
    "   \n",
    "    print(\"Summary Stats\")\n",
    "    print(\"Precision = %s\" % precision)\n",
    "    print(\"Recall = %s\" % recall)\n",
    "    print(\"F1 Score = %s\" % f1Score)\n",
    "    \n",
    "    # Weighted stats\n",
    "    print(\"Weighted recall = %s\" % metrics.weightedRecall)\n",
    "    print(\"Weighted precision = %s\" % metrics.weightedPrecision)\n",
    "    print(\"Weighted F(1) Score = %s\" % metrics.weightedFMeasure())\n",
    "    print(\"Weighted F(0.5) Score = %s\" % metrics.weightedFMeasure(beta=0.5))\n",
    "    print(\"Weighted false positive rate = %s\" % metrics.weightedFalsePositiveRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline steps for Logistic Regression:\n",
    "\n",
    "#onehotencoder to pickup\n",
    "ohe_pu = OneHotEncoder(inputCol=\"Pickup_Community_Area\", outputCol=\"Pickup_Community_Area_vec\")\n",
    "\n",
    "#onehotencoder to dropoff\n",
    "ohe_do = OneHotEncoder(inputCol=\"Dropoff_Community_Area\", outputCol=\"Dropoff_Community_Area_vec\")\n",
    "\n",
    "#assemble the vector or LR\n",
    "\n",
    "# our colulms for lr\n",
    "predictor_col_for_lr = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec']\n",
    "\n",
    "lr_va = VectorAssembler(inputCols=predictor_col_for_lr, outputCol=\"features\") \n",
    "\n",
    "#scale our LR\n",
    "\n",
    "lr_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "#what do we want to do if we are doing a parameter search? make the parameters as variables and just do a loop?\n",
    "#we learned that this week.  May also need to add in cv step\n",
    "\n",
    "lr = LogisticRegression(maxIter=10,\n",
    "                        regParam=0.01, #org 0.1\n",
    "                        elasticNetParam=0.01, #org 0.3\n",
    "                        featuresCol=\"features\",\n",
    "                        labelCol=\"label\")\n",
    "\n",
    "# Build the pipeline\n",
    "lr_pipeline = Pipeline(stages=[ohe_pu, ohe_do, lr_va, lr_scaler, lr])\n",
    "\n",
    "# Fit the pipeline\n",
    "lr_model = lr_pipeline.fit(train)\n",
    "\n",
    "# Make a prediction\n",
    "lr_prediction = lr_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[19670. 20797.]\n",
      " [ 2089.  6266.]]\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.5312359182335832\n",
      "\n",
      "Area Under the Curve 0.6180225756572093\n"
     ]
    }
   ],
   "source": [
    "cmacc(lr_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above confirms the results of the first pass of the grid search from tuning below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------------------+\n",
      "|prediction|label|            features|\n",
      "+----------+-----+--------------------+\n",
      "|       1.0|  0.0|(162,[0,1,2,3,5,1...|\n",
      "|       1.0|  0.0|(162,[0,1,2,3,5,1...|\n",
      "|       1.0|  0.0|(162,[0,1,2,3,5,3...|\n",
      "|       1.0|  0.0|(162,[0,1,2,3,5,3...|\n",
      "|       0.0|  1.0|(162,[0,1,2,3,5,1...|\n",
      "+----------+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test Error = 0.716173\n",
      "RandomForestClassificationModel (uid=RandomForestClassifier_448462e021c7) with 10 trees\n"
     ]
    }
   ],
   "source": [
    "# pipeline steps for Random Forest:\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\")#.fit(df2)\n",
    "\n",
    "#onehotencoder to pickup\n",
    "ohe_pu = OneHotEncoder(inputCol=\"Pickup_Community_Area\", outputCol=\"Pickup_Community_Area_vec\")\n",
    "\n",
    "#onehotencoder to dropoff\n",
    "ohe_do = OneHotEncoder(inputCol=\"Dropoff_Community_Area\", outputCol=\"Dropoff_Community_Area_vec\")\n",
    "\n",
    "# our colulms for rf\n",
    "predictor_col_for_rf = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec']\n",
    "\n",
    "rf_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4)#.fit(df2)\n",
    "\n",
    "#skip scaling for now\n",
    "\n",
    "# lr_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "#                         withStd=True, withMean=False)\n",
    "\n",
    "#what do we want to do if we are doing a parameter search? make the parameters as variables and just do a loop?\n",
    "#we learned that this week.  May also need to add in cv step\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"indexedLabel\", \n",
    "                            featuresCol=\"indexedFeatures\", \n",
    "                            numTrees=10)\n",
    "\n",
    "# Build the pipeline\n",
    "rf_pipeline = Pipeline(stages=[ohe_pu, ohe_do, labelIndexer, rf_va, featureIndexer, rf])\n",
    "\n",
    "# Fit the pipeline\n",
    "rf_model = rf_pipeline.fit(train)\n",
    "\n",
    "# Make a prediction\n",
    "rf_prediction = rf_model.transform(test)\n",
    "\n",
    "# Select example rows to display.\n",
    "rf_prediction.select(\"prediction\", \"label\",\"features\").show(5) \n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\")\n",
    "\n",
    "accuracy = evaluator.evaluate(rf_prediction)\n",
    "\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "\n",
    "rfModel = rf_model.stages[5]\n",
    "print(rfModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8393. 32074.]\n",
      " [ 2891.  5464.]]\n",
      "\n",
      "0.2838269632542706\n"
     ]
    }
   ],
   "source": [
    "cmacc(rf_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline for GBT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try a GBT \n",
    "\n",
    "# https://spark.apache.org/docs/latest/ml-classification-regression.html#gradient-boosted-tree-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#onehotencoder to pickup\n",
    "ohe_pu = OneHotEncoder(inputCol=\"Pickup_Community_Area\", outputCol=\"Pickup_Community_Area_vec\")\n",
    "\n",
    "#onehotencoder to dropoff\n",
    "ohe_do = OneHotEncoder(inputCol=\"Dropoff_Community_Area\", outputCol=\"Dropoff_Community_Area_vec\")\n",
    "\n",
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "labelIndexer = StringIndexer(inputCol=\"binarized_tip\", outputCol=\"indexedLabel\")#.fit(data)\n",
    "\n",
    "#assemble the vector or GBT\n",
    "\n",
    "# our colulms for gbt\n",
    "predictor_col_for_gbt = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec']\n",
    "\n",
    "gbt_va = VectorAssembler(inputCols=predictor_col_for_rf, outputCol=\"features\") \n",
    "\n",
    "# Automatically identify categorical features, and index them.\n",
    "# Set maxCategories so features with > 4 distinct values are treated as continuous.\n",
    "featureIndexer =\\\n",
    "    VectorIndexer(inputCol=\"features\", outputCol=\"indexedFeatures\", maxCategories=4)#.fit(data)\n",
    "\n",
    "# Train a GBT model.\n",
    "gbt = GBTClassifier(labelCol=\"indexedLabel\", featuresCol=\"indexedFeatures\", maxIter=5)\n",
    "\n",
    "# Chain indexers and GBT in a Pipeline\n",
    "gbt_pipeline = Pipeline(stages=[ohe_pu, ohe_do, labelIndexer, gbt_va, featureIndexer, gbt])\n",
    "\n",
    "# Train model.  This also runs the indexers.\n",
    "gbt_model = gbt_pipeline.fit(train)\n",
    "\n",
    "# Make predictions.\n",
    "gbt_prediction = gbt_model.transform(test)\n",
    "\n",
    "gbt_prediction.show(3)\n",
    "\n",
    "# Select example rows to display.\n",
    "gbt_prediction.select(\"prediction\", \"binarized_tip\", \"features\").show(5)\n",
    "\n",
    "# Select (prediction, true label) and compute test error\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"binarized_tip\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(gbt_prediction)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "gbtModel = gbt_model.stages[5]\n",
    "print(gbtModel)  # summary only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmacc(gbt_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline LR with Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(paramGrid): 24\n"
     ]
    }
   ],
   "source": [
    "# pipeline steps for Logistic Regression:\n",
    "\n",
    "#onehotencoder to pickup\n",
    "ohe_pu = OneHotEncoder(inputCol=\"Pickup_Community_Area\", outputCol=\"Pickup_Community_Area_vec\")\n",
    "\n",
    "#onehotencoder to dropoff\n",
    "ohe_do = OneHotEncoder(inputCol=\"Dropoff_Community_Area\", outputCol=\"Dropoff_Community_Area_vec\")\n",
    "\n",
    "#assemble the vector or LR\n",
    "\n",
    "# our colulms for lr\n",
    "predictor_col_for_lr = ['Trip_Seconds',\n",
    "                        'Trip_Miles',\n",
    "                        'Fare',\n",
    "                        'Additional_Charges',\n",
    "                        'Shared_Trip_Authorized',\n",
    "                        'Trips_Pooled',\n",
    "                        'Pickup_Community_Area_vec',\n",
    "                        'Dropoff_Community_Area_vec']\n",
    "\n",
    "lr_va = VectorAssembler(inputCols=predictor_col_for_lr, outputCol=\"features\") \n",
    "\n",
    "#scale our LR\n",
    "\n",
    "lr_scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaledFeatures\",\n",
    "                        withStd=True, withMean=False)\n",
    "\n",
    "#what do we want to do if we are doing a parameter search? make the parameters as variables and just do a loop?\n",
    "#we learned that this week.  May also need to add in cv step\n",
    "\n",
    "lr = LogisticRegression(featuresCol=\"features\",\n",
    "                        labelCol=\"label\") # regParam=0.1, elasticNetParam=0.3, maxIter=10,\n",
    "\n",
    "# Build the pipeline\n",
    "lr_pipeline = Pipeline(stages=[ohe_pu, ohe_do, lr_va, lr_scaler, lr])\n",
    "\n",
    "# Set up the parameter grid\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(lr.regParam, [0, 0.01]) \\\n",
    "    .addGrid(lr.elasticNetParam, [0.19, 0.17, 0.15]) \\\n",
    "    .addGrid(lr.maxIter, [1, 2, 3, 5]) \\\n",
    "    .build()\n",
    "\n",
    "print('len(paramGrid): {}'.format(len(paramGrid)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "crossval = CrossValidator(estimator=lr_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          #evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          evaluator= MulticlassClassificationEvaluator(metricName='f1'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to find all our items we can call\n",
    "#dir(crossval.evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 191.24045610427856\n"
     ]
    }
   ],
   "source": [
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "\n",
    "t0 = time.time()\n",
    "cvModel = crossval.setParallelism(6).fit(train) # train 4 models in parallel\n",
    "print(\"train time:\", time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5710626974202797,\n",
       " 0.5827658046697693,\n",
       " 0.6198533919940417,\n",
       " 0.6133413438745555,\n",
       " 0.5710626974202797,\n",
       " 0.5827658046697693,\n",
       " 0.6198533919940417,\n",
       " 0.6133413438745555,\n",
       " 0.5710626974202797,\n",
       " 0.5827658046697693,\n",
       " 0.6198533919940417,\n",
       " 0.6133413438745555,\n",
       " 0.561447961886958,\n",
       " 0.5948383403382718,\n",
       " 0.6078647832593146,\n",
       " 0.6175480258558254,\n",
       " 0.5623210367003959,\n",
       " 0.5948773241499016,\n",
       " 0.6082882850061193,\n",
       " 0.6181302438974028,\n",
       " 0.562937487290531,\n",
       " 0.5946161659692834,\n",
       " 0.6081400798693645,\n",
       " 0.6182955688014299]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#not sure what this metric is...\n",
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_6cad572a74e9', name='regParam', doc='regularization parameter (>= 0).'): 0.0,\n",
       " Param(parent='LogisticRegression_6cad572a74e9', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.19,\n",
       " Param(parent='LogisticRegression_6cad572a74e9', name='maxIter', doc='max number of iterations (>= 0).'): 3}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# magic code from https://stackoverflow.com/questions/36697304/how-to-extract-model-hyper-parameters-from-spark-ml-in-pyspark\n",
    "\n",
    "cvModel.getEstimatorParamMaps()[ np.argmax(cvModel.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "predictionAUC = cvModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[2225. 1820.]\n",
      " [ 261.  527.]]\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.569418580591765\n",
      "\n",
      "Area Under the ROC 0.609421765292741\n",
      "\n",
      "Area Under the PR Curve 0.21435762903658068\n",
      "Summary Stats\n",
      "Precision = 0.569418580591765\n",
      "Recall = 0.569418580591765\n",
      "F1 Score = 0.569418580591765\n",
      "Weighted recall = 0.569418580591765\n",
      "Weighted precision = 0.7856947826421379\n",
      "Weighted F(1) Score = 0.6250886621091084\n",
      "Weighted F(0.5) Score = 0.7078221943038275\n",
      "Weighted false positive rate = 0.3505750500062831\n"
     ]
    }
   ],
   "source": [
    "cmacc2(predictionAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Treat the Pipeline as an Estimator, wrapping it in a CrossValidator instance.\n",
    "crossval = CrossValidator(estimator=lr_pipeline,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(metricName='areaUnderROC'), #we can pass in our own function if necessary\n",
    "                          #evaluator= MulticlassClassificationEvaluator(metricName='f1'),\n",
    "                          numFolds=5)\n",
    "\n",
    "# you can do a custom evaluator, but it seems to be a lot of work.  https://stackoverflow.com/questions/51404344/custom-evaluator-in-pyspark\n",
    "# we can use either areaUnderROC or areaUnderPR as defaults for binary.\n",
    "# f1|accuracy|weightedPrecision|weightedRecall for multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to find all our items we can call\n",
    "#dir(crossval.evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 207.37963557243347\n"
     ]
    }
   ],
   "source": [
    "# Run cross-validation, and choose the best set of parameters. Print the training time.\n",
    "\n",
    "t0 = time.time()\n",
    "cvModel = crossval.setParallelism(6).fit(train) # train 4 models in parallel\n",
    "print(\"train time:\", time.time() - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6751491044822934,\n",
       " 0.6737781933564606,\n",
       " 0.6751491044822934,\n",
       " 0.6737781933564606,\n",
       " 0.6751491044822933,\n",
       " 0.6737781933564606,\n",
       " 0.6738802839267473,\n",
       " 0.6739198614473169,\n",
       " 0.6741785330601496,\n",
       " 0.6738660265121904,\n",
       " 0.6743579375174591,\n",
       " 0.6739314267679457,\n",
       " 0.6576877413590392,\n",
       " 0.6560329723252993,\n",
       " 0.6643763586580695,\n",
       " 0.6637032287213127,\n",
       " 0.6701444427902179,\n",
       " 0.6705654555560161]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for AUC\n",
    "cvModel.avgMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{Param(parent='LogisticRegression_d45a35aba6c0', name='regParam', doc='regularization parameter (>= 0).'): 0.0,\n",
       " Param(parent='LogisticRegression_d45a35aba6c0', name='elasticNetParam', doc='the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty.'): 0.2,\n",
       " Param(parent='LogisticRegression_d45a35aba6c0', name='maxIter', doc='max number of iterations (>= 0).'): 5}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# magic code from https://stackoverflow.com/questions/36697304/how-to-extract-model-hyper-parameters-from-spark-ml-in-pyspark\n",
    "\n",
    "cvModel.getEstimatorParamMaps()[ np.argmax(cvModel.avgMetrics) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test documents. cvModel uses the best model found (lrModel).\n",
    "predictionAUC = cvModel.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[1796. 2249.]\n",
      " [ 176.  612.]]\n",
      "\n",
      "Accuracy from Confusion Matrix:  0.49824125801779434\n",
      "\n",
      "Area Under the ROC 0.610327345284333\n",
      "\n",
      "Area Under the PR Curve 0.20823080951636297\n",
      "Summary Stats\n",
      "Precision = 0.49824125801779434\n",
      "Recall = 0.49824125801779434\n",
      "F1 Score = 0.49824125801779434\n",
      "Weighted recall = 0.4982412580177943\n",
      "Weighted precision = 0.7971338387050194\n",
      "Weighted F(1) Score = 0.5543321152596681\n",
      "Weighted F(0.5) Score = 0.6706254634470036\n",
      "Weighted false positive rate = 0.27758656744912835\n"
     ]
    }
   ],
   "source": [
    "cmacc2(predictionAUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DS 5559",
   "language": "python",
   "name": "ds5559"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
